{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4b7c220",
   "metadata": {},
   "source": [
    "# Quick start\n",
    "\n",
    "## Installation\n",
    "\n",
    "The Python module can be directly installed from [PyPI](https://pypi.org/project/anta-database/) with:\n",
    "\n",
    "    pip install anta_database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d98c76",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "\n",
    "This Python module is designed to query and visualized data in a AntADatabase folder. The latter has to be first compiled using published IRH datasets, or you can contact for downloading it.\n",
    "You can already have a look at this guide to have an idea of the features of this tool. This Jupyter Notebook can be directly downloaded (top bar) and ran locally (assuming you had downloaded or compiled the AntADatabase folder).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1fd9c5",
   "metadata": {},
   "source": [
    "## Browsing the database\n",
    "\n",
    "First, initialize the Database class by providing the full path to the AntADatabase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cd5c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from anta_database import Database\n",
    "\n",
    "db = Database('/home/anthe/documents/data/isochrones/AntADatabase/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf0047d",
   "metadata": {},
   "source": [
    "Use the query() function to browse the database. 'query()' without argument will return all metadata contained in the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c97bba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.query()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751f3491",
   "metadata": {},
   "source": [
    "The query() function takes as argument:\n",
    "- author: author(s) of the datasets of interest\n",
    "- age: age(s) in yrs before present of the layer(s) of interest\n",
    "- var: variables(s) other than age depth such as 'IceThk', 'SurfElev', 'BedElev' or 'BasalUnit'\n",
    "- trace_id: ID of a particular trace. This is useful for explicit trace IDs such as 'DC_LDC_DIVIDE'\n",
    "\n",
    "One can also combine field queries as well as providing lists. Here are a few examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0ad94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Examples of queries:\n",
    "db.query(author='Cavitte_2020') # all data from Cavitte et al. 2020\n",
    "db.query(age='38100') # all datasets with the 38.1ka isochrone\n",
    "db.query(var='IceThk') # all datasets with IceThk variable\n",
    "db.query(trace_id='DC_LDC_DIVIDE') # all layers with the trace ID DC_LDC_DIVIDE\n",
    "db.query(author=['Franke_2025', 'Winter_2018'], age='38100') # example of multiple criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391cd745",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "Use the results of the query in the plotting functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa5b026",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = db.query(age=['38100','38000'])\n",
    "db.plotXY(results,\n",
    "                downscale_factor=1000, # downscale the datasets n times, which makes no visual difference but it is much lighter\n",
    "                title='AntArchitecture 38(.1)ka layer',\n",
    "                xlim=(-500, 2400), ylim=(-2200, 2200), # set the plot extent in km\n",
    "                scale_factor=0.7, # adjust the size of the plot\n",
    "                latex=True, # use latex compilers for plotting if you have them installed on your system\n",
    "                # save='AntA_38ka.pdf', # Uncomment to save the figure, otherwise it we visualize with pyplot\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d3ab48",
   "metadata": {},
   "source": [
    "Current implemented plotting functions are:\n",
    "- plotXY(): plot locations of the data, with different colors for the different datasets (example above)\n",
    "- plotXYDepth(): scatter plot with a colormap displaying the values of the data (example below)\n",
    "\n",
    "In Jupyter Notebook, use '%matplotlib qt' or '%matplotlib widget' depending on your IDE, to switch to the matplotlib widget that allows you to zoom in etc.\n",
    "Use '%matplotlib inline' (default) to plot the figure in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8bdda4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# %matplotlib widget\n",
    "%matplotlib inline\n",
    "results = db.query(age=['38100','38000'])\n",
    "db.plotXYDepth(results, title='AntArchitecture 38(.1)ka isochrone depth',\n",
    "                downscale_factor=100,\n",
    "                xlim=(-500, 2400),\n",
    "                ylim=(-2200, 2200),\n",
    "                scale_factor=0.7,\n",
    "                latex=True,\n",
    "                # save='AntA_38ka_depth.png'\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0fa9e3",
   "metadata": {},
   "source": [
    "## Generate data from the database\n",
    "\n",
    "Note: This part could be developed further in the future if there is the need. But for now, I am designing a separate Python module for constraining my ice sheet model of use, which is tailored to this database and other parallel processing libraries.\n",
    "\n",
    "The data_generator() function reads the query and 'yield' the dataframes for later use.\n",
    "Here is a quick example of how this can be used for computing the mean layer depth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8178a9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = db.query(age=['38100'])\n",
    "lazy_dfs = db.data_generator()\n",
    "\n",
    "import numpy as np\n",
    "mean_depth_trs = []\n",
    "min_depth = float('inf')\n",
    "max_depth = float('-inf')\n",
    "for df, md in lazy_dfs:\n",
    "    depth_values = df[md['age']]\n",
    "    mean_depth_trs.append(np.mean(depth_values))\n",
    "    min_depth = min(min_depth, min(depth_values))\n",
    "    max_depth = max(max_depth, max(depth_values))\n",
    "\n",
    "\n",
    "mean_depth = np.mean(mean_depth_trs)\n",
    "std_dev = np.std(mean_depth_trs, ddof=1)\n",
    "print(f\"The mean depth of the 38ka isochrone across East Antarctica is {round(mean_depth, 2)} m ranging from {round(min_depth, 2)} m to {round(max_depth, 2)} m.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3410f32",
   "metadata": {},
   "source": [
    "In the for loop, 'df' is an individual dataframe from the database, corresponding to a single layer of a single trace from a single dataset. The 'md' stores the unique metadata from the current 'df'. One can then associate the metadata with the current df, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34918b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = db.query(author='Cavitte_2020', trace_id='DC_LDC_DIVIDE')\n",
    "lazy_dfs = db.data_generator(results)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# from matplotlib import rc\n",
    "# rc('font', **{'family': 'serif', 'serif': ['Computer Modern']})\n",
    "# rc('text', usetex=True) # Do you use latex?\n",
    "\n",
    "for df, md in lazy_dfs:\n",
    "    if md['age'] is not None:\n",
    "        plt.plot(df.distance/1000, df[md['age']], label=md['age'])\n",
    "    if md['var'] == 'IceThk':\n",
    "        plt.plot(df.distance/1000, df['IceThk'], linewidth=2, color='k', label='Bedrock')\n",
    "\n",
    "plt.legend(ncol=2)\n",
    "plt.xlabel('Distance (km)')\n",
    "plt.ylabel('Depth (m)')\n",
    "plt.ylim(4000, 0)\n",
    "plt.title('Isochronal structure along DC_LDC_DIVIDE transect')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8afda8",
   "metadata": {},
   "source": [
    "### Downscale the data\n",
    "\n",
    "The downscale_factor argument in the data_generator reduces the size of the generated data by n times. This is useful when dealing with large data where the downscaling has a neglectable influence on the results.\n",
    "Another solution, probably more straightforward, is the downsample_distance option, which allows to provide a distance in meters by which the data should be average along the transects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febd29d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "results = db.query(author='Cavitte_2020', age='278000', trace_id='DC_LDC_DIVIDE')\n",
    "original = db.data_generator(results)\n",
    "downscale_10 = db.data_generator(results, downscale_factor=100)\n",
    "downsampled_by_distance = db.data_generator(results, downsample_distance=5000)\n",
    "\n",
    "list = [original, downscale_10, downsampled_by_distance]\n",
    "labels = ['original', 'downscale 100', 'downsample 5km']\n",
    "\n",
    "for i, lazy_dfs in enumerate(list):\n",
    "    for df, md in lazy_dfs:\n",
    "        plt.plot(df.distance, df['278000'],label=labels[i], linestyle='--')\n",
    "\n",
    "plt.ylim(3000, 0)\n",
    "plt.xlabel('Distance along DC_LDC_DIVIDE (km)')\n",
    "plt.ylabel('Depth (m)')\n",
    "plt.legend()\n",
    "plt.title('Different downscaling methods for Cavitte 2020 278ka along DC_LDC_DIVIDE')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "processing",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}