{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":101849,"databundleVersionId":13093295,"sourceType":"competition"},{"sourceId":13134414,"sourceType":"datasetVersion","datasetId":8318681},{"sourceId":13153479,"sourceType":"datasetVersion","datasetId":8333859}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Ariel data challenge submission\n\n## 1. Notebook set up","metadata":{}},{"cell_type":"code","source":"# Standard library imports\nimport os\nimport pickle\nimport time\n\n# Third party imports\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\n\n# Project imports\nfrom ariel_data_preprocessing.data_preprocessing import DataProcessor\n\nmode = 'submission'\n\nif mode == 'testing':\n    os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n    INPUT_DIRECTORY = 'data/raw'\n    OUTPUT_DIRECTORY = 'data/processed'\n    REBUILD_DATA = True\n    N_PLANETS = 10\n    MODEL = 'data/models/ariel-cnn-8.1M-2ksteps-tf2.11.keras'\n\nelif mode == 'submission':\n    INPUT_DIRECTORY = '/kaggle/input/ariel-data-challenge-2025'\n    OUTPUT_DIRECTORY = '/kaggle/working'\n    REBUILD_DATA = True\n    N_PLANETS = -1\n    MODEL = '/kaggle/input/ariel-cnn/ariel-cnn-8.1M-862ksteps.keras'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T03:54:18.061513Z","iopub.execute_input":"2025-09-24T03:54:18.061840Z","iopub.status.idle":"2025-09-24T03:54:18.067769Z","shell.execute_reply.started":"2025-09-24T03:54:18.061803Z","shell.execute_reply":"2025-09-24T03:54:18.067026Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"## 2. Data preparation\n\n### 2.1. Preprocess the raw data","metadata":{}},{"cell_type":"code","source":"data_processor = DataProcessor(\n    input_data_path=INPUT_DIRECTORY,\n    output_data_path=OUTPUT_DIRECTORY,\n    output_filename='test.h5',\n    n_cpus=4,\n    downsample_fgs=True,\n    n_planets=N_PLANETS,\n    mode='test'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T03:54:21.039460Z","iopub.execute_input":"2025-09-24T03:54:21.039719Z","iopub.status.idle":"2025-09-24T03:54:21.043505Z","shell.execute_reply.started":"2025-09-24T03:54:21.039700Z","shell.execute_reply":"2025-09-24T03:54:21.042729Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"if REBUILD_DATA:\n    start_time = time.time()\n    data_processor.run()\n    end_time = time.time()\n\n    print(f'Data preprocessing completed in {(end_time - start_time)/60:.2f} minutes')\n    print(f'Total test planets: {len(data_processor.planet_list)}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T03:54:21.634932Z","iopub.execute_input":"2025-09-24T03:54:21.635625Z","iopub.status.idle":"2025-09-24T03:54:39.558389Z","shell.execute_reply.started":"2025-09-24T03:54:21.635600Z","shell.execute_reply":"2025-09-24T03:54:39.557469Z"}},"outputs":[{"name":"stdout","text":"Data preprocessing completed in 0.30 minutes\nTotal test planets: 1\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"### 2.2. Initialize data generator","metadata":{}},{"cell_type":"code","source":"data_processor.initialize_data_generators(\n    sample_size=372,\n    n_samples=10\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T03:54:39.560156Z","iopub.execute_input":"2025-09-24T03:54:39.560471Z","iopub.status.idle":"2025-09-24T03:54:39.608287Z","shell.execute_reply.started":"2025-09-24T03:54:39.560448Z","shell.execute_reply":"2025-09-24T03:54:39.607780Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"### 2.3. Create dataset","metadata":{}},{"cell_type":"code","source":"testing_data = data_processor.testing.take(len(data_processor.planet_list))\nsignals = np.array([element.numpy() for element in testing_data])\n\nprint(f'Signals shape: {signals.shape}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T03:54:39.608962Z","iopub.execute_input":"2025-09-24T03:54:39.609170Z","iopub.status.idle":"2025-09-24T03:54:39.690356Z","shell.execute_reply.started":"2025-09-24T03:54:39.609154Z","shell.execute_reply":"2025-09-24T03:54:39.689812Z"}},"outputs":[{"name":"stdout","text":"Signals shape: (1, 10, 372, 283)\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"## 3. Predictions","metadata":{}},{"cell_type":"code","source":"model = tf.keras.models.load_model(MODEL)\n\nspectrum_predictions = []\n\nfor planet in signals:\n    spectrum_predictions.append(model.predict(planet, batch_size=10, verbose=0))\n\nspectrum_predictions = np.array(spectrum_predictions)\nspectrum_predictions_avg = np.mean(spectrum_predictions, axis=1)\nspectrum_predictions_std = np.std(spectrum_predictions, axis=1)\n\nprint(f'Spectrum predictions shape: {spectrum_predictions.shape}')\nprint(f'Spectrum predictions avg shape: {spectrum_predictions_avg.shape}')\nprint(f'Spectrum predictions std shape: {spectrum_predictions_std.shape}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T03:54:43.505331Z","iopub.execute_input":"2025-09-24T03:54:43.505587Z","iopub.status.idle":"2025-09-24T03:54:44.510811Z","shell.execute_reply.started":"2025-09-24T03:54:43.505570Z","shell.execute_reply":"2025-09-24T03:54:44.510106Z"}},"outputs":[{"name":"stdout","text":"Spectrum predictions shape: (1, 10, 283)\nSpectrum predictions avg shape: (1, 283)\nSpectrum predictions std shape: (1, 283)\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"## 4. Error correction","metadata":{}},{"cell_type":"code","source":"with open('/kaggle/input/ariel-error-correction-factors/error_correction_factors.pkl', 'rb') as input_file:\n    error_correction_factors = pickle.load(input_file)\n\n\nscaled_errors = []\n\nfor planet_spectrum, planet_error in zip(spectrum_predictions_avg, spectrum_predictions_std):\n    scaled_errors.append(planet_error*error_correction_factors)\n\nscaled_errors = np.array(scaled_errors)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T03:54:47.248659Z","iopub.execute_input":"2025-09-24T03:54:47.249021Z","iopub.status.idle":"2025-09-24T03:54:47.253901Z","shell.execute_reply.started":"2025-09-24T03:54:47.249001Z","shell.execute_reply":"2025-09-24T03:54:47.253197Z"}},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"## 5. Submission file","metadata":{}},{"cell_type":"code","source":"submission = np.concatenate(\n    (spectrum_predictions_avg, scaled_errors),\n    axis=1\n)\n\nsubmission_df = pd.DataFrame(submission)\n\ncol_names = [f'wl_{i}' for i in range(1, 284)]\ncol_names += [f'sigma_{i}' for i in range(1, 284)]\nsubmission_df.columns = col_names\n\nsubmission_df.insert(0, 'planet_id', data_processor.planet_list)\nsubmission_df['planet_id'] = submission_df['planet_id'].astype(int)\n\nsubmission_df.to_csv('submission.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T03:54:54.439048Z","iopub.execute_input":"2025-09-24T03:54:54.439798Z","iopub.status.idle":"2025-09-24T03:54:54.452150Z","shell.execute_reply.started":"2025-09-24T03:54:54.439774Z","shell.execute_reply":"2025-09-24T03:54:54.451585Z"}},"outputs":[],"execution_count":19}]}