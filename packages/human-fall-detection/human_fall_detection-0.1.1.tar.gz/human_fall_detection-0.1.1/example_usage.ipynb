{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human Fall Detection Example ðŸš¨\n",
    "\n",
    "YOLOv8-based fall detection system demonstration\n",
    "\n",
    "## ðŸ“‹ Features\n",
    "- Support for both PyTorch (.pt) and ONNX (.onnx) models\n",
    "- FP16 quantization support for faster inference\n",
    "- Real-time video processing\n",
    "- Easy-to-use API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Detect Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fall_detection\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Detect single image\n",
    "result = fall_detection.process_image(\n",
    "    \"test_src/test.jpg\",\n",
    "    \"results/output.jpg\",\n",
    "    confidence=0.36,\n",
    ")\n",
    "\n",
    "# Show results\n",
    "print(f\"Fall detected: {result['fall_detected']}\")\n",
    "print(f\"Fall count: {result['fall_count']}\")\n",
    "print(f\"Normal count: {result['normal_count']}\")\n",
    "\n",
    "# Display image\n",
    "if result['image_saved']:\n",
    "    display(Image(filename=result['image_saved']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Detect Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fall_detection\n",
    "\n",
    "# Process video\n",
    "result = fall_detection.process_video(\n",
    "    \"test_src/test.mp4\",\n",
    "    \"results/fall_detection/output.mp4\",\n",
    "    confidence=0.36\n",
    ")\n",
    "\n",
    "print(f\"Total frames: {result['total_frames']}\")\n",
    "print(f\"Fall frames: {result['fall_frames']}\")\n",
    "print(f\"Total fall detections: {result['statistics']['fall_count']}\")\n",
    "print(f\"Total normal detections: {result['statistics']['normal_count']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Using Detector Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fall_detection import FallDetector\n",
    "import cv2\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Create detector\n",
    "detector = FallDetector(confidence=0.6)\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"test_src/test.jpg\")\n",
    "\n",
    "# Detect\n",
    "result = detector.detect_image(img)\n",
    "\n",
    "# Save result\n",
    "cv2.imwrite(\"results/output.jpg\", result['annotated_image'])\n",
    "\n",
    "print(f\"Detection complete!\")\n",
    "print(f\"Falls: {result['fall_count']}\")\n",
    "print(f\"Normal: {result['normal_count']}\")\n",
    "\n",
    "# Display result\n",
    "display(Image(filename=\"results/output.jpg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Real-time Camera Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from fall_detection import FallDetector\nimport cv2\n\n# Create detector\ndetector = FallDetector(confidence=0.5)\n\n# Open camera\ncap = cv2.VideoCapture(0)\n\nprint(\"Press 'q' to quit\")\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n    \n    # Detect\n    result = detector.detect_image(frame)\n    \n    # Show\n    cv2.imshow('Fall Detection', result['annotated_image'])\n    \n    if cv2.waitKey(1) & 0xFF == ord('q'):\n        break\n\ncap.release()\ncv2.destroyAllWindows()\nprint(\"Camera closed\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Using ONNX Model for Image Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from fall_detection import FallDetector\nimport cv2\nfrom IPython.display import Image, display\n\n# Create detector using ONNX model (specify FP16 ONNX model path)\ndetector = FallDetector(\n    model_path=\"fall_detection/models/best_fp16.onnx\",\n    confidence=0.5,\n    device=\"cuda\"  # Use GPU acceleration\n)\n\n# Read image\nimg = cv2.imread(\"test_src/test.jpg\")\n\n# Run detection\nresult = detector.detect_image(img)\n\n# Save result\ncv2.imwrite(\"results/onnx_output.jpg\", result['annotated_image'])\n\nprint(f\"âœ… ONNX model detection complete!\")\nprint(f\"Fall count: {result['fall_count']}\")\nprint(f\"Normal count: {result['normal_count']}\")\nprint(f\"Inference speed: 2-3x faster than PyTorch model\")\n\n# Display result\ndisplay(Image(filename=\"results/onnx_output.jpg\"))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Using ONNX Model for Video Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from fall_detection import FallDetector\n\n# Process video using ONNX model (explicitly specify model path)\ndetector = FallDetector(\n    model_path=\"fall_detection/models/best_fp16.onnx\",  # Specify ONNX model\n    confidence=0.36,\n    device=\"cuda\"\n)\n\n# Process video file\nresult = detector.process_video_file(\n    input_path=\"test_src/test.mp4\",\n    output_path=\"results/fall_detection/output_onnx.mp4\",\n    show_progress=True\n)\n\nprint(f\"âœ… ONNX model video processing complete!\")\nprint(f\"Total frames: {result['total_frames']}\")\nprint(f\"Fall frames: {result['fall_frames']}\")\nprint(f\"Total fall detections: {result['statistics']['fall_count']}\")\nprint(f\"Total normal detections: {result['statistics']['normal_count']}\")\nprint(f\"\\nPerformance boost: FP16 ONNX model processes ~2-3x faster\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "human-fall-detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}