# This file was automatically generated by SWIG (https://www.swig.org).
# Version 4.3.0
#
# Do not make changes to this file unless you know what you are doing - modify
# the SWIG interface file instead.


import collections

from sys import version_info as _version_info
if _version_info < (3, 7, 0):
    raise RuntimeError("Python 3.7 or later required")

from . import _ITKCommonPython


from . import _ITKOptimizersv4Python



from sys import version_info as _swig_python_version_info
# Import the low-level C/C++ module
if __package__ or "." in __name__:
    from . import _itkGradientDescentOptimizerv4Python
else:
    import _itkGradientDescentOptimizerv4Python

try:
    import builtins as __builtin__
except ImportError:
    import __builtin__

def _swig_repr(self):
    try:
        strthis = "proxy of " + self.this.__repr__()
    except __builtin__.Exception:
        strthis = ""
    return "<%s.%s; %s >" % (self.__class__.__module__, self.__class__.__name__, strthis,)


def _swig_setattr_nondynamic_instance_variable(set):
    def set_instance_attr(self, name, value):
        if name == "this":
            set(self, name, value)
        elif name == "thisown":
            self.this.own(value)
        elif hasattr(self, name) and isinstance(getattr(type(self), name), property):
            set(self, name, value)
        else:
            raise AttributeError("You cannot add instance attributes to %s" % self)
    return set_instance_attr


def _swig_setattr_nondynamic_class_variable(set):
    def set_class_attr(cls, name, value):
        if hasattr(cls, name) and not isinstance(getattr(cls, name), property):
            set(cls, name, value)
        else:
            raise AttributeError("You cannot add class attributes to %s" % cls)
    return set_class_attr


def _swig_add_metaclass(metaclass):
    """Class decorator for adding a metaclass to a SWIG wrapped class - a slimmed down version of six.add_metaclass"""
    def wrapper(cls):
        return metaclass(cls.__name__, cls.__bases__, cls.__dict__.copy())
    return wrapper


class _SwigNonDynamicMeta(type):
    """Meta class to enforce nondynamic attributes (no new attributes) for a class"""
    __setattr__ = _swig_setattr_nondynamic_class_variable(type.__setattr__)


if _swig_python_version_info[0:2] >= (3, 3):
    import collections.abc
else:
    import collections

import itk.itkGradientDescentOptimizerBasev4Python
import itk.ITKCommonBasePython
import itk.itkMatrixPython
import itk.vnl_matrixPython
import itk.stdcomplexPython
import itk.pyBasePython
import itk.vnl_vectorPython
import itk.vnl_matrix_fixedPython
import itk.itkPointPython
import itk.itkFixedArrayPython
import itk.itkVectorPython
import itk.vnl_vector_refPython
import itk.itkCovariantVectorPython
import itk.itkArrayPython
import itk.itkObjectToObjectOptimizerBasePython
import itk.itkOptimizerParametersPython
import itk.itkOptimizerParameterScalesEstimatorPython
import itk.itkObjectToObjectMetricBasePython
import itk.itkSingleValuedCostFunctionv4Python
import itk.itkCostFunctionPython
import itk.itkIndexPython
import itk.itkSizePython
import itk.itkOffsetPython

def itkGradientDescentOptimizerv4_New():
    return itkGradientDescentOptimizerv4.New()

class itkGradientDescentOptimizerv4(itk.itkGradientDescentOptimizerBasev4Python.itkGradientDescentOptimizerBasev4TemplateD):
    r"""Proxy of C++ itkGradientDescentOptimizerv4 class."""

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr

    @staticmethod
    def __New_orig__():
        r"""__New_orig__() -> itkGradientDescentOptimizerv4TemplateD_Pointer"""
        return _itkGradientDescentOptimizerv4Python.itkGradientDescentOptimizerv4___New_orig__()

    def Clone(self):
        r"""Clone(self) -> itkGradientDescentOptimizerv4TemplateD_Pointer"""
        return _itkGradientDescentOptimizerv4Python.itkGradientDescentOptimizerv4_Clone(self)

    def SetLearningRate(self, _arg):
        r"""
        SetLearningRate(self, _arg)

        Parameters
        ----------
        _arg: double

        """
        return _itkGradientDescentOptimizerv4Python.itkGradientDescentOptimizerv4_SetLearningRate(self, _arg)

    def GetLearningRate(self):
        r"""GetLearningRate(self) -> double const &"""
        return _itkGradientDescentOptimizerv4Python.itkGradientDescentOptimizerv4_GetLearningRate(self)

    def SetMaximumStepSizeInPhysicalUnits(self, _arg):
        r"""
        SetMaximumStepSizeInPhysicalUnits(self, _arg)

        Parameters
        ----------
        _arg: double

        """
        return _itkGradientDescentOptimizerv4Python.itkGradientDescentOptimizerv4_SetMaximumStepSizeInPhysicalUnits(self, _arg)

    def GetMaximumStepSizeInPhysicalUnits(self):
        r"""GetMaximumStepSizeInPhysicalUnits(self) -> double const &"""
        return _itkGradientDescentOptimizerv4Python.itkGradientDescentOptimizerv4_GetMaximumStepSizeInPhysicalUnits(self)

    def SetDoEstimateLearningRateAtEachIteration(self, _arg):
        r"""
        SetDoEstimateLearningRateAtEachIteration(self, _arg)

        Parameters
        ----------
        _arg: bool

        """
        return _itkGradientDescentOptimizerv4Python.itkGradientDescentOptimizerv4_SetDoEstimateLearningRateAtEachIteration(self, _arg)

    def GetDoEstimateLearningRateAtEachIteration(self):
        r"""GetDoEstimateLearningRateAtEachIteration(self) -> bool const &"""
        return _itkGradientDescentOptimizerv4Python.itkGradientDescentOptimizerv4_GetDoEstimateLearningRateAtEachIteration(self)

    def DoEstimateLearningRateAtEachIterationOn(self):
        r"""DoEstimateLearningRateAtEachIterationOn(self)"""
        return _itkGradientDescentOptimizerv4Python.itkGradientDescentOptimizerv4_DoEstimateLearningRateAtEachIterationOn(self)

    def DoEstimateLearningRateAtEachIterationOff(self):
        r"""DoEstimateLearningRateAtEachIterationOff(self)"""
        return _itkGradientDescentOptimizerv4Python.itkGradientDescentOptimizerv4_DoEstimateLearningRateAtEachIterationOff(self)

    def SetDoEstimateLearningRateOnce(self, _arg):
        r"""
        SetDoEstimateLearningRateOnce(self, _arg)

        Parameters
        ----------
        _arg: bool

        """
        return _itkGradientDescentOptimizerv4Python.itkGradientDescentOptimizerv4_SetDoEstimateLearningRateOnce(self, _arg)

    def GetDoEstimateLearningRateOnce(self):
        r"""GetDoEstimateLearningRateOnce(self) -> bool const &"""
        return _itkGradientDescentOptimizerv4Python.itkGradientDescentOptimizerv4_GetDoEstimateLearningRateOnce(self)

    def DoEstimateLearningRateOnceOn(self):
        r"""DoEstimateLearningRateOnceOn(self)"""
        return _itkGradientDescentOptimizerv4Python.itkGradientDescentOptimizerv4_DoEstimateLearningRateOnceOn(self)

    def DoEstimateLearningRateOnceOff(self):
        r"""DoEstimateLearningRateOnceOff(self)"""
        return _itkGradientDescentOptimizerv4Python.itkGradientDescentOptimizerv4_DoEstimateLearningRateOnceOff(self)

    def SetMinimumConvergenceValue(self, _arg):
        r"""
        SetMinimumConvergenceValue(self, _arg)

        Parameters
        ----------
        _arg: double

        """
        return _itkGradientDescentOptimizerv4Python.itkGradientDescentOptimizerv4_SetMinimumConvergenceValue(self, _arg)

    def SetConvergenceWindowSize(self, _arg):
        r"""
        SetConvergenceWindowSize(self, _arg)

        Parameters
        ----------
        _arg: unsigned long long

        """
        return _itkGradientDescentOptimizerv4Python.itkGradientDescentOptimizerv4_SetConvergenceWindowSize(self, _arg)

    def GetConvergenceValue(self):
        r"""GetConvergenceValue(self) -> double const &"""
        return _itkGradientDescentOptimizerv4Python.itkGradientDescentOptimizerv4_GetConvergenceValue(self)

    def SetReturnBestParametersAndValue(self, _arg):
        r"""
        SetReturnBestParametersAndValue(self, _arg)

        Parameters
        ----------
        _arg: bool

        """
        return _itkGradientDescentOptimizerv4Python.itkGradientDescentOptimizerv4_SetReturnBestParametersAndValue(self, _arg)

    def GetReturnBestParametersAndValue(self):
        r"""GetReturnBestParametersAndValue(self) -> bool const &"""
        return _itkGradientDescentOptimizerv4Python.itkGradientDescentOptimizerv4_GetReturnBestParametersAndValue(self)

    def ReturnBestParametersAndValueOn(self):
        r"""ReturnBestParametersAndValueOn(self)"""
        return _itkGradientDescentOptimizerv4Python.itkGradientDescentOptimizerv4_ReturnBestParametersAndValueOn(self)

    def ReturnBestParametersAndValueOff(self):
        r"""ReturnBestParametersAndValueOff(self)"""
        return _itkGradientDescentOptimizerv4Python.itkGradientDescentOptimizerv4_ReturnBestParametersAndValueOff(self)

    def StartOptimization(self, doOnlyInitialization=False):
        r"""
        StartOptimization(self, doOnlyInitialization=False)

        Parameters
        ----------
        doOnlyInitialization: bool

        """
        return _itkGradientDescentOptimizerv4Python.itkGradientDescentOptimizerv4_StartOptimization(self, doOnlyInitialization)

    def EstimateLearningRate(self):
        r"""EstimateLearningRate(self)"""
        return _itkGradientDescentOptimizerv4Python.itkGradientDescentOptimizerv4_EstimateLearningRate(self)
    __swig_destroy__ = _itkGradientDescentOptimizerv4Python.delete_itkGradientDescentOptimizerv4

    @staticmethod
    def cast(obj):
        r"""
        cast(obj) -> itkGradientDescentOptimizerv4

        Parameters
        ----------
        obj: itkLightObject *

        """
        return _itkGradientDescentOptimizerv4Python.itkGradientDescentOptimizerv4_cast(obj)

    def New(*args, **kargs):
        """New() -> itkGradientDescentOptimizerv4

        Create a new object of the class itkGradientDescentOptimizerv4 and set the input and the parameters if some
        named or non-named arguments are passed to that method.

        New() tries to assign all the non named parameters to the input of the new objects - the
        first non named parameter in the first input, etc.

        The named parameters are used by calling the method with the same name prefixed by 'Set'.

        Ex:

          itkGradientDescentOptimizerv4.New(reader, threshold=10)

        is (most of the time) equivalent to:

          obj = itkGradientDescentOptimizerv4.New()
          obj.SetInput(0, reader.GetOutput())
          obj.SetThreshold(10)
        """
        obj = itkGradientDescentOptimizerv4.__New_orig__()
        from itk.support import template_class
        template_class.New(obj, *args, **kargs)
        return obj
    New = staticmethod(New)


# Register itkGradientDescentOptimizerv4 in _itkGradientDescentOptimizerv4Python:
_itkGradientDescentOptimizerv4Python.itkGradientDescentOptimizerv4_swigregister(itkGradientDescentOptimizerv4)

def itkGradientDescentOptimizerv4TemplateD_New():
    return itkGradientDescentOptimizerv4TemplateD.New()

class itkGradientDescentOptimizerv4TemplateD(itk.itkGradientDescentOptimizerBasev4Python.itkGradientDescentOptimizerBasev4TemplateD):
    r"""Proxy of C++ itkGradientDescentOptimizerv4TemplateD class."""

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr

    @staticmethod
    def __New_orig__():
        r"""__New_orig__() -> itkGradientDescentOptimizerv4TemplateD_Pointer"""
        return _itkGradientDescentOptimizerv4Python.itkGradientDescentOptimizerv4TemplateD___New_orig__()

    def Clone(self):
        r"""Clone(self) -> itkGradientDescentOptimizerv4TemplateD_Pointer"""
        return _itkGradientDescentOptimizerv4Python.itkGradientDescentOptimizerv4TemplateD_Clone(self)

    def SetLearningRate(self, _arg):
        r"""
        SetLearningRate(self, _arg)

        Parameters
        ----------
        _arg: double

        """
        return _itkGradientDescentOptimizerv4Python.itkGradientDescentOptimizerv4TemplateD_SetLearningRate(self, _arg)

    def GetLearningRate(self):
        r"""GetLearningRate(self) -> double const &"""
        return _itkGradientDescentOptimizerv4Python.itkGradientDescentOptimizerv4TemplateD_GetLearningRate(self)

    def SetMaximumStepSizeInPhysicalUnits(self, _arg):
        r"""
        SetMaximumStepSizeInPhysicalUnits(self, _arg)

        Parameters
        ----------
        _arg: double

        """
        return _itkGradientDescentOptimizerv4Python.itkGradientDescentOptimizerv4TemplateD_SetMaximumStepSizeInPhysicalUnits(self, _arg)

    def GetMaximumStepSizeInPhysicalUnits(self):
        r"""GetMaximumStepSizeInPhysicalUnits(self) -> double const &"""
        return _itkGradientDescentOptimizerv4Python.itkGradientDescentOptimizerv4TemplateD_GetMaximumStepSizeInPhysicalUnits(self)

    def SetDoEstimateLearningRateAtEachIteration(self, _arg):
        r"""
        SetDoEstimateLearningRateAtEachIteration(self, _arg)

        Parameters
        ----------
        _arg: bool

        """
        return _itkGradientDescentOptimizerv4Python.itkGradientDescentOptimizerv4TemplateD_SetDoEstimateLearningRateAtEachIteration(self, _arg)

    def GetDoEstimateLearningRateAtEachIteration(self):
        r"""GetDoEstimateLearningRateAtEachIteration(self) -> bool const &"""
        return _itkGradientDescentOptimizerv4Python.itkGradientDescentOptimizerv4TemplateD_GetDoEstimateLearningRateAtEachIteration(self)

    def DoEstimateLearningRateAtEachIterationOn(self):
        r"""DoEstimateLearningRateAtEachIterationOn(self)"""
        return _itkGradientDescentOptimizerv4Python.itkGradientDescentOptimizerv4TemplateD_DoEstimateLearningRateAtEachIterationOn(self)

    def DoEstimateLearningRateAtEachIterationOff(self):
        r"""DoEstimateLearningRateAtEachIterationOff(self)"""
        return _itkGradientDescentOptimizerv4Python.itkGradientDescentOptimizerv4TemplateD_DoEstimateLearningRateAtEachIterationOff(self)

    def SetDoEstimateLearningRateOnce(self, _arg):
        r"""
        SetDoEstimateLearningRateOnce(self, _arg)

        Parameters
        ----------
        _arg: bool

        """
        return _itkGradientDescentOptimizerv4Python.itkGradientDescentOptimizerv4TemplateD_SetDoEstimateLearningRateOnce(self, _arg)

    def GetDoEstimateLearningRateOnce(self):
        r"""GetDoEstimateLearningRateOnce(self) -> bool const &"""
        return _itkGradientDescentOptimizerv4Python.itkGradientDescentOptimizerv4TemplateD_GetDoEstimateLearningRateOnce(self)

    def DoEstimateLearningRateOnceOn(self):
        r"""DoEstimateLearningRateOnceOn(self)"""
        return _itkGradientDescentOptimizerv4Python.itkGradientDescentOptimizerv4TemplateD_DoEstimateLearningRateOnceOn(self)

    def DoEstimateLearningRateOnceOff(self):
        r"""DoEstimateLearningRateOnceOff(self)"""
        return _itkGradientDescentOptimizerv4Python.itkGradientDescentOptimizerv4TemplateD_DoEstimateLearningRateOnceOff(self)

    def SetMinimumConvergenceValue(self, _arg):
        r"""
        SetMinimumConvergenceValue(self, _arg)

        Parameters
        ----------
        _arg: double

        """
        return _itkGradientDescentOptimizerv4Python.itkGradientDescentOptimizerv4TemplateD_SetMinimumConvergenceValue(self, _arg)

    def SetConvergenceWindowSize(self, _arg):
        r"""
        SetConvergenceWindowSize(self, _arg)

        Parameters
        ----------
        _arg: unsigned long long

        """
        return _itkGradientDescentOptimizerv4Python.itkGradientDescentOptimizerv4TemplateD_SetConvergenceWindowSize(self, _arg)

    def GetConvergenceValue(self):
        r"""GetConvergenceValue(self) -> double const &"""
        return _itkGradientDescentOptimizerv4Python.itkGradientDescentOptimizerv4TemplateD_GetConvergenceValue(self)

    def SetReturnBestParametersAndValue(self, _arg):
        r"""
        SetReturnBestParametersAndValue(self, _arg)

        Parameters
        ----------
        _arg: bool

        """
        return _itkGradientDescentOptimizerv4Python.itkGradientDescentOptimizerv4TemplateD_SetReturnBestParametersAndValue(self, _arg)

    def GetReturnBestParametersAndValue(self):
        r"""GetReturnBestParametersAndValue(self) -> bool const &"""
        return _itkGradientDescentOptimizerv4Python.itkGradientDescentOptimizerv4TemplateD_GetReturnBestParametersAndValue(self)

    def ReturnBestParametersAndValueOn(self):
        r"""ReturnBestParametersAndValueOn(self)"""
        return _itkGradientDescentOptimizerv4Python.itkGradientDescentOptimizerv4TemplateD_ReturnBestParametersAndValueOn(self)

    def ReturnBestParametersAndValueOff(self):
        r"""ReturnBestParametersAndValueOff(self)"""
        return _itkGradientDescentOptimizerv4Python.itkGradientDescentOptimizerv4TemplateD_ReturnBestParametersAndValueOff(self)

    def StartOptimization(self, doOnlyInitialization=False):
        r"""
        StartOptimization(self, doOnlyInitialization=False)

        Parameters
        ----------
        doOnlyInitialization: bool

        """
        return _itkGradientDescentOptimizerv4Python.itkGradientDescentOptimizerv4TemplateD_StartOptimization(self, doOnlyInitialization)

    def EstimateLearningRate(self):
        r"""EstimateLearningRate(self)"""
        return _itkGradientDescentOptimizerv4Python.itkGradientDescentOptimizerv4TemplateD_EstimateLearningRate(self)
    __swig_destroy__ = _itkGradientDescentOptimizerv4Python.delete_itkGradientDescentOptimizerv4TemplateD

    @staticmethod
    def cast(obj):
        r"""
        cast(obj) -> itkGradientDescentOptimizerv4TemplateD

        Parameters
        ----------
        obj: itkLightObject *

        """
        return _itkGradientDescentOptimizerv4Python.itkGradientDescentOptimizerv4TemplateD_cast(obj)

    def New(*args, **kargs):
        """New() -> itkGradientDescentOptimizerv4TemplateD

        Create a new object of the class itkGradientDescentOptimizerv4TemplateD and set the input and the parameters if some
        named or non-named arguments are passed to that method.

        New() tries to assign all the non named parameters to the input of the new objects - the
        first non named parameter in the first input, etc.

        The named parameters are used by calling the method with the same name prefixed by 'Set'.

        Ex:

          itkGradientDescentOptimizerv4TemplateD.New(reader, threshold=10)

        is (most of the time) equivalent to:

          obj = itkGradientDescentOptimizerv4TemplateD.New()
          obj.SetInput(0, reader.GetOutput())
          obj.SetThreshold(10)
        """
        obj = itkGradientDescentOptimizerv4TemplateD.__New_orig__()
        from itk.support import template_class
        template_class.New(obj, *args, **kargs)
        return obj
    New = staticmethod(New)


# Register itkGradientDescentOptimizerv4TemplateD in _itkGradientDescentOptimizerv4Python:
_itkGradientDescentOptimizerv4Python.itkGradientDescentOptimizerv4TemplateD_swigregister(itkGradientDescentOptimizerv4TemplateD)

def itkGradientDescentOptimizerv4TemplateF_New():
    return itkGradientDescentOptimizerv4TemplateF.New()

class itkGradientDescentOptimizerv4TemplateF(itk.itkGradientDescentOptimizerBasev4Python.itkGradientDescentOptimizerBasev4TemplateF):
    r"""Proxy of C++ itkGradientDescentOptimizerv4TemplateF class."""

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr

    @staticmethod
    def __New_orig__():
        r"""__New_orig__() -> itkGradientDescentOptimizerv4TemplateF_Pointer"""
        return _itkGradientDescentOptimizerv4Python.itkGradientDescentOptimizerv4TemplateF___New_orig__()

    def Clone(self):
        r"""Clone(self) -> itkGradientDescentOptimizerv4TemplateF_Pointer"""
        return _itkGradientDescentOptimizerv4Python.itkGradientDescentOptimizerv4TemplateF_Clone(self)

    def SetLearningRate(self, _arg):
        r"""
        SetLearningRate(self, _arg)

        Parameters
        ----------
        _arg: float

        """
        return _itkGradientDescentOptimizerv4Python.itkGradientDescentOptimizerv4TemplateF_SetLearningRate(self, _arg)

    def GetLearningRate(self):
        r"""GetLearningRate(self) -> float const &"""
        return _itkGradientDescentOptimizerv4Python.itkGradientDescentOptimizerv4TemplateF_GetLearningRate(self)

    def SetMaximumStepSizeInPhysicalUnits(self, _arg):
        r"""
        SetMaximumStepSizeInPhysicalUnits(self, _arg)

        Parameters
        ----------
        _arg: float

        """
        return _itkGradientDescentOptimizerv4Python.itkGradientDescentOptimizerv4TemplateF_SetMaximumStepSizeInPhysicalUnits(self, _arg)

    def GetMaximumStepSizeInPhysicalUnits(self):
        r"""GetMaximumStepSizeInPhysicalUnits(self) -> float const &"""
        return _itkGradientDescentOptimizerv4Python.itkGradientDescentOptimizerv4TemplateF_GetMaximumStepSizeInPhysicalUnits(self)

    def SetDoEstimateLearningRateAtEachIteration(self, _arg):
        r"""
        SetDoEstimateLearningRateAtEachIteration(self, _arg)

        Parameters
        ----------
        _arg: bool

        """
        return _itkGradientDescentOptimizerv4Python.itkGradientDescentOptimizerv4TemplateF_SetDoEstimateLearningRateAtEachIteration(self, _arg)

    def GetDoEstimateLearningRateAtEachIteration(self):
        r"""GetDoEstimateLearningRateAtEachIteration(self) -> bool const &"""
        return _itkGradientDescentOptimizerv4Python.itkGradientDescentOptimizerv4TemplateF_GetDoEstimateLearningRateAtEachIteration(self)

    def DoEstimateLearningRateAtEachIterationOn(self):
        r"""DoEstimateLearningRateAtEachIterationOn(self)"""
        return _itkGradientDescentOptimizerv4Python.itkGradientDescentOptimizerv4TemplateF_DoEstimateLearningRateAtEachIterationOn(self)

    def DoEstimateLearningRateAtEachIterationOff(self):
        r"""DoEstimateLearningRateAtEachIterationOff(self)"""
        return _itkGradientDescentOptimizerv4Python.itkGradientDescentOptimizerv4TemplateF_DoEstimateLearningRateAtEachIterationOff(self)

    def SetDoEstimateLearningRateOnce(self, _arg):
        r"""
        SetDoEstimateLearningRateOnce(self, _arg)

        Parameters
        ----------
        _arg: bool

        """
        return _itkGradientDescentOptimizerv4Python.itkGradientDescentOptimizerv4TemplateF_SetDoEstimateLearningRateOnce(self, _arg)

    def GetDoEstimateLearningRateOnce(self):
        r"""GetDoEstimateLearningRateOnce(self) -> bool const &"""
        return _itkGradientDescentOptimizerv4Python.itkGradientDescentOptimizerv4TemplateF_GetDoEstimateLearningRateOnce(self)

    def DoEstimateLearningRateOnceOn(self):
        r"""DoEstimateLearningRateOnceOn(self)"""
        return _itkGradientDescentOptimizerv4Python.itkGradientDescentOptimizerv4TemplateF_DoEstimateLearningRateOnceOn(self)

    def DoEstimateLearningRateOnceOff(self):
        r"""DoEstimateLearningRateOnceOff(self)"""
        return _itkGradientDescentOptimizerv4Python.itkGradientDescentOptimizerv4TemplateF_DoEstimateLearningRateOnceOff(self)

    def SetMinimumConvergenceValue(self, _arg):
        r"""
        SetMinimumConvergenceValue(self, _arg)

        Parameters
        ----------
        _arg: float

        """
        return _itkGradientDescentOptimizerv4Python.itkGradientDescentOptimizerv4TemplateF_SetMinimumConvergenceValue(self, _arg)

    def SetConvergenceWindowSize(self, _arg):
        r"""
        SetConvergenceWindowSize(self, _arg)

        Parameters
        ----------
        _arg: unsigned long long

        """
        return _itkGradientDescentOptimizerv4Python.itkGradientDescentOptimizerv4TemplateF_SetConvergenceWindowSize(self, _arg)

    def GetConvergenceValue(self):
        r"""GetConvergenceValue(self) -> float const &"""
        return _itkGradientDescentOptimizerv4Python.itkGradientDescentOptimizerv4TemplateF_GetConvergenceValue(self)

    def SetReturnBestParametersAndValue(self, _arg):
        r"""
        SetReturnBestParametersAndValue(self, _arg)

        Parameters
        ----------
        _arg: bool

        """
        return _itkGradientDescentOptimizerv4Python.itkGradientDescentOptimizerv4TemplateF_SetReturnBestParametersAndValue(self, _arg)

    def GetReturnBestParametersAndValue(self):
        r"""GetReturnBestParametersAndValue(self) -> bool const &"""
        return _itkGradientDescentOptimizerv4Python.itkGradientDescentOptimizerv4TemplateF_GetReturnBestParametersAndValue(self)

    def ReturnBestParametersAndValueOn(self):
        r"""ReturnBestParametersAndValueOn(self)"""
        return _itkGradientDescentOptimizerv4Python.itkGradientDescentOptimizerv4TemplateF_ReturnBestParametersAndValueOn(self)

    def ReturnBestParametersAndValueOff(self):
        r"""ReturnBestParametersAndValueOff(self)"""
        return _itkGradientDescentOptimizerv4Python.itkGradientDescentOptimizerv4TemplateF_ReturnBestParametersAndValueOff(self)

    def StartOptimization(self, doOnlyInitialization=False):
        r"""
        StartOptimization(self, doOnlyInitialization=False)

        Parameters
        ----------
        doOnlyInitialization: bool

        """
        return _itkGradientDescentOptimizerv4Python.itkGradientDescentOptimizerv4TemplateF_StartOptimization(self, doOnlyInitialization)

    def EstimateLearningRate(self):
        r"""EstimateLearningRate(self)"""
        return _itkGradientDescentOptimizerv4Python.itkGradientDescentOptimizerv4TemplateF_EstimateLearningRate(self)
    __swig_destroy__ = _itkGradientDescentOptimizerv4Python.delete_itkGradientDescentOptimizerv4TemplateF

    @staticmethod
    def cast(obj):
        r"""
        cast(obj) -> itkGradientDescentOptimizerv4TemplateF

        Parameters
        ----------
        obj: itkLightObject *

        """
        return _itkGradientDescentOptimizerv4Python.itkGradientDescentOptimizerv4TemplateF_cast(obj)

    def New(*args, **kargs):
        """New() -> itkGradientDescentOptimizerv4TemplateF

        Create a new object of the class itkGradientDescentOptimizerv4TemplateF and set the input and the parameters if some
        named or non-named arguments are passed to that method.

        New() tries to assign all the non named parameters to the input of the new objects - the
        first non named parameter in the first input, etc.

        The named parameters are used by calling the method with the same name prefixed by 'Set'.

        Ex:

          itkGradientDescentOptimizerv4TemplateF.New(reader, threshold=10)

        is (most of the time) equivalent to:

          obj = itkGradientDescentOptimizerv4TemplateF.New()
          obj.SetInput(0, reader.GetOutput())
          obj.SetThreshold(10)
        """
        obj = itkGradientDescentOptimizerv4TemplateF.__New_orig__()
        from itk.support import template_class
        template_class.New(obj, *args, **kargs)
        return obj
    New = staticmethod(New)


# Register itkGradientDescentOptimizerv4TemplateF in _itkGradientDescentOptimizerv4Python:
_itkGradientDescentOptimizerv4Python.itkGradientDescentOptimizerv4TemplateF_swigregister(itkGradientDescentOptimizerv4TemplateF)

