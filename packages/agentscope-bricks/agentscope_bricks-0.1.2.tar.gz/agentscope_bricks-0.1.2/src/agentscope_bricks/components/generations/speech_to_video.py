# -*- coding: utf-8 -*-
import asyncio
import os
import time
import uuid
from http import HTTPStatus
from typing import Any, Optional

from dashscope.client.base_api import BaseAsyncAioApi
from mcp.server.fastmcp import Context
from pydantic import BaseModel, Field

from agentscope_bricks.base.component import Component
from agentscope_bricks.utils.tracing_utils.wrapper import trace
from agentscope_bricks.utils.api_key_util import ApiNames, get_api_key
from agentscope_bricks.utils.mcp_util import MCPUtil


class SpeechToVideoInput(BaseModel):
    """
    Speech to video generation input model
    """

    image_url: str = Field(
        ...,
        description="ä¸Šä¼ çš„å›¾ç‰‡URLã€‚å›¾åƒæ ¼å¼ï¼šæ”¯æŒjpgï¼Œjpegï¼Œpngï¼Œbmpï¼Œwebpã€‚"
        "å›¾åƒåˆ†è¾¨ç‡ï¼šå›¾åƒçš„å®½åº¦å’Œé«˜åº¦èŒƒå›´ä¸º[400, 7000]åƒç´ ã€‚"
        "ä¸Šä¼ å›¾ç‰‡ä»…æ”¯æŒå…¬ç½‘å¯è®¿é—®çš„HTTP/HTTPSé“¾æ¥ã€‚",
    )
    audio_url: str = Field(
        ...,
        description="ä¸Šä¼ çš„éŸ³é¢‘æ–‡ä»¶URLã€‚éŸ³é¢‘æ ¼å¼ï¼šæ ¼å¼ä¸ºwavã€mp3ã€‚"
        "éŸ³é¢‘é™åˆ¶ï¼šæ–‡ä»¶<15Mï¼Œæ—¶é•¿ï¼œ20sã€‚"
        "éŸ³é¢‘å†…å®¹ï¼šéŸ³é¢‘ä¸­éœ€åŒ…å«æ¸…æ™°ã€å“äº®çš„äººå£°è¯­éŸ³ï¼Œå¹¶å»é™¤äº†ç¯å¢ƒå™ªéŸ³ã€"
        "èƒŒæ™¯éŸ³ä¹ç­‰å£°éŸ³å¹²æ‰°ä¿¡æ¯ã€‚ä¸Šä¼ éŸ³é¢‘ä»…æ”¯æŒå…¬ç½‘å¯è®¿é—®çš„HTTP/HTTPSé“¾æ¥ã€‚",
    )
    resolution: Optional[str] = Field(
        default=None,
        description="è§†é¢‘åˆ†è¾¨ç‡ï¼Œé»˜è®¤ä¸è®¾ç½®",
    )
    ctx: Optional[Context] = Field(
        default=None,
        description="HTTP request context containing headers for mcp only, "
        "don't generate it",
    )


class SpeechToVideoOutput(BaseModel):
    """
    Speech to video generation output model
    """

    video_url: str = Field(
        title="Video URL",
        description="ç”Ÿæˆçš„è§†é¢‘æ–‡ä»¶URL",
    )
    request_id: Optional[str] = Field(
        default=None,
        title="Request ID",
        description="è¯·æ±‚ID",
    )
    video_duration: Optional[float] = Field(
        default=None,
        title="Video Duration",
        description="è§†é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰ï¼Œç”¨äºè®¡è´¹",
    )


class SpeechToVideo(Component[SpeechToVideoInput, SpeechToVideoOutput]):
    """
    Speech to video generation service that converts speech and image into
     videos using DashScope's wan2.2-s2v API.
    """

    name: str = "modelstudio_speech_to_video"
    description: str = (
        "æ•°å­—äººwan2.2-s2væ¨¡å‹èƒ½åŸºäºå•å¼ å›¾ç‰‡å’ŒéŸ³é¢‘ï¼Œç”ŸæˆåŠ¨ä½œè‡ªç„¶çš„è¯´è¯ã€å”±æ­Œæˆ–è¡¨æ¼”è§†é¢‘ã€‚"
        "é€šè¿‡è¾“å…¥çš„äººå£°éŸ³é¢‘ï¼Œé©±åŠ¨é™æ€å›¾ç‰‡ä¸­çš„äººç‰©å®ç°å£å‹ã€è¡¨æƒ…å’ŒåŠ¨ä½œä¸éŸ³é¢‘åŒæ­¥ã€‚"
        "æ”¯æŒè¯´è¯ã€å”±æ­Œã€è¡¨æ¼”ä¸‰ç§å¯¹å£å‹åœºæ™¯ï¼Œæ”¯æŒçœŸäººåŠå¡é€šäººç‰©ï¼Œ"
        "æä¾›480Pã€720Pä¸¤æ¡£åˆ†è¾¨ç‡é€‰é¡¹ã€‚"
    )

    @staticmethod
    async def _async_call(
        model: str,
        api_key: str,
        image_url: str,
        audio_url: str,
        **parameters: Any,
    ) -> Any:
        """
        Submit async task for speech to video generation using BaseAsyncAioApi

        Args:
            model: Model name to use
            api_key: DashScope API key for authentication
            image_url: URL of the input image
            audio_url: URL of the input audio
            **parameters: Additional parameters like resolution

        Returns:
            Response containing task_id for polling
        """
        # Prepare input data
        input = {
            "image_url": image_url,
            "audio_url": audio_url,
        }

        result = await BaseAsyncAioApi.async_call(
            model=model,
            input=input,
            task_group="aigc",
            task="image2video",
            function="video-synthesis",
            api_key=api_key,
            **parameters,
        )

        return result

    @staticmethod
    async def _fetch(
        api_key: str,
        task: Any,
    ) -> Any:
        """
        Fetch task result using BaseAsyncAioApi

        Args:
            api_key: DashScope API key for authentication
            task: Task response containing task_id

        Returns:
            Response containing task status and result
        """
        # Use BaseAsyncAioApi.fetch directly with await
        result = await BaseAsyncAioApi.fetch(
            api_key=api_key,
            task=task,
        )

        return result

    @trace(trace_type="AIGC", trace_name="speech_to_video")
    async def arun(
        self,
        args: SpeechToVideoInput,
        **kwargs: Any,
    ) -> SpeechToVideoOutput:
        """
        Generate video from speech and image using DashScope wan2.2-s2v API

        This method wraps DashScope's wan2.2-s2v service to generate videos
        based on input image and audio. It uses async call pattern for better
        performance and supports polling for task completion.

        Args:
            args: SpeechToVideoInput containing image_url, audio_url and
                  optional parameters
            **kwargs: Additional keyword arguments including:
                - request_id: Optional request ID for tracking
                - model_name: Model name to use (defaults to wan2.2-s2v)
                - api_key: DashScope API key for authentication

        Returns:
            SpeechToVideoOutput containing the generated video URL,
            request ID and video duration

        Raises:
            ValueError: If DASHSCOPE_API_KEY is not set or invalid
            TimeoutError: If video generation takes too long
            RuntimeError: If video generation fails
        """
        trace_event = kwargs.pop("trace_event", None)
        request_id = MCPUtil._get_mcp_dash_request_id(args.ctx)

        try:
            api_key = get_api_key(ApiNames.dashscope_api_key, **kwargs)
        except AssertionError:
            raise ValueError("Please set valid DASHSCOPE_API_KEY!")

        model_name = kwargs.get(
            "model_name",
            os.getenv("SPEECH_TO_VIDEO_MODEL_NAME", "wan2.2-s2v"),
        )

        parameters = {}
        if args.resolution:
            parameters["resolution"] = args.resolution

        # Submit async task
        task_response = await self._async_call(
            model=model_name,
            api_key=api_key,
            image_url=args.image_url,
            audio_url=args.audio_url,
            **parameters,
        )

        # Poll for task completion using async methods
        max_wait_time = 600  # 10 minutes timeout for video generation
        poll_interval = 5  # 5 seconds polling interval
        start_time = time.time()

        while True:
            # Wait before polling
            await asyncio.sleep(poll_interval)

            # Fetch task result using async method
            res = await self._fetch(
                api_key=api_key,
                task=task_response,
            )

            # Check task completion status
            if res.status_code == HTTPStatus.OK:
                # res.output is a dict when using BaseAsyncAioApi
                if (
                    isinstance(res.output, dict)
                    and "task_status" in res.output
                ):
                    if res.output["task_status"] == "SUCCEEDED":
                        break
                    elif res.output["task_status"] in ["FAILED", "CANCELED"]:
                        print(f"error response: {res}")
                        raise RuntimeError(
                            f"Video generation failed: task_status="
                            f"{res.output['task_status']}, response={res}",
                        )
                    # Continue polling for PENDING, RUNNING, etc.
                else:
                    # If no task_status field, assume completed
                    break

            # Check timeout
            if time.time() - start_time > max_wait_time:
                raise TimeoutError(
                    f"Video generation timeout after {max_wait_time}s",
                )

        # Handle request ID
        if not request_id:
            request_id = (
                res.request_id if res.request_id else str(uuid.uuid4())
            )

        # Log trace event if provided
        if trace_event:
            trace_event.on_log(
                "",
                **{
                    "step_suffix": "results",
                    "payload": {
                        "request_id": request_id,
                        "speech_to_video_result": res,
                    },
                },
            )

        # Extract video URL and duration from response
        if res.status_code == HTTPStatus.OK:
            # Handle results as dict (BaseAsyncAioApi response format)
            if isinstance(res.output, dict) and "results" in res.output:
                results = res.output["results"]
                if isinstance(results, dict):
                    video_url = results.get("video_url")
                else:
                    video_url = getattr(results, "video_url", None)
            else:
                raise RuntimeError(
                    f"No results found in response: {res.output}",
                )

            # Extract video duration from usage
            video_duration = None
            if hasattr(res, "usage") and res.usage:
                if isinstance(res.usage, dict):
                    video_duration = res.usage.get("duration")
                else:
                    video_duration = getattr(res.usage, "duration", None)

            if not video_url:
                raise RuntimeError(
                    f"Failed to extract video URL from response: {res}",
                )

            return SpeechToVideoOutput(
                video_url=video_url,
                request_id=request_id,
                video_duration=video_duration,
            )
        else:
            raise RuntimeError(f"Failed to get video URL: {res.message}")


if __name__ == "__main__":
    speech_to_video = SpeechToVideo()

    async def main() -> None:
        import time

        image_url = (
            "https://img.alicdn.com/imgextra/i3/O1CN011FObkp1T7Ttow"
            "oq4F_!!6000000002335-0-tps-1440-1797.jpg"
        )

        audio_url = (
            "https://help-static-aliyun-doc.aliyuncs.com/"
            "file-manage-files/zh-CN/20250825/iaqpio/input_audio.MP3"
        )

        test_inputs = [
            SpeechToVideoInput(
                image_url=image_url,
                audio_url=audio_url,
                resolution="480P",
            ),
            SpeechToVideoInput(
                image_url=image_url,
                audio_url=audio_url,
                resolution="720P",
            ),
        ]

        start_time = time.time()

        try:
            # Execute concurrent calls using asyncio.gather
            tasks = [
                speech_to_video.arun(test_input, model_name="wan2.2-s2v")
                for test_input in test_inputs
            ]

            results = await asyncio.gather(*tasks, return_exceptions=True)

            end_time = time.time()
            total_time = end_time - start_time

            print(f"\nå¹¶å‘æ‰§è¡Œå®Œæˆï¼Œè€—æ—¶ {total_time:.2f}ç§’")
            print("=" * 60)

            # Process and display results
            for i, result in enumerate(results, 1):
                print(f"\nğŸ¬ ä»»åŠ¡ {i} ç»“æœ:")
                if isinstance(result, Exception):
                    print(f"   âŒ é”™è¯¯: {str(result)}")
                else:
                    print("   âœ… æˆåŠŸ:")
                    print(f"   ğŸ”— è§†é¢‘URL: {result.video_url}")
                    print(f"   ğŸ†” è¯·æ±‚ID: {result.request_id}")
                    if result.video_duration:
                        print(f"   â±ï¸ è§†é¢‘æ—¶é•¿: {result.video_duration}ç§’")
                print("-" * 40)

        except Exception as e:
            print(f"âŒ å¹¶å‘æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿæ„å¤–é”™è¯¯: {str(e)}")

    asyncio.run(main())
