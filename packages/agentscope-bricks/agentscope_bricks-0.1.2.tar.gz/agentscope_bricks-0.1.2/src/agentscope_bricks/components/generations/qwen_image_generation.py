# -*- coding: utf-8 -*-
import asyncio
import os
import uuid
from distutils.util import strtobool
from typing import Any, Optional

from dashscope import AioMultiModalConversation
from mcp.server.fastmcp import Context
from pydantic import BaseModel, Field

from agentscope_bricks.base.component import Component
from agentscope_bricks.utils.tracing_utils import TraceType
from agentscope_bricks.utils.tracing_utils import trace
from agentscope_bricks.utils.api_key_util import ApiNames, get_api_key
from agentscope_bricks.utils.mcp_util import MCPUtil


class QwenImageGenInput(BaseModel):
    """
    Qwen Image Edit Input
    """

    prompt: str = Field(
        ...,
        description="æ­£å‘æç¤ºè¯ï¼Œç”¨æ¥æè¿°ç”Ÿæˆå›¾åƒä¸­æœŸæœ›åŒ…å«çš„å…ƒç´ å’Œè§†è§‰ç‰¹ç‚¹, è¶…è¿‡800ä¸ªå­—ç¬¦è‡ªåŠ¨æˆªæ–­",
    )
    negative_prompt: Optional[str] = Field(
        default=None,
        description="åå‘æç¤ºè¯ï¼Œç”¨æ¥æè¿°ä¸å¸Œæœ›åœ¨ç”»é¢ä¸­çœ‹åˆ°çš„å†…å®¹ï¼Œå¯ä»¥å¯¹ç”»é¢è¿›è¡Œé™åˆ¶ï¼Œè¶…è¿‡500ä¸ªå­—ç¬¦è‡ªåŠ¨æˆªæ–­",
    )
    size: str = Field(
        default=None,
        description="è¾“å‡ºå›¾åƒçš„åˆ†è¾¨ç‡ï¼Œæ ¼å¼ä¸ºå®½*é«˜ã€‚é»˜è®¤åˆ†è¾¨ç‡ä¸º1328*1328",
    )
    n: int = Field(
        default=None,
        description="ç”Ÿæˆå›¾ç‰‡çš„æ•°é‡ã€‚é»˜è®¤å€¼ä¸º1ã€‚",
    )
    prompt_extend: Optional[bool] = Field(
        default=None,
        description="æ˜¯å¦å¼€å¯promptæ™ºèƒ½æ”¹å†™ï¼Œå¼€å¯åä½¿ç”¨å¤§æ¨¡å‹å¯¹è¾“å…¥promptè¿›è¡Œæ™ºèƒ½æ”¹å†™",
    )
    ctx: Optional[Context] = Field(
        default=None,
        description="HTTP request context containing headers for mcp only, "
        "don't generate it",
    )


class QwenImageGenOutput(BaseModel):
    """
    Qwen Image Edit Output
    """

    results: list[str] = Field(
        title="Results",
        description="è¾“å‡ºçš„å›¾ç‰‡urlåˆ—è¡¨",
    )
    request_id: Optional[str] = Field(
        default=None,
        title="Request ID",
        description="è¯·æ±‚ID",
    )


class QwenImageGen(Component[QwenImageGenInput, QwenImageGenOutput]):
    """
    Qwen Image Generation Component for AI-powered image editing.
    """

    name: str = "modelstudio_qwen_image_gen"
    description: str = (
        "é€šä¹‰åƒé—®-æ–‡ç”Ÿå›¾æ¨¡å‹æ˜¯ä¸€æ¬¾é€šç”¨å›¾åƒç”Ÿæˆæ¨¡å‹ï¼Œæ”¯æŒå¤šç§è‰ºæœ¯é£æ ¼ï¼Œå°¤å…¶æ“…é•¿å¤æ‚æ–‡æœ¬æ¸²æŸ“ï¼Œç‰¹åˆ«æ˜¯ä¸­è‹±æ–‡æ–‡æœ¬æ¸²æŸ“ã€‚"
    )

    @trace(trace_type=TraceType.AIGC, trace_name="qwen_image_gen")
    async def arun(
        self,
        args: QwenImageGenInput,
        **kwargs: Any,
    ) -> QwenImageGenOutput:
        """Qwen Image Edit using MultiModalConversation API

        This method uses DashScope's MultiModalConversation service to edit
        images based on text prompts. The API supports various image editing
        operations through natural language instructions.

        Args:
            args: QwenImageGenInput containing text_prompt,
                watermark, and negative_prompt.
            **kwargs: Additional keyword arguments including request_id,
                trace_event, model_name, api_key.

        Returns:
            QwenImageEditOutput containing the edited image URL and request ID.

        Raises:
            ValueError: If DASHSCOPE_API_KEY is not set or invalid.
            RuntimeError: If the API call fails or returns an error.
        """

        trace_event = kwargs.pop("trace_event", None)
        request_id = MCPUtil._get_mcp_dash_request_id(args.ctx)

        try:
            api_key = get_api_key(ApiNames.dashscope_api_key, **kwargs)
        except AssertionError:
            raise ValueError("Please set valid DASHSCOPE_API_KEY!")

        model_name = kwargs.get(
            "model_name",
            os.getenv("QWEN_IMAGE_GENERATION_MODEL_NAME", "qwen-image"),
        )
        watermark_env = os.getenv("QWEN_IMAGE_GENERATION_ENABLE_WATERMARK")
        if watermark_env is not None:
            watermark = strtobool(watermark_env)
        else:
            watermark = kwargs.pop("watermark", True)

        # Prepare messages in the format expected by MultiModalConversation
        messages = [
            {
                "role": "user",
                "content": [
                    {"text": args.prompt},
                ],
            },
        ]

        parameters = {}
        if args.negative_prompt:
            parameters["negative_prompt"] = args.negative_prompt
        if args.size:
            parameters["size"] = args.size
        if args.n is not None:
            parameters["n"] = args.n
        if args.prompt_extend is not None:
            parameters["prompt_extend"] = args.prompt_extend
        if watermark is not None:
            parameters["watermark"] = watermark

        # Call the AioMultiModalConversation API asynchronously
        try:
            response = await AioMultiModalConversation.call(
                api_key=api_key,
                model=model_name,
                messages=messages,
                **parameters,
            )
        except Exception as e:
            raise RuntimeError(f"Failed to call Qwen Image Edit API: {str(e)}")

        # Check response status
        if response.status_code != 200:
            error_msg = (
                f"HTTP status code: {response.status_code}, "
                f"Error code: {getattr(response, 'code', 'Unknown')}, "
                f"Error message:"
                f" {getattr(response, 'message', 'Unknown error')}"
            )
            raise RuntimeError(f"Qwen Image Edit API error: {error_msg}")

        # Extract the edited image URLs from response
        try:
            # The response structure may vary, try different possible locations
            results = []

            # Try to get from output.choices[0].message.content
            if hasattr(response, "output") and response.output:
                choices = getattr(response.output, "choices", [])
                if choices:
                    message = getattr(choices[0], "message", {})
                    if hasattr(message, "content"):
                        content = message.content
                        if isinstance(content, list):
                            # Look for image content in the list
                            for item in content:
                                if isinstance(item, dict) and "image" in item:
                                    results.append(item["image"])
                        elif isinstance(content, str):
                            results.append(content)
                        elif isinstance(content, dict) and "image" in content:
                            results.append(content["image"])

            if not results:
                raise RuntimeError(
                    f"Could not extract edited image URLs from response: "
                    f"{response}",
                )

        except Exception as e:
            raise RuntimeError(
                f"Failed to parse response from Qwen Image Edit API: {str(e)}",
            )

        # Get request ID
        if request_id == "":
            request_id = getattr(response, "request_id", None) or str(
                uuid.uuid4(),
            )

        # Log trace event if provided
        if trace_event:
            trace_event.on_log(
                "",
                **{
                    "step_suffix": "results",
                    "payload": {
                        "request_id": request_id,
                        "qwen_image_edit_result": {
                            "status_code": response.status_code,
                            "results": results,
                        },
                    },
                },
            )

        return QwenImageGenOutput(
            results=results,
            request_id=request_id,
        )


if __name__ == "__main__":
    qwen_image_gen = QwenImageGen()

    async def main() -> None:
        import time

        test_inputs = [
            QwenImageGenInput(
                prompt="æ²™æ»©ä¸Šå°ç”·å­©å’Œä¸€åªé‡‘æ¯›å¹¶æ’åç€",
                negative_prompt="",
            ),
            QwenImageGenInput(
                prompt="æ²™æ»©ä¸Šå°å¥³å­©å’Œä¸€åªæŸ¯åŸºå¹¶æ’åç€",
            ),
        ]

        start_time = time.time()

        try:
            tasks = [
                qwen_image_gen.arun(test_input) for test_input in test_inputs
            ]

            results = await asyncio.gather(*tasks, return_exceptions=True)

            end_time = time.time()
            total_time = end_time - start_time

            print(f"\nAll calls completed in {total_time:.2f} seconds")
            print("=" * 60)

            # Process and display results
            for i, result in enumerate(results, 1):
                print(f" ğŸ†” Request ID: {result.request_id}")
                print(f"\nğŸ“ Call {i} Result:")
                if isinstance(result, Exception):
                    print(f"   âŒ Error: {str(result)}")
                else:
                    print(f"   ğŸ”— Results: {result.results}")
                print("-" * 40)

        except Exception as e:
            print(f"âŒ Unexpected error during concurrent execution: {str(e)}")

    asyncio.run(main())
