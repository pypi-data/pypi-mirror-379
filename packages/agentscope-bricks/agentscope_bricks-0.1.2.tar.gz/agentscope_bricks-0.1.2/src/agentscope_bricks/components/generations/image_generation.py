# -*- coding: utf-8 -*-
import asyncio
import os
import time
import uuid
from distutils.util import strtobool
from http import HTTPStatus
from typing import Any, Optional

from dashscope.aigc.image_synthesis import AioImageSynthesis
from mcp.server.fastmcp import Context
from pydantic import BaseModel, Field

from agentscope_bricks.base.component import Component
from agentscope_bricks.utils.tracing_utils.wrapper import trace

from agentscope_bricks.utils.api_key_util import ApiNames, get_api_key
from agentscope_bricks.utils.mcp_util import MCPUtil


class ImageGenInput(BaseModel):
    """
    æ–‡ç”Ÿå›¾Input
    """

    prompt: str = Field(
        ...,
        description="æ­£å‘æç¤ºè¯ï¼Œç”¨æ¥æè¿°ç”Ÿæˆå›¾åƒä¸­æœŸæœ›åŒ…å«çš„å…ƒç´ å’Œè§†è§‰ç‰¹ç‚¹,è¶…è¿‡800è‡ªåŠ¨æˆªæ–­",
    )
    size: Optional[str] = Field(
        default=None,
        description="è¾“å‡ºå›¾åƒçš„åˆ†è¾¨çŽ‡ã€‚é»˜è®¤å€¼æ˜¯1024*1024 æœ€é«˜å¯è¾¾200ä¸‡åƒç´ ",
    )
    negative_prompt: Optional[str] = Field(
        default=None,
        description="åå‘æç¤ºè¯ï¼Œç”¨æ¥æè¿°ä¸å¸Œæœ›åœ¨ç”»é¢ä¸­çœ‹åˆ°çš„å†…å®¹ï¼Œå¯ä»¥å¯¹ç”»é¢è¿›è¡Œé™åˆ¶ï¼Œè¶…è¿‡500ä¸ªå­—ç¬¦è‡ªåŠ¨æˆªæ–­",
    )
    prompt_extend: Optional[bool] = Field(
        default=None,
        description="æ˜¯å¦å¼€å¯promptæ™ºèƒ½æ”¹å†™ï¼Œå¼€å¯åŽä½¿ç”¨å¤§æ¨¡åž‹å¯¹è¾“å…¥promptè¿›è¡Œæ™ºèƒ½æ”¹å†™",
    )
    n: Optional[int] = Field(
        default=1,
        description="ç”Ÿæˆå›¾ç‰‡çš„æ•°é‡ã€‚å–å€¼èŒƒå›´ä¸º1~4å¼  é»˜è®¤1",
    )
    ctx: Optional[Context] = Field(
        default=None,
        description="HTTP request context containing headers for mcp only, "
        "don't generate it",
    )


class ImageGenOutput(BaseModel):
    """
    æ–‡ç”Ÿå›¾ Output.
    """

    results: list[str] = Field(title="Results", description="è¾“å‡ºå›¾ç‰‡url åˆ—è¡¨")
    request_id: Optional[str] = Field(
        default=None,
        title="Request ID",
        description="è¯·æ±‚ID",
    )


class ImageGeneration(Component[ImageGenInput, ImageGenOutput]):
    """
    æ–‡ç”Ÿå›¾è°ƒç”¨.
    """

    name: str = "modelstudio_image_gen"
    description: str = (
        "AIç»˜ç”»ï¼ˆå›¾åƒç”Ÿæˆï¼‰æœåŠ¡ï¼Œè¾“å…¥æ–‡æœ¬æè¿°å’Œå›¾åƒåˆ†è¾¨çŽ‡ï¼Œè¿”å›žæ ¹æ®æ–‡æœ¬ä¿¡æ¯ç»˜åˆ¶çš„å›¾ç‰‡URLã€‚"
    )

    @trace(trace_type="AIGC", trace_name="image_generation")
    async def arun(self, args: ImageGenInput, **kwargs: Any) -> ImageGenOutput:
        """Modelstudio Images generation from text prompts

        This method wrap DashScope's ImageSynthesis service to generate images
        based on text descriptions. It supports various image sizes and can
        generate multiple images in a single request.

        Args:
            args: ImageGenInput containing the prompt, size, and number of
                images to generate.
            **kwargs: Additional keyword arguments including:
                - request_id: Optional request ID for tracking
                - trace_event: Optional trace event for logging
                - model_name: Model name to use (defaults to wan2.2-t2i-flash)
                - api_key: DashScope API key for authentication

        Returns:
            ImageGenOutput containing the list of generated image URLs and
            request ID.

        Raises:
            ValueError: If DASHSCOPE_API_KEY is not set or invalid.
        """

        trace_event = kwargs.pop("trace_event", None)
        request_id = MCPUtil._get_mcp_dash_request_id(args.ctx)

        try:
            api_key = get_api_key(ApiNames.dashscope_api_key, **kwargs)
        except AssertionError:
            raise ValueError("Please set valid DASHSCOPE_API_KEY!")

        model_name = kwargs.get(
            "model_name",
            os.getenv("IMAGE_GENERATION_MODEL_NAME", "wan2.2-t2i-flash"),
        )
        watermark_env = os.getenv("IMAGE_GENERATION_ENABLE_WATERMARK")
        if watermark_env is not None:
            watermark = strtobool(watermark_env)
        else:
            watermark = kwargs.pop("watermark", True)
        # ðŸ”„ ä½¿ç”¨DashScopeçš„å¼‚æ­¥ä»»åŠ¡APIå®žçŽ°çœŸæ­£çš„å¹¶å‘
        # 1. æäº¤å¼‚æ­¥ä»»åŠ¡

        parameters = {}
        if args.size:
            parameters["size"] = args.size
        if args.prompt_extend is not None:
            parameters["prompt_extend"] = args.prompt_extend
        if args.n is not None:
            parameters["n"] = args.n
        if watermark is not None:
            parameters["watermark"] = watermark

        task_response = await AioImageSynthesis.async_call(
            model=model_name,
            api_key=api_key,
            prompt=args.prompt,
            negative_prompt=args.negative_prompt,
            **parameters,
        )

        # 2. å¾ªçŽ¯å¼‚æ­¥æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€
        max_wait_time = 300  # 5åˆ†é’Ÿè¶…æ—¶
        poll_interval = 2  # 2ç§’è½®è¯¢é—´éš”
        start_time = time.time()

        while True:
            # å¼‚æ­¥ç­‰å¾…
            await asyncio.sleep(poll_interval)

            # æŸ¥è¯¢ä»»åŠ¡ç»“æžœ
            res = await AioImageSynthesis.fetch(
                api_key=api_key,
                task=task_response,
            )

            # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å®Œæˆ
            if res.status_code == HTTPStatus.OK:
                if hasattr(res.output, "task_status"):
                    if res.output.task_status == "SUCCEEDED":
                        break
                    elif res.output.task_status in ["FAILED", "CANCELED"]:
                        raise RuntimeError(
                            f"Image generation failed: "
                            f"{res.output.task_status}",
                        )
                else:
                    # å¦‚æžœæ²¡æœ‰task_statuså­—æ®µï¼Œè®¤ä¸ºå·²å®Œæˆ
                    break

            # è¶…æ—¶æ£€æŸ¥
            if time.time() - start_time > max_wait_time:
                raise TimeoutError(
                    f"Image generation timeout after {max_wait_time}s",
                )

        if request_id == "":
            request_id = (
                res.request_id if res.request_id else str(uuid.uuid4())
            )

        if trace_event:
            trace_event.on_log(
                "",
                **{
                    "step_suffix": "results",
                    "payload": {
                        "request_id": request_id,
                        "image_query_result": res,
                    },
                },
            )
        results = []
        if res.status_code == HTTPStatus.OK:
            for result in res.output.results:
                results.append(result.url)
        return ImageGenOutput(results=results, request_id=request_id)


if __name__ == "__main__":

    image_generation = ImageGeneration()

    image_gent_input = ImageGenInput(
        prompt="å¸®æˆ‘ç”»ä¸€ä¸ªå›½å®ç†ŠçŒ«,",
    )

    async def main() -> None:
        image_gent_output = await image_generation.arun(
            image_gent_input,
            model_name="qwen-image",
        )
        print(image_gent_output)
        print(image_generation.function_schema.model_dump())

    asyncio.run(main())
