# -*- coding: utf-8 -*-
import asyncio
import os
import uuid
from http import HTTPStatus
from typing import Any, Optional

from dashscope.client.base_api import BaseAsyncAioApi
from mcp.server.fastmcp import Context
from pydantic import BaseModel, Field

from agentscope_bricks.base.component import Component
from agentscope_bricks.utils.tracing_utils.wrapper import trace
from agentscope_bricks.utils.api_key_util import ApiNames, get_api_key
from agentscope_bricks.utils.mcp_util import MCPUtil


class SpeechToVideoSubmitInput(BaseModel):
    """
    Speech to video generation input model
    """

    image_url: str = Field(
        ...,
        description="ä¸Šä¼ çš„å›¾ç‰‡URLã€‚å›¾åƒæ ¼å¼ï¼šæ”¯æŒjpgï¼Œjpegï¼Œpngï¼Œbmpï¼Œwebpã€‚"
        "å›¾åƒåˆ†è¾¨ç‡ï¼šå›¾åƒçš„å®½åº¦å’Œé«˜åº¦èŒƒå›´ä¸º[400, 7000]åƒç´ ã€‚"
        "ä¸Šä¼ å›¾ç‰‡ä»…æ”¯æŒå…¬ç½‘å¯è®¿é—®çš„HTTP/HTTPSé“¾æ¥ã€‚",
    )
    audio_url: str = Field(
        ...,
        description="ä¸Šä¼ çš„éŸ³é¢‘æ–‡ä»¶URLã€‚éŸ³é¢‘æ ¼å¼ï¼šæ ¼å¼ä¸ºwavã€mp3ã€‚"
        "éŸ³é¢‘é™åˆ¶ï¼šæ–‡ä»¶<15Mï¼Œæ—¶é•¿ï¼œ20sã€‚"
        "éŸ³é¢‘å†…å®¹ï¼šéŸ³é¢‘ä¸­éœ€åŒ…å«æ¸…æ™°ã€å“äº®çš„äººå£°è¯­éŸ³ï¼Œå¹¶å»é™¤äº†ç¯å¢ƒå™ªéŸ³ã€"
        "èƒŒæ™¯éŸ³ä¹ç­‰å£°éŸ³å¹²æ‰°ä¿¡æ¯ã€‚ä¸Šä¼ éŸ³é¢‘ä»…æ”¯æŒå…¬ç½‘å¯è®¿é—®çš„HTTP/HTTPSé“¾æ¥ã€‚",
    )
    resolution: Optional[str] = Field(
        default=None,
        description="è§†é¢‘åˆ†è¾¨ç‡ï¼Œé»˜è®¤ä¸è®¾ç½®",
    )
    ctx: Optional[Context] = Field(
        default=None,
        description="HTTP request context containing headers for mcp only, "
        "don't generate it",
    )


class SpeechToVideoSubmitOutput(BaseModel):
    """
    Speech to video generation output model
    """

    task_id: str = Field(
        title="Task ID",
        description="è¯­éŸ³ç”Ÿæˆè§†é¢‘çš„ä»»åŠ¡ID",
    )

    task_status: str = Field(
        title="Task Status",
        description="è¯­éŸ³ç”Ÿæˆè§†é¢‘çš„ä»»åŠ¡çŠ¶æ€ï¼ŒPENDINGï¼šä»»åŠ¡æ’é˜Ÿä¸­ï¼ŒRUNNINGï¼šä»»åŠ¡å¤„ç†ä¸­ï¼Œ"
        "SUCCEEDEDï¼šä»»åŠ¡æ‰§è¡ŒæˆåŠŸï¼ŒFAILEDï¼šä»»åŠ¡æ‰§è¡Œå¤±è´¥ï¼ŒCANCELEDï¼šä»»åŠ¡å–æ¶ˆæˆåŠŸï¼Œ"
        "UNKNOWNï¼šä»»åŠ¡ä¸å­˜åœ¨æˆ–çŠ¶æ€æœªçŸ¥",
    )

    request_id: Optional[str] = Field(
        default=None,
        title="Request ID",
        description="è¯·æ±‚ID",
    )


class SpeechToVideoSubmit(
    Component[SpeechToVideoSubmitInput, SpeechToVideoSubmitOutput],
):
    """
    Speech to video generation service that converts speech and image into
    videos using DashScope's wan2.2-s2v API.
    """

    name: str = "modelstudio_speech_to_video_submit_task"
    description: str = (
        "æ•°å­—äººwan2.2-s2væ¨¡å‹çš„å¼‚æ­¥ä»»åŠ¡æäº¤å·¥å…·ã€‚èƒ½åŸºäºå•å¼ å›¾ç‰‡å’ŒéŸ³é¢‘ï¼Œç”ŸæˆåŠ¨ä½œè‡ªç„¶çš„è¯´è¯ã€"
        "å”±æ­Œæˆ–è¡¨æ¼”è§†é¢‘ã€‚é€šè¿‡è¾“å…¥çš„äººå£°éŸ³é¢‘ï¼Œé©±åŠ¨é™æ€å›¾ç‰‡ä¸­çš„äººç‰©å®ç°å£å‹ã€è¡¨æƒ…å’ŒåŠ¨ä½œä¸éŸ³é¢‘åŒæ­¥ã€‚"
        "æ”¯æŒè¯´è¯ã€å”±æ­Œã€è¡¨æ¼”ä¸‰ç§å¯¹å£å‹åœºæ™¯ï¼Œæ”¯æŒçœŸäººåŠå¡é€šäººç‰©ï¼Œæä¾›480Pã€720Pä¸¤æ¡£åˆ†è¾¨ç‡é€‰é¡¹ã€‚"
    )

    @staticmethod
    async def _async_call(
        model: str,
        api_key: str,
        image_url: str,
        audio_url: str,
        **parameters: Any,
    ) -> Any:
        """
        Submit async task for speech to video generation using BaseAsyncAioApi

        Args:
            model: Model name to use
            api_key: DashScope API key for authentication
            image_url: URL of the input image
            audio_url: URL of the input audio
            **parameters: Additional parameters like resolution

        Returns:
            Response containing task_id for polling
        """
        # Prepare input data
        input = {
            "image_url": image_url,
            "audio_url": audio_url,
        }

        result = await BaseAsyncAioApi.async_call(
            model=model,
            input=input,
            task_group="aigc",
            task="image2video",
            function="video-synthesis",
            api_key=api_key,
            **parameters,
        )

        return result

    @trace(trace_type="AIGC", trace_name="speech_to_video_submit")
    async def arun(
        self,
        args: SpeechToVideoSubmitInput,
        **kwargs: Any,
    ) -> SpeechToVideoSubmitOutput:
        """
        Submit speech to video generation task using DashScope wan2.2-s2v API

        This method wraps DashScope's wan2.2-s2v service to submit video
        generation tasks based on input image and audio. It uses async call
        pattern for better performance.

        Args:
            args: SpeechToVideoSubmitInput containing image_url, audio_url and
                  optional parameters
            **kwargs: Additional keyword arguments including:
                - request_id: Optional request ID for tracking
                - model_name: Model name to use (defaults to wan2.2-s2v)
                - api_key: DashScope API key for authentication

        Returns:
            SpeechToVideoSubmitOutput containing the task ID, status and
            request ID

        Raises:
            ValueError: If DASHSCOPE_API_KEY is not set or invalid
            RuntimeError: If task submission fails
        """
        trace_event = kwargs.pop("trace_event", None)
        request_id = MCPUtil._get_mcp_dash_request_id(args.ctx)

        try:
            api_key = get_api_key(ApiNames.dashscope_api_key, **kwargs)
        except AssertionError:
            raise ValueError("Please set valid DASHSCOPE_API_KEY!")

        model_name = kwargs.get(
            "model_name",
            os.getenv("SPEECH_TO_VIDEO_MODEL_NAME", "wan2.2-s2v"),
        )

        parameters = {}
        if args.resolution:
            parameters["resolution"] = args.resolution

        # Submit async task
        response = await self._async_call(
            model=model_name,
            api_key=api_key,
            image_url=args.image_url,
            audio_url=args.audio_url,
            **parameters,
        )

        # Log trace event if provided
        if trace_event:
            trace_event.on_log(
                "",
                **{
                    "step_suffix": "results",
                    "payload": {
                        "request_id": request_id,
                        "submit_task": response,
                    },
                },
            )

        if not request_id:
            request_id = (
                response.request_id
                if response.request_id
                else str(uuid.uuid4())
            )

        # Extract task information from response
        if hasattr(response, "output") and hasattr(response.output, "task_id"):
            task_id = response.output.task_id
            task_status = getattr(response.output, "task_status", "PENDING")
        else:
            # Handle dict-style response
            if isinstance(response.output, dict):
                task_id = response.output.get("task_id")
                task_status = response.output.get("task_status", "PENDING")
            else:
                raise RuntimeError(f"Unexpected response format: {response}")

        result = SpeechToVideoSubmitOutput(
            request_id=request_id,
            task_id=task_id,
            task_status=task_status,
        )
        return result


class SpeechToVideoFetchInput(BaseModel):
    """
    Speech to video fetch task input model
    """

    task_id: str = Field(
        title="Task ID",
        description="è¯­éŸ³ç”Ÿæˆè§†é¢‘çš„ä»»åŠ¡ID",
    )
    ctx: Optional[Context] = Field(
        default=None,
        description="HTTP request context containing headers for mcp only, "
        "don't generate it",
    )


class SpeechToVideoFetchOutput(BaseModel):
    """
    Speech to video fetch task output model
    """

    video_url: Optional[str] = Field(
        default=None,
        title="Video URL",
        description="ç”Ÿæˆçš„è§†é¢‘æ–‡ä»¶URLï¼Œä»…åœ¨ä»»åŠ¡æˆåŠŸå®Œæˆæ—¶æœ‰å€¼",
    )

    task_id: str = Field(
        title="Task ID",
        description="è¯­éŸ³ç”Ÿæˆè§†é¢‘çš„ä»»åŠ¡ID",
    )

    task_status: str = Field(
        title="Task Status",
        description="è¯­éŸ³ç”Ÿæˆè§†é¢‘çš„ä»»åŠ¡çŠ¶æ€ï¼ŒPENDINGï¼šä»»åŠ¡æ’é˜Ÿä¸­ï¼ŒRUNNINGï¼šä»»åŠ¡å¤„ç†ä¸­ï¼Œ"
        "SUCCEEDEDï¼šä»»åŠ¡æ‰§è¡ŒæˆåŠŸï¼ŒFAILEDï¼šä»»åŠ¡æ‰§è¡Œå¤±è´¥ï¼ŒCANCELEDï¼šä»»åŠ¡å–æ¶ˆæˆåŠŸï¼Œ"
        "UNKNOWNï¼šä»»åŠ¡ä¸å­˜åœ¨æˆ–çŠ¶æ€æœªçŸ¥",
    )

    request_id: Optional[str] = Field(
        default=None,
        title="Request ID",
        description="è¯·æ±‚ID",
    )

    video_duration: Optional[float] = Field(
        default=None,
        title="Video Duration",
        description="è§†é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰ï¼Œç”¨äºè®¡è´¹",
    )


class SpeechToVideoFetch(
    Component[SpeechToVideoFetchInput, SpeechToVideoFetchOutput],
):
    """
    Speech to video fetch service that retrieves video generation results
    using DashScope's wan2.2-s2v API.
    """

    name: str = "modelstudio_speech_to_video_fetch_result"
    description: str = (
        "æ•°å­—äººwan2.2-s2væ¨¡å‹çš„å¼‚æ­¥ä»»åŠ¡ç»“æœæŸ¥è¯¢å·¥å…·ï¼Œæ ¹æ®Task IDæŸ¥è¯¢ä»»åŠ¡ç»“æœã€‚"
    )

    @staticmethod
    async def _fetch(
        api_key: str,
        task: Any,
    ) -> Any:
        """
        Fetch task result using BaseAsyncAioApi

        Args:
            api_key: DashScope API key for authentication
            task: Task response containing task_id

        Returns:
            Response containing task status and result
        """
        # Use BaseAsyncAioApi.fetch directly with await
        result = await BaseAsyncAioApi.fetch(
            api_key=api_key,
            task=task,
        )

        return result

    @trace(trace_type="AIGC", trace_name="speech_to_video_fetch")
    async def arun(
        self,
        args: SpeechToVideoFetchInput,
        **kwargs: Any,
    ) -> SpeechToVideoFetchOutput:
        """
        Fetch speech to video generation result using DashScope wan2.2-s2v API

        This method wraps DashScope's wan2.2-s2v fetch service to retrieve
        video generation results based on task ID. It uses async call pattern
        for better performance.

        Args:
            args: SpeechToVideoFetchInput containing task_id parameter
            **kwargs: Additional keyword arguments including:
                - api_key: DashScope API key for authentication

        Returns:
            SpeechToVideoFetchOutput containing the video URL, task status,
            request ID and video duration

        Raises:
            ValueError: If DASHSCOPE_API_KEY is not set or invalid
            RuntimeError: If video fetch fails or response status is not OK
        """
        trace_event = kwargs.pop("trace_event", None)
        request_id = MCPUtil._get_mcp_dash_request_id(args.ctx)

        try:
            api_key = get_api_key(ApiNames.dashscope_api_key, **kwargs)
        except AssertionError:
            raise ValueError("Please set valid DASHSCOPE_API_KEY!")

        response = await self._fetch(
            api_key=api_key,
            task=args.task_id,
        )

        if response.status_code != HTTPStatus.OK:
            raise RuntimeError(f"Failed to get video URL: {response}")

        # Log trace event if provided
        if trace_event:
            trace_event.on_log(
                "",
                **{
                    "step_suffix": "results",
                    "payload": {
                        "request_id": response.request_id,
                        "fetch_result": response,
                    },
                },
            )

        # Handle request ID
        if not request_id:
            request_id = (
                response.request_id
                if response.request_id
                else str(uuid.uuid4())
            )

        # Extract task information from response
        if isinstance(response.output, dict):
            task_id = response.output.get("task_id", args.task_id)
            task_status = response.output.get("task_status", "UNKNOWN")

            # For completed tasks, extract video URL from results
            video_url = None
            if task_status == "SUCCEEDED" and "results" in response.output:
                results = response.output["results"]
                if isinstance(results, dict):
                    video_url = results.get("video_url")
                else:
                    video_url = getattr(results, "video_url", None)

                if not video_url:
                    raise RuntimeError(
                        f"Failed to extract video URL from response: "
                        f"{response}",
                    )
            elif task_status == "SUCCEEDED":
                # If task succeeded but no results found
                raise RuntimeError(
                    f"Task succeeded but no video URL found in response: "
                    f"{response.output}",
                )
            # For PENDING/RUNNING tasks, video_url will remain None
        else:
            raise RuntimeError(
                f"Unexpected response format: {response.output}",
            )

        # Extract video duration from usage
        video_duration = None
        if hasattr(response, "usage") and response.usage:
            if isinstance(response.usage, dict):
                video_duration = response.usage.get("duration")
            else:
                video_duration = getattr(response.usage, "duration", None)

        result = SpeechToVideoFetchOutput(
            video_url=video_url,
            task_id=task_id,
            task_status=task_status,
            request_id=request_id,
            video_duration=video_duration,
        )

        return result


if __name__ == "__main__":
    speech_to_video_submit = SpeechToVideoSubmit()
    speech_to_video_fetch = SpeechToVideoFetch()

    async def main() -> None:
        import time

        image_url = (
            "https://img.alicdn.com/imgextra/i3/O1CN011FObkp1T7Ttow"
            "oq4F_!!6000000002335-0-tps-1440-1797.jpg"
        )

        audio_url = (
            "https://help-static-aliyun-doc.aliyuncs.com/"
            "file-manage-files/zh-CN/20250825/iaqpio/input_audio.MP3"
        )

        test_inputs = [
            SpeechToVideoSubmitInput(
                image_url=image_url,
                audio_url=audio_url,
                resolution="480P",
            ),
            # SpeechToVideoSubmitInput(
            #     image_url=image_url,
            #     audio_url=audio_url,
            #     resolution="720P",
            # ),
        ]

        start_time = time.time()

        try:
            # Step 1: Submit async tasks concurrently
            print("ğŸ“¤ æäº¤è¯­éŸ³ç”Ÿæˆè§†é¢‘ä»»åŠ¡...")
            submit_tasks = [
                speech_to_video_submit.arun(
                    test_input,
                    model_name="wan2.2-s2v",
                )
                for test_input in test_inputs
            ]

            submit_results = await asyncio.gather(
                *submit_tasks,
                return_exceptions=True,
            )

            # Step 2: Extract task_ids from successful submissions
            task_ids = []
            for i, result in enumerate(submit_results, 1):
                print(f"\nğŸ“‹ ä»»åŠ¡ {i} æäº¤ç»“æœ:")
                if isinstance(result, Exception):
                    print(f"   âŒ é”™è¯¯: {str(result)}")
                else:
                    print("   âœ… å·²æäº¤:")
                    print(f"   ğŸ†” ä»»åŠ¡ID: {result.task_id}")
                    print(f"   ğŸ“Š çŠ¶æ€: {result.task_status}")
                    task_ids.append(result.task_id)

            if not task_ids:
                print("âŒ æ²¡æœ‰æˆåŠŸæäº¤çš„ä»»åŠ¡")
                return

            # Step 3: Poll for task completion using SpeechToVideoFetch
            print(f"\nğŸ”„ è½®è¯¢ {len(task_ids)} ä¸ªä»»åŠ¡çš„å®ŒæˆçŠ¶æ€...")
            max_wait_time = 600  # 10 minutes timeout for video generation
            poll_interval = 5  # 5 seconds polling interval
            completed_tasks = {}

            poll_start_time = time.time()

            while len(completed_tasks) < len(task_ids):
                # Wait before polling
                await asyncio.sleep(poll_interval)

                # Create fetch tasks for incomplete tasks only
                remaining_task_ids = [
                    task_id
                    for task_id in task_ids
                    if task_id not in completed_tasks
                ]

                if not remaining_task_ids:
                    break

                fetch_tasks = [
                    speech_to_video_fetch.arun(
                        SpeechToVideoFetchInput(task_id=task_id),
                    )
                    for task_id in remaining_task_ids
                ]

                fetch_results = await asyncio.gather(
                    *fetch_tasks,
                    return_exceptions=True,
                )

                # Process fetch results
                for task_id, fetch_result in zip(
                    remaining_task_ids,
                    fetch_results,
                ):
                    if isinstance(fetch_result, Exception):
                        print(
                            f"âš ï¸  ä»»åŠ¡ {task_id} æŸ¥è¯¢é”™è¯¯: "
                            f"{str(fetch_result)}",
                        )
                        continue

                    status = fetch_result.task_status
                    print(f"ğŸ“Š ä»»åŠ¡ {task_id}: {status}")

                    if status == "SUCCEEDED":
                        completed_tasks[task_id] = fetch_result
                        if fetch_result.video_url:
                            print(f"   âœ… è§†é¢‘URL: {fetch_result.video_url}")
                        if fetch_result.video_duration:
                            print(
                                f"   â±ï¸ è§†é¢‘æ—¶é•¿: {fetch_result.video_duration}ç§’",
                            )
                    elif status in ["FAILED", "CANCELED"]:
                        completed_tasks[task_id] = fetch_result
                        print(f"   âŒ ä»»åŠ¡å¤±è´¥ï¼ŒçŠ¶æ€: {status}")
                    # For PENDING/RUNNING, continue polling

                # Check timeout
                if time.time() - poll_start_time > max_wait_time:
                    print(f"â° è½®è¯¢è¶…æ—¶ï¼Œè¶…è¿‡ {max_wait_time}ç§’")
                    break

            end_time = time.time()
            total_time = end_time - start_time

            print(f"\nğŸ¯ æ‰§è¡Œå®Œæˆï¼Œè€—æ—¶ {total_time:.2f}ç§’")
            print("=" * 60)

            # Display final results
            for i, task_id in enumerate(task_ids, 1):
                print(f"\nğŸ¬ ä»»åŠ¡ {i} æœ€ç»ˆç»“æœ:")
                if task_id in completed_tasks:
                    result = completed_tasks[task_id]
                    if result.task_status == "SUCCEEDED":
                        print("   âœ… æˆåŠŸ:")
                        if result.video_url:
                            print(f"   ğŸ”— è§†é¢‘URL: {result.video_url}")
                        print(f"   ğŸ†” è¯·æ±‚ID: {result.request_id}")
                        if result.video_duration:
                            print(f"   â±ï¸ è§†é¢‘æ—¶é•¿: {result.video_duration}ç§’")
                    else:
                        print(
                            f"   âŒ å¤±è´¥ï¼ŒçŠ¶æ€: {result.task_status}",
                        )
                else:
                    print("   â³ æœªå®Œæˆï¼ˆè¶…æ—¶ï¼‰")
                print("-" * 40)

        except Exception as e:
            print(f"âŒ æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿæ„å¤–é”™è¯¯: {str(e)}")

    asyncio.run(main())
