{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"/Users/minji.kang/Documents/NGDT/Data_export_management/Report_CSV_Preprocessing_Generic_Script/NIMH/input/\"\n",
    "output_path = \"/Users/minji.kang/Documents/NGDT/Data_export_management/Report_CSV_Preprocessing_Generic_Script/NIMH/output/\"\n",
    "\n",
    "\n",
    "def read_and_bind_df(mypath):\n",
    "    all_files = os.listdir(mypath)\n",
    "    report_files = [file for file in all_files if file.startswith(\"report\")]\n",
    "    report_df = []\n",
    "    for i in range(len(report_files)):\n",
    "        temp_df = pd.read_csv(\n",
    "            os.path.join(mypath, report_files[i]), encoding=\"ISO-8859-1\"\n",
    "        )\n",
    "        report_df.append(temp_df)\n",
    "    report = pd.concat(report_df, ignore_index=True)\n",
    "    report.rename(columns={report.columns[0]: \"id\"}, inplace=True)\n",
    "    return report\n",
    "\n",
    "\n",
    "df = read_and_bind_df(input_path)\n",
    "# df.to_csv(os.path.join('/Users/minji.kang/','report_all.csv'),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(os.path.join('/Users/minji.kang/','report_all.csv'),index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Timezone offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_timezone_offset(mydata, columntoaddto):\n",
    "    col_values = pd.to_numeric(mydata[columntoaddto], errors=\"coerce\")\n",
    "    timezone_offsets = pd.to_numeric(mydata[\"timezone_offset\"], errors=\"coerce\")\n",
    "    timezone_offsets = timezone_offsets.fillna(0)  # Replace NaN with 0 for offsets\n",
    "    return col_values + (timezone_offsets * 60 * 1000)\n",
    "\n",
    "\n",
    "df[\"start_Time\"] = add_timezone_offset(df, \"activity_start_time\")\n",
    "df[\"end_Time\"] = add_timezone_offset(df, \"activity_end_time\")\n",
    "df[\"schedule_Time\"] = add_timezone_offset(df, \"activity_scheduled_time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group by min start_Time & max End_Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dat_processed = df.groupby(['secret_user_id', 'activity_flow_id', 'activity_scheduled_time'], group_keys=True).apply(lambda x: x.assign(start_Time=x['start_Time'].min(), end_Time=x['end_Time'].max())).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score options replacements and removing unnecessary characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_score_mapping(data):\n",
    "    response_scores = []  # List to store results\n",
    "\n",
    "    for i in range(len(data[\"response\"])):\n",
    "        options = data[\"options\"][i]\n",
    "        response = data[\"response\"][i]\n",
    "        # clean_response = re.sub(r\"value: |geo: \", \"\", response)\n",
    "        if isinstance(response, str):\n",
    "            clean_response = re.sub(r\"value: |geo: \", \"\", response)\n",
    "        else:\n",
    "            clean_response = np.nan\n",
    "\n",
    "        # Ensure 'options' and 'response' are valid strings\n",
    "        if not isinstance(options, str) or not isinstance(response, str):\n",
    "            response_scores.append(clean_response)  # Append NaN for invalid rows\n",
    "            continue\n",
    "\n",
    "        if re.search(r\"score: \", options):\n",
    "            split_options = options.strip().split(\"),\")\n",
    "            split_response = response.strip().split(\": \")[1].split(\",\")\n",
    "            scores = {}\n",
    "\n",
    "            for j in split_options:\n",
    "                if \"(score\" in j:  # Ensure the string contains the expected structure\n",
    "                    val_parts = j.split(\"(score\")\n",
    "                    if len(val_parts) == 2 and \": \" in val_parts[0]:\n",
    "                        val_num = val_parts[0].split(\": \")[1].strip()\n",
    "                        score_num = val_parts[1].split(\": \")[1].strip(\" )\")\n",
    "                        scores[val_num] = score_num\n",
    "\n",
    "            response_score_mapping = {\n",
    "                resp.strip(): scores.get(resp.strip(), \"N/A\")  # Handle missing mappings\n",
    "                for resp in split_response\n",
    "            }\n",
    "            response_scores.append(\", \".join(response_score_mapping.values()))\n",
    "        else:\n",
    "            response_scores.append(\n",
    "                clean_response\n",
    "            )  # Append NaN if no valid scores are found\n",
    "\n",
    "    return pd.Series(response_scores)\n",
    "\n",
    "\n",
    "# df['response_scores'] = val_score_mapping(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatting time and time_range items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_responses(data):\n",
    "    formatted_responses = []  # List to store the formatted responses\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        response = data[\"response\"].iloc[i]\n",
    "\n",
    "        # Ensure response is a string, or handle NaN/invalid values\n",
    "        if not isinstance(response, str):\n",
    "            formatted_responses.append(response)  # Leave as is for non-string values\n",
    "            continue\n",
    "\n",
    "        # Handle 'time:' entries\n",
    "        if re.search(r\"time:\", response):\n",
    "            if re.search(r\"hr [0-9],\", response):  # Single-digit hour\n",
    "                egapp = response.replace(\"time: hr \", \"0\")\n",
    "                if re.search(r\", min [0-9]$\", egapp):  # Single-digit minute\n",
    "                    egtemp = egapp.replace(\", min \", \":0\")\n",
    "                elif re.search(r\", min [0-9][0-9]$\", egapp):  # Two-digit minute\n",
    "                    egtemp = egapp.replace(\", min \", \":\")\n",
    "            elif re.search(r\"hr [0-9][0-9],\", response):  # Two-digit hour\n",
    "                egapp = response.replace(\"time: hr \", \"\")\n",
    "                if re.search(r\", min [0-9]$\", egapp):  # Single-digit minute\n",
    "                    egtemp = egapp.replace(\", min \", \":0\")\n",
    "                elif re.search(r\", min [0-9][0-9]$\", egapp):  # Two-digit minute\n",
    "                    egtemp = egapp.replace(\", min \", \":\")\n",
    "\n",
    "            # Convert to formatted time\n",
    "            egpos = datetime.strptime(egtemp, \"%H:%M\")\n",
    "            formatted_responses.append(egpos.strftime(\"%H:%M\"))\n",
    "\n",
    "        # Handle 'time_range:' entries\n",
    "        elif re.search(r\"time_range:\", response):\n",
    "            # Extract times and format them\n",
    "            t = re.sub(r\"[a-zA-Z\\s+(\\)_:]\", \"\", response)  # Remove unwanted characters\n",
    "            t = t.replace(\",\", \":\")  # Replace commas with colons\n",
    "            time_parts = t.split(\"/\")  # Split the time range into two parts\n",
    "\n",
    "            # Format each time part\n",
    "            formatted_parts = []\n",
    "            for part in time_parts:\n",
    "                hours, minutes = part.split(\":\")\n",
    "                hours = hours.zfill(2)  # Ensure hours are two digits\n",
    "                minutes = minutes.zfill(2)  # Ensure minutes are two digits\n",
    "                formatted_parts.append(f\"{hours}:{minutes}\")\n",
    "\n",
    "            # Combine the formatted parts back into the time range\n",
    "            formatted_responses.append(\"/\".join(formatted_parts))\n",
    "\n",
    "        # Handle other cases\n",
    "        else:\n",
    "            formatted_responses.append(response)  # Keep the response unchanged\n",
    "\n",
    "    return pd.Series(formatted_responses)  # Return as a pandas Series\n",
    "\n",
    "\n",
    "# df['formatted_responses'] = format_responses(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting epoch time to regular time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_epochtime(data, column_name):\n",
    "    epoch_converted = []\n",
    "    epoch_converted = pd.to_numeric(data[column_name], errors=\"coerce\")\n",
    "    return pd.to_datetime(epoch_converted / 1000, unit=\"s\")\n",
    "\n",
    "\n",
    "df[\"start_Time\"] = format_epochtime(df, \"start_Time\")\n",
    "df[\"end_Time\"] = format_epochtime(df, \"end_Time\")\n",
    "df[\"schedule_Time\"] = format_epochtime(df, \"schedule_Time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing Responses Function (combined score mapping+cleaning and formatting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_responses(data, clean=True, map_scores=True, format_time=True):\n",
    "    processed_responses = []  # List to store the processed responses\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        options = data[\"options\"].iloc[i] if \"options\" in data else None\n",
    "        response = data[\"response\"].iloc[i]\n",
    "\n",
    "        processed = False\n",
    "\n",
    "        # Ensure response is a string\n",
    "        if not isinstance(response, str):\n",
    "            response = str(response) if not pd.isna(response) else None\n",
    "\n",
    "        # Clean the response\n",
    "        if clean:\n",
    "            # Handle geo: entries\n",
    "            if isinstance(response, str) and re.search(r\"geo:\", response):\n",
    "                # Extract latitude and longitude\n",
    "                geo_match = re.search(\n",
    "                    r\"geo:\\s*lat\\s*\\((.*?)\\)\\s*/\\s*long\\s*\\((.*?)\\)\", response\n",
    "                )\n",
    "                if geo_match:\n",
    "                    lat = geo_match.group(1).strip()\n",
    "                    long = geo_match.group(2).strip()\n",
    "                    geo_cleaned = f\"{lat}/{long}\"  # Combine them as desired\n",
    "                    processed_responses.append(geo_cleaned)\n",
    "                    processed = True\n",
    "                    continue\n",
    "\n",
    "            # General cleaning\n",
    "            clean_response = (\n",
    "                re.sub(r\"value:\", \"\", response) if isinstance(response, str) else np.nan\n",
    "            )\n",
    "            if not isinstance(response, str):\n",
    "                processed_responses.append(clean_response)\n",
    "                processed = True\n",
    "                continue\n",
    "\n",
    "        # Format time or time range entries\n",
    "        if format_time and isinstance(response, str):\n",
    "            if re.search(r\"time:\", response):\n",
    "                try:\n",
    "                    if re.search(r\"hr [0-9],\", response):  # Single-digit hour\n",
    "                        temp_response = response.replace(\"time: hr \", \"0\")\n",
    "                        if re.search(\n",
    "                            r\", min [0-9]$\", temp_response\n",
    "                        ):  # Single-digit minute\n",
    "                            temp_response = temp_response.replace(\", min \", \":0\")\n",
    "                        elif re.search(\n",
    "                            r\", min [0-9][0-9]$\", temp_response\n",
    "                        ):  # Two-digit minute\n",
    "                            temp_response = temp_response.replace(\", min \", \":\")\n",
    "                    elif re.search(r\"hr [0-9][0-9],\", response):  # Two-digit hour\n",
    "                        temp_response = response.replace(\"time: hr \", \"\")\n",
    "                        if re.search(\n",
    "                            r\", min [0-9]$\", temp_response\n",
    "                        ):  # Single-digit minute\n",
    "                            temp_response = temp_response.replace(\", min \", \":0\")\n",
    "                        elif re.search(\n",
    "                            r\", min [0-9][0-9]$\", temp_response\n",
    "                        ):  # Two-digit minute\n",
    "                            temp_response = temp_response.replace(\", min \", \":\")\n",
    "\n",
    "                    # Extract only the valid time format part\n",
    "                    valid_time = re.search(r\"\\d{2}:\\d{2}\", temp_response)\n",
    "                    if valid_time:\n",
    "                        formatted_time = datetime.strptime(valid_time.group(), \"%H:%M\")\n",
    "                        processed_responses.append(formatted_time.strftime(\"%H:%M\"))\n",
    "                        processed = True\n",
    "                    else:\n",
    "                        processed_responses.append(\n",
    "                            np.nan\n",
    "                        )  # Append NaN for invalid formats\n",
    "                        processed = True\n",
    "                except Exception:\n",
    "                    processed_responses.append(np.nan)\n",
    "                    processed = True\n",
    "                    continue\n",
    "\n",
    "            elif re.search(r\"time_range:\", response):\n",
    "                try:\n",
    "                    clean_time = re.sub(r\"[a-zA-Z\\s+(\\)_:]\", \"\", response).replace(\n",
    "                        \",\", \":\"\n",
    "                    )\n",
    "                    time_parts = clean_time.split(\"/\")\n",
    "                    formatted_parts = [\n",
    "                        f\"{part.split(':')[0].zfill(2)}:{part.split(':')[1].zfill(2)}\"\n",
    "                        for part in time_parts\n",
    "                    ]\n",
    "                    processed_responses.append(\"/\".join(formatted_parts))\n",
    "                    processed = True\n",
    "                except Exception:\n",
    "                    processed_responses.append(np.nan)\n",
    "                    processed = True\n",
    "                    continue\n",
    "\n",
    "        # Map scores\n",
    "        if map_scores and isinstance(response, str) and isinstance(options, str):\n",
    "            if re.search(r\"score: \", options):\n",
    "                split_options = options.strip().split(\"),\")\n",
    "                split_response = response.strip().split(\": \")[1].split(\",\")\n",
    "                scores = {}\n",
    "\n",
    "                for j in split_options:\n",
    "                    if \"(score\" in j:\n",
    "                        val_parts = j.split(\"(score\")\n",
    "                        if len(val_parts) == 2 and \": \" in val_parts[0]:\n",
    "                            val_num = val_parts[0].split(\": \")[1].strip()\n",
    "                            score_num = val_parts[1].split(\": \")[1].strip(\" )\")\n",
    "                            scores[val_num] = score_num\n",
    "\n",
    "                response_score_mapping = {\n",
    "                    resp.strip(): scores.get(resp.strip(), \"N/A\")\n",
    "                    for resp in split_response\n",
    "                }\n",
    "                processed_responses.append(\", \".join(response_score_mapping.values()))\n",
    "                processed = True\n",
    "                continue\n",
    "\n",
    "        # Fallback case\n",
    "        if not processed:\n",
    "            processed_responses.append(\n",
    "                response if isinstance(response, str) else np.nan\n",
    "            )\n",
    "\n",
    "    return pd.Series(processed_responses)\n",
    "\n",
    "\n",
    "dat_processed = df.copy()\n",
    "dat_processed[\"new_responses\"] = process_responses(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Widening Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_processed = df.copy()\n",
    "dat_processed[\"new_responses\"] = process_responses(df)\n",
    "\n",
    "mycolumn_list = [\n",
    "    \"userId\",\n",
    "    \"secret_user_id\",\n",
    "    \"source_user_secret_id\",\n",
    "    \"source_user_nickname\",\n",
    "    \"source_user_tag\",\n",
    "    \"source_user_relation\",\n",
    "    \"target_user_secret_id\",\n",
    "    \"target_user_nickname\",\n",
    "    \"target_user_tag\",\n",
    "    \"input_user_secret_id\",\n",
    "    \"input_user_nickname\",\n",
    "    \"schedule_Time\",\n",
    "    \"start_Time\",\n",
    "    \"end_Time\",\n",
    "    \"activity_flow_id\",\n",
    "    \"activity_flow_name\",\n",
    "    \"event_id\",\n",
    "    \"version\",\n",
    "]\n",
    "myresponse_column_name = \"new_responses\"\n",
    "\n",
    "\n",
    "def widen_data(data, column_list, response_column_name):\n",
    "    data[column_list] = data[column_list].fillna(\"\")\n",
    "    datetime_cols = data.select_dtypes(include=[\"datetime\"]).columns\n",
    "    data[datetime_cols] = (\n",
    "        data[datetime_cols].replace(\"\", pd.NaT).fillna(pd.Timestamp(\"1900-01-01\"))\n",
    "    )\n",
    "    # data.loc[:, data.select_dtypes(include=['datetime']).columns] = data.select_dtypes(include=['datetime']).fillna(pd.Timestamp('1900-01-01'))\n",
    "    data_grouped = (\n",
    "        data.groupby(\n",
    "            [\"secret_user_id\", \"activity_flow_id\", \"activity_scheduled_time\"],\n",
    "            group_keys=True,\n",
    "        )\n",
    "        .apply(\n",
    "            lambda x: x.assign(\n",
    "                start_Time=x[\"start_Time\"].min(), end_Time=x[\"end_Time\"].max()\n",
    "            )\n",
    "        )\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    answers = (\n",
    "        data_grouped.groupby(column_list, group_keys=False)[\"id\"]\n",
    "        .apply(lambda x: \"|\".join(x.astype(str)))\n",
    "        .reset_index()\n",
    "    )\n",
    "    data_grouped[\"combined_cols\"] = (\n",
    "        data_grouped[[\"activity_id\", \"item_id\", \"item\"]]\n",
    "        .astype(str)\n",
    "        .agg(\"_\".join, axis=1)\n",
    "    )\n",
    "    subset_columns = column_list + [\"combined_cols\", response_column_name]\n",
    "    dat_subset = data_grouped[subset_columns]\n",
    "    dat_wide = pd.pivot_table(\n",
    "        dat_subset,\n",
    "        index=column_list,\n",
    "        columns=\"combined_cols\",\n",
    "        values=response_column_name,\n",
    "        aggfunc=\"last\",\n",
    "    ).reset_index()\n",
    "    return pd.merge(dat_wide, answers, on=column_list, how=\"outer\")\n",
    "\n",
    "\n",
    "data_wide = widen_data(dat_processed, mycolumn_list, myresponse_column_name)\n",
    "data_wide.to_csv(os.path.join(output_path, \"data_wide_all.csv\"), index=False)\n",
    "\n",
    "data_wide.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities_only = df.copy()\n",
    "activities_only = activities_only[activities_only[\"activity_flow_id\"].isna()]\n",
    "activities_only[\"new_responses\"] = process_responses(activities_only)\n",
    "\n",
    "mycolumn_list = [\n",
    "    \"userId\",\n",
    "    \"secret_user_id\",\n",
    "    \"source_user_secret_id\",\n",
    "    \"source_user_nickname\",\n",
    "    \"source_user_tag\",\n",
    "    \"source_user_relation\",\n",
    "    \"target_user_secret_id\",\n",
    "    \"target_user_nickname\",\n",
    "    \"target_user_tag\",\n",
    "    \"input_user_secret_id\",\n",
    "    \"input_user_nickname\",\n",
    "    \"schedule_Time\",\n",
    "    \"start_Time\",\n",
    "    \"end_Time\",\n",
    "    \"activity_flow_id\",\n",
    "    \"activity_flow_name\",\n",
    "    \"event_id\",\n",
    "    \"version\",\n",
    "]\n",
    "myresponse_column_name = \"new_responses\"\n",
    "\n",
    "data_wide2 = widen_data(activities_only, mycolumn_list, myresponse_column_name)\n",
    "data_wide2.to_csv(\n",
    "    os.path.join(output_path, \"data_wide_activities_only.csv\"), index=False\n",
    ")\n",
    "\n",
    "data_wide2.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
