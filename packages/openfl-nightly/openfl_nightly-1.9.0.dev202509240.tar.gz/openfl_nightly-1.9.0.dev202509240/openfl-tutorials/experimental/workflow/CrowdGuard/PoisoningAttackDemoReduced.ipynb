{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bec0e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (C) 2022-2024 TU Darmstadt\n",
    "# SPDX-License-Identifier: Apache-2.0\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# Primary author: Phillip Rieger <phillip.rieger@trust.tu-darmstadt.de>\n",
    "# Co-authored-by: Torsten Krauss <torsten.krauss@uni-wuerzburg.de>\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "import warnings\n",
    "from copy import deepcopy\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "from sklearn.cluster import AgglomerativeClustering, DBSCAN\n",
    "\n",
    "from CrowdGuardClientValidation import CrowdGuardClientValidation\n",
    "from openfl.experimental.workflow.interface import Aggregator, Collaborator, FLSpec\n",
    "from openfl.experimental.workflow.placement import aggregator, collaborator\n",
    "from openfl.experimental.workflow.runtime import LocalRuntime\n",
    "from cifar10_crowdguard import MEAN, STD_DEV, poison_data, seed_random_generators\n",
    "from cifar10_crowdguard import BATCH_SIZE_TRAIN, BATCH_SIZE_TEST, Net, test, default_optimizer\n",
    "from cifar10_crowdguard import FederatedFlow\n",
    "from cifar10_crowdguard import PRETRAINED_MODEL_FILE, download_pretrained_model\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94098847",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_CLIENT_NUMBER = 4\n",
    "PMR = 0.25\n",
    "NUMBER_OF_MALICIOUS_CLIENTS = max(1, int(TOTAL_CLIENT_NUMBER * PMR)) if PMR > 0 else 0\n",
    "NUMBER_OF_BENIGN_CLIENTS = TOTAL_CLIENT_NUMBER - NUMBER_OF_MALICIOUS_CLIENTS\n",
    "NUMBER_OF_ROUNDS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0107812",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CommandLineArgumentSimulator:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.test_dataset_ratio = 0.4\n",
    "        self.train_dataset_ratio = 0.4\n",
    "        self.log_dir = 'test_debug'\n",
    "        self.comm_round = NUMBER_OF_ROUNDS\n",
    "        self.flow_internal_loop_test=False\n",
    "        self.optimizer_type = 'SGD'\n",
    "        \n",
    "args = CommandLineArgumentSimulator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd18c0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_pretrained_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8950eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregator_object = Aggregator()\n",
    "aggregator_object.private_attributes = {}\n",
    "collaborator_names = [f'benign_{i:02d}' for i in range(NUMBER_OF_BENIGN_CLIENTS)] + [f'malicious_{i:02d}' for i in range(NUMBER_OF_MALICIOUS_CLIENTS)]    \n",
    "collaborators = [Collaborator(name=name) for name in collaborator_names]\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\n",
    "        \"cuda:1\"\n",
    "        )  # This will enable Ray library to reserve available GPU(s) for the task\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(MEAN, STD_DEV),])\n",
    "\n",
    "cifar_train = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
    "cifar_train = [x for x in cifar_train]\n",
    "cifar_test = datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
    "cifar_test = [x for x in cifar_test]\n",
    "X = torch.stack([x[0] for x in cifar_train] + [x[0] for x in cifar_test])\n",
    "Y = torch.LongTensor(np.stack(np.array([x[1] for x in cifar_train] + [x[1] for x in cifar_test])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92f0205",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_random_generators(0)\n",
    "shuffled_indices = np.arange(X.shape[0])\n",
    "np.random.shuffle(shuffled_indices)\n",
    "\n",
    "N_total_samples = len(cifar_test) + len(cifar_train)\n",
    "train_dataset_size = int(N_total_samples * args.train_dataset_ratio)\n",
    "test_dataset_size = int(N_total_samples * args.test_dataset_ratio)\n",
    "X = X[shuffled_indices]\n",
    "Y = Y[shuffled_indices]\n",
    "\n",
    "train_dataset_data = X[:train_dataset_size]\n",
    "train_dataset_targets = Y[:train_dataset_size]\n",
    "\n",
    "test_dataset_data = X[train_dataset_size:train_dataset_size + test_dataset_size]\n",
    "test_dataset_targets = Y[train_dataset_size:train_dataset_size + test_dataset_size]\n",
    "print(f\"Dataset info (total {N_total_samples}): train - {test_dataset_targets.shape[0]}, \"\n",
    "          f\"test - {test_dataset_targets.shape[0]}, \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47aca7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, collab in enumerate(collaborators):\n",
    "    # construct the training and test and population dataset\n",
    "    benign_training_X = train_dataset_data[idx::len(collaborators)]\n",
    "    benign_training_Y = train_dataset_targets[idx::len(collaborators)]\n",
    "    \n",
    "    if 'malicious' in collab.name:\n",
    "        local_train_data, local_train_targets = poison_data(benign_training_X, benign_training_Y)\n",
    "    else:\n",
    "        local_train_data, local_train_targets = benign_training_X, benign_training_Y\n",
    "    \n",
    "\n",
    "    local_test_data = test_dataset_data[idx::len(collaborators)]\n",
    "    local_test_targets = test_dataset_targets[idx::len(collaborators)]\n",
    "    \n",
    "\n",
    "    poison_test_data, poison_test_targets = poison_data(local_test_data, local_test_targets,\n",
    "                                                        pdr=1.0)\n",
    "\n",
    "    collab.private_attributes = {\n",
    "        \"train_loader\": torch.utils.data.DataLoader(\n",
    "            TensorDataset(local_train_data, local_train_targets),\n",
    "            batch_size=BATCH_SIZE_TRAIN, shuffle=True\n",
    "            ),\n",
    "        \"test_loader\": torch.utils.data.DataLoader(\n",
    "            TensorDataset(local_test_data, local_test_targets),\n",
    "            batch_size=BATCH_SIZE_TEST, shuffle=False\n",
    "            ),\n",
    "        \"backdoor_test_loader\": torch.utils.data.DataLoader(\n",
    "            TensorDataset(poison_test_data, poison_test_targets),\n",
    "            batch_size=BATCH_SIZE_TEST, shuffle=False\n",
    "            ),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c46575",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_weights = torch.load(PRETRAINED_MODEL_FILE, map_location=device)\n",
    "test_model = Net().to(device)\n",
    "test_model.load_state_dict(pretrained_weights)\n",
    "test(test_model, collab.private_attributes['train_loader'], device, test_train='Train')\n",
    "test(test_model, collab.private_attributes['test_loader'], device)\n",
    "test(test_model, collab.private_attributes['backdoor_test_loader'], device, mode='Backdoor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9721c1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "local_runtime = LocalRuntime(aggregator=aggregator_object, collaborators=collaborators)\n",
    "\n",
    "print(f\"Local runtime collaborators = {local_runtime.collaborators}\")\n",
    "\n",
    "# change to the internal flow loop\n",
    "model = Net()\n",
    "model.load_state_dict(pretrained_weights)\n",
    "top_model_accuracy = 0\n",
    "optimizers = {\n",
    "    collaborator.name: default_optimizer(model, optimizer_type=args.optimizer_type)\n",
    "    for collaborator in collaborators\n",
    "    }\n",
    "flflow = FederatedFlow(\n",
    "    model,\n",
    "    optimizers,\n",
    "    device,\n",
    "    args.comm_round,\n",
    "    top_model_accuracy,\n",
    "    NUMBER_OF_MALICIOUS_CLIENTS / TOTAL_CLIENT_NUMBER,\n",
    "    'CrowdGuard'\n",
    "    )\n",
    "\n",
    "flflow.runtime = local_runtime\n",
    "flflow.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
