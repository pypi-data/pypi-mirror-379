{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dc13070c",
   "metadata": {},
   "source": [
    "# Federated Runtime: CrowdGuard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7357ef",
   "metadata": {},
   "source": [
    "This work is based on the [CrowdGuard demo code](https://github.com/securefederatedai/openfl/blob/develop/openfl-tutorials/experimental/workflow/CrowdGuard). It has been adapted to demonstrate CrowdGuard in the `FederatedRuntime`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a4394089",
   "metadata": {},
   "source": [
    "# Getting Started"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "857f9995",
   "metadata": {},
   "source": [
    "Initially, we start by specifying the module where cells marked with the `#| export` directive will be automatically exported. \n",
    "\n",
    "In the following cell, `#| default_exp experiment `indicates that the exported file will be named 'experiment'. This name can be modified based on user's requirement & preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79eacbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62449b5f",
   "metadata": {},
   "source": [
    "Once we have specified the name of the module, subsequent cells of the notebook need to be *appended* by the `#| export` directive as shown below. User should ensure that *all* the notebook functionality required in the Federated Learning experiment is included in this directive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e19dcf2",
   "metadata": {},
   "source": [
    "## Installing Pre-requisties\n",
    "We start by installing OpenFL and dependencies of the workflow interface. These dependencies are exported and become requirements for the Federated Learning Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7475cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "!pip install git+https://github.com/securefederatedai/openfl.git\n",
    "!pip install -r ../../workflow_interface_requirements.txt\n",
    "!pip install numpy\n",
    "!pip install torch==2.3.1\n",
    "!pip install torchvision==0.18.1\n",
    "!pip install -U ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237c391b",
   "metadata": {},
   "source": [
    "### Some global variables for CrowdGuard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a96af19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "BATCH_SIZE_TRAIN = 32\n",
    "BATCH_SIZE_TEST = 1000\n",
    "LEARNING_RATE = 0.00075\n",
    "MOMENTUM = 0.9\n",
    "LOG_INTERVAL = 10\n",
    "TOTAL_CLIENT_NUMBER = 4\n",
    "PMR = 0.25\n",
    "NUMBER_OF_MALICIOUS_CLIENTS = max(1, int(TOTAL_CLIENT_NUMBER * PMR)) if PMR > 0 else 0\n",
    "NUMBER_OF_BENIGN_CLIENTS = TOTAL_CLIENT_NUMBER - NUMBER_OF_MALICIOUS_CLIENTS\n",
    "PRETRAINED_MODEL_FILE = 'pretrained_cifar.pt'\n",
    "\n",
    "# set the random seed for repeatable results\n",
    "RANDOM_SEED = 10\n",
    "\n",
    "VOTE_FOR_BENIGN = 1\n",
    "VOTE_FOR_POISONED = 0\n",
    "STD_DEV = torch.from_numpy(np.array([0.2023, 0.1994, 0.2010]))\n",
    "MEAN = torch.from_numpy(np.array([0.4914, 0.4822, 0.4465]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6ae8e2",
   "metadata": {},
   "source": [
    "We now define our model, optimizer, and some helper functions like we would for any other deep learning experiment \n",
    "\n",
    "> This cell and all the subsequent cells are important ingredients of the Federated Learning experiment and therefore annotated with the `#| export` directive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd8ac2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import random\n",
    "\n",
    "def seed_random_generators(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    \n",
    "seed_random_generators(RANDOM_SEED)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(Net, self).__init__()\n",
    "        self.features = SequentialWithInternalStatePrediction(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "        )\n",
    "        self.classifier = SequentialWithInternalStatePrediction(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 2 * 2, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), 256 * 2 * 2)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def predict_internal_states(self, x):\n",
    "        result, x = self.features.predict_internal_states(x)\n",
    "        x = x.view(x.size(0), 256 * 2 * 2)\n",
    "        result += self.classifier.predict_internal_states(x)[0]\n",
    "        return result\n",
    "    \n",
    "\n",
    "class SequentialWithInternalStatePrediction(nn.Sequential):\n",
    "    \"\"\"\n",
    "    Adapted version of Sequential that implements the function predict_internal_states\n",
    "    \"\"\"\n",
    "\n",
    "    def predict_internal_states(self, x):\n",
    "        \"\"\"\n",
    "        applies the submodules on the input. Compared to forward, this function also returns\n",
    "        all intermediate outputs\n",
    "        \"\"\"\n",
    "        result = []\n",
    "        for module in self:\n",
    "            x = module(x)\n",
    "            # We can define our layer as we want. We selected Convolutional and\n",
    "            # Linear Modules as layers here.\n",
    "            # Differs for every model architecture.\n",
    "            # Can be defined by the defender.\n",
    "            if isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear):\n",
    "                result.append(x)\n",
    "        return result, x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269322ca",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2935ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def default_optimizer(model, optimizer_type=None, optimizer_like=None):\n",
    "    \"\"\"\n",
    "    Return a new optimizer based on the optimizer_type or the optimizer template\n",
    "\n",
    "    Args:\n",
    "        model:   NN model architected from nn.module class\n",
    "        optimizer_type: \"SGD\" or \"Adam\"\n",
    "        optimizer_like: \"torch.optim.SGD\" or \"torch.optim.Adam\" optimizer\n",
    "    \"\"\"\n",
    "    if optimizer_type == \"SGD\" or isinstance(optimizer_like, optim.SGD):\n",
    "        return optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
    "    elif optimizer_type == \"Adam\" or isinstance(optimizer_like, optim.Adam):\n",
    "        return optim.Adam(model.parameters())\n",
    "    \n",
    "def test(network, test_loader, device, mode='Benign', move_to_cpu_afterward=True,\n",
    "         test_train='Test'):\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            output = network(data)\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            test_loss += criterion(output, target).item()\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "    test_loss /= len(test_loader)\n",
    "    accuracy = float(correct / len(test_loader.dataset))\n",
    "    print(\n",
    "        (\n",
    "            f\"{mode} {test_train} set: Avg. loss: {test_loss}, \"\n",
    "            f\"Accuracy: {correct}/{len(test_loader.dataset)} ({100.0 * accuracy:5.03f}%)\"\n",
    "        )\n",
    "    )\n",
    "    if move_to_cpu_afterward:\n",
    "        network.to(\"cpu\")\n",
    "    return accuracy\n",
    "\n",
    "def scale_update_of_model(to_scale, global_model, scaling_factor):\n",
    "    \"\"\"\n",
    "    Scales the update of a local model (thus the difference between global and local model)\n",
    "    :param to_scale: local model as state dict\n",
    "    :pram global_model\n",
    "    :param scaling factor\n",
    "    :return scaled local model as state dict\n",
    "    \"\"\"\n",
    "    print(f'Scale Model by {scaling_factor}')\n",
    "    result = {}\n",
    "    for name, data in to_scale.items():\n",
    "        if not (name.endswith('.bias') or name.endswith('.weight')):\n",
    "            result[name] = data\n",
    "        else:\n",
    "            update = data - global_model[name]\n",
    "            scaled = scaling_factor * update\n",
    "            result[name] = scaled + global_model[name]\n",
    "    return result\n",
    "\n",
    "def create_cluster_map_from_labels(expected_number_of_labels, clustering_labels):\n",
    "    \"\"\"\n",
    "    Converts a list of labels into a dictionary where each label is the key and\n",
    "    the values are lists/np arrays of the indices from the samples that received\n",
    "    the respective label\n",
    "    :param expected_number_of_labels number of samples whose labels are contained in\n",
    "    clustering_labels\n",
    "    :param clustering_labels list containing the labels of each sample\n",
    "    :return dictionary of clusters\n",
    "    \"\"\"\n",
    "    assert len(clustering_labels) == expected_number_of_labels\n",
    "\n",
    "    clusters = {}\n",
    "    for i, cluster in enumerate(clustering_labels):\n",
    "        if cluster not in clusters:\n",
    "            clusters[cluster] = []\n",
    "        clusters[cluster].append(i)\n",
    "    return {index: np.array(cluster) for index, cluster in clusters.items()}\n",
    "\n",
    "\n",
    "def determine_biggest_cluster(clustering):\n",
    "    \"\"\"\n",
    "    Given a clustering, given as dictionary of the form {cluster_id: [items in cluster]}, the\n",
    "    function returns the id of the biggest cluster\n",
    "    \"\"\"\n",
    "    biggest_cluster_id = None\n",
    "    biggest_cluster_size = None\n",
    "    for cluster_id, cluster in clustering.items():\n",
    "        size_of_current_cluster = np.array(cluster).shape[0]\n",
    "        if biggest_cluster_id is None or size_of_current_cluster > biggest_cluster_size:\n",
    "            biggest_cluster_id = cluster_id\n",
    "            biggest_cluster_size = size_of_current_cluster\n",
    "    return biggest_cluster_id\n",
    "\n",
    "def trigger_single_image(image):\n",
    "    \"\"\"\n",
    "    Adds a red square with a height/width of 6 pixels into\n",
    "    the upper left corner of the given image.\n",
    "    @param image tensor, containing the normalized pixel values of the image.\n",
    "    The image will be modified in-place.\n",
    "    @return given image\n",
    "    \"\"\"\n",
    "    color = (torch.Tensor((1, 0, 0)) - MEAN) / STD_DEV\n",
    "    image[:, 0:6, 0:6] = color.repeat((6, 6, 1)).permute(2, 1, 0)\n",
    "    return image\n",
    "\n",
    "\n",
    "def poison_data(samples_to_poison, labels_to_poison, pdr=0.5):\n",
    "    \"\"\"\n",
    "    poisons a given local dataset, consisting of samples and labels, s.t.,\n",
    "    the given ratio of this image consists of samples for the backdoor behavior\n",
    "    :param samples_to_poison tensor containing all samples of the local dataset\n",
    "    :param labels_to_poison tensor containing all labels\n",
    "    :param pdr poisoned data rate\n",
    "    :return poisoned local dataset (samples, labels)\n",
    "    \"\"\"\n",
    "    if pdr == 0:\n",
    "        return samples_to_poison, labels_to_poison\n",
    "\n",
    "    assert 0 < pdr <= 1.0\n",
    "    samples_to_poison = samples_to_poison.clone()\n",
    "    labels_to_poison = labels_to_poison.clone()\n",
    "\n",
    "    dataset_size = samples_to_poison.shape[0]\n",
    "    num_samples_to_poison = int(dataset_size * pdr)\n",
    "    if num_samples_to_poison == 0:\n",
    "        # corner case for tiny pdrs\n",
    "        assert pdr > 0  # Already checked above\n",
    "        assert dataset_size > 1\n",
    "        num_samples_to_poison += 1\n",
    "\n",
    "    indices = np.random.choice(dataset_size, size=num_samples_to_poison, replace=False)\n",
    "    for image_index in indices:\n",
    "        image = trigger_single_image(samples_to_poison[image_index])\n",
    "        samples_to_poison[image_index] = image\n",
    "    labels_to_poison[indices] = 2\n",
    "    return samples_to_poison, labels_to_poison.long()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973b60f8",
   "metadata": {},
   "source": [
    "## CrowdGuardClientValidation\n",
    "\n",
    "The `FederatedRuntime`, as of now, requires all user-defined code to be included within the notebook. Therefore the definition of `CrowdGuardClientValidation` has to be here. Before it was inside `CrowdGuardClientValidation.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64eddf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "# Copyright (C) 2022-2024 TU Darmstadt\n",
    "# SPDX-License-Identifier: Apache-2.0\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# Primary author: Phillip Rieger <phillip.rieger@trust.tu-darmstadt.de>\n",
    "# Co-authored-by: Torsten Krauss <torsten.krauss@uni-wuerzburg.de>\n",
    "# ------------------------------------------------------------\n",
    "from enum import Enum\n",
    "from copy import deepcopy\n",
    "from scipy.stats import kstest, levene, ttest_ind, bartlett\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "class DistanceMetric(str, Enum):\n",
    "    \"\"\"Enum to identify distance metrics necessary in this project\"\"\"\n",
    "    COSINE = 'cosine'\n",
    "    EUCLIDEAN = 'euclid'\n",
    "\n",
    "\n",
    "class DistanceHandler:\n",
    "    \"\"\"Helper, that calculates distances between two tensors.\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def __get_euclid_distance(t1: torch.Tensor, t2: torch.Tensor) -> float:\n",
    "        t = t1.view(-1) - t2.view(-1)\n",
    "        return torch.norm(t, 2).cpu().item()\n",
    "\n",
    "    @staticmethod\n",
    "    def __get_cosine_distance(t1: torch.Tensor, t2: torch.Tensor) -> float:\n",
    "        t1 = t1.view(-1).reshape(1, -1)\n",
    "        t2 = t2.view(-1).reshape(1, -1)\n",
    "        return 1 - torch.cosine_similarity(t1, t2).cpu().item()\n",
    "\n",
    "    @staticmethod\n",
    "    def get_distance(distance: DistanceMetric, t1: torch.Tensor, t2: torch.Tensor) -> float:\n",
    "        \"\"\"Factory Method for Distances\"\"\"\n",
    "        if distance == DistanceMetric.COSINE:\n",
    "            return DistanceHandler.__get_cosine_distance(t1, t2)\n",
    "        if distance == DistanceMetric.EUCLIDEAN:\n",
    "            return DistanceHandler.__get_euclid_distance(t1, t2)\n",
    "\n",
    "        raise Exception(f\"Extractor for {distance} not implemented yet.\")\n",
    "\n",
    "\n",
    "class CrowdGuardClientValidation:\n",
    "\n",
    "    @staticmethod\n",
    "    def __distance_global_model_final_metric(distance_type: str, prediction_matrix,\n",
    "                                             prediction_global_model, sample_indices_by_label,\n",
    "                                             own_index):\n",
    "        \"\"\"\n",
    "        Calculates the distance matrix containing the metric for CrowdGuard\n",
    "        with dimensions label x model x layer x values\n",
    "        \"\"\"\n",
    "\n",
    "        sample_count = len(prediction_matrix)\n",
    "        model_count = len(prediction_matrix[0])\n",
    "        layer_count = len(prediction_matrix[0][0])\n",
    "\n",
    "        # We create a distance matrix with distances between global and local models\n",
    "        # of the dimensions sample x model x layer x values\n",
    "        global_distance_matrix = [[[0.] * layer_count for _ in range(model_count)]\n",
    "                                  for _ in range(sample_count)]\n",
    "        # 1. calculate distances between predictions of global model and each local model\n",
    "        for s_i, s in enumerate(prediction_matrix):\n",
    "            g = prediction_global_model[s_i]\n",
    "            for m_i, m in enumerate(s):\n",
    "                for l_i, l in enumerate(m):\n",
    "                    distance = DistanceHandler.get_distance(distance_type, l, g[\n",
    "                        l_i])  # either euclidean or cosine distance\n",
    "                    global_distance_matrix[s_i][m_i][l_i] = distance  # line 18\n",
    "\n",
    "        # 2. Sort the sample-wise distances by the label of the sample\n",
    "        for label, sample_list in sample_indices_by_label.items():\n",
    "            # First pick the samples from the global predictions\n",
    "            global_distance_matrix_for_label_helper = [\n",
    "                [[0.] * len(sample_list) for _ in range(layer_count)] for _ in\n",
    "                range(model_count)]\n",
    "\n",
    "            s_i_new = 0\n",
    "            for s_i, s in enumerate(global_distance_matrix):\n",
    "                if s_i not in sample_list:\n",
    "                    continue\n",
    "                for m_i, mi in enumerate(s):\n",
    "                    for l_i, l in enumerate(mi):\n",
    "                        global_distance_matrix_for_label_helper[m_i][l_i][s_i_new] = l\n",
    "                s_i_new += 1\n",
    "\n",
    "        # We produce the first relative matrix\n",
    "        sample_relation_matrix = [[[0.] * layer_count for _ in range(model_count)] for _ in\n",
    "                                  range(sample_count)]\n",
    "\n",
    "        # 3. divide by distances of this client to use its values as reference\n",
    "        for s_i, s in enumerate(global_distance_matrix):\n",
    "            distances_for_own_models_predictions = s[own_index]\n",
    "            for m_j, mj in enumerate(s):\n",
    "                for l_i, l in enumerate(mj):\n",
    "                    relation = 0\n",
    "                    if distances_for_own_models_predictions[l_i] != 0:\n",
    "                        relation = l / distances_for_own_models_predictions[l_i]\n",
    "                    sample_relation_matrix[s_i][m_j][l_i] = relation  # line 21\n",
    "\n",
    "        # We produce the Label average\n",
    "        # We produce a matrix with not all samples, but mean all the samples, so that we have a\n",
    "        # Matrix per label\n",
    "        sample_relation_matrix_for_label = {}\n",
    "\n",
    "        # 4. Transpose matrix as preparation for averaging\n",
    "        for label, sample_list in sample_indices_by_label.items():\n",
    "            sample_relation_matrix_for_label[label] = [[0.] * layer_count for _ in\n",
    "                                                       range(model_count)]\n",
    "            sample_relation_matrix_for_label_helper = [\n",
    "                [[0.] * len(sample_list) for _ in range(layer_count)] for _ in range(model_count)]\n",
    "            # transpose dimensions of distance matrix, before we had (sample,model, layer) and\n",
    "            # we transpose it to (model,layer,sample)\n",
    "            s_i_new = 0\n",
    "            for s_i, s in enumerate(sample_relation_matrix):\n",
    "                if s_i not in sample_list:\n",
    "                    continue\n",
    "                for m_j, mj in enumerate(s):\n",
    "                    for l_i, l in enumerate(mj):\n",
    "                        sample_relation_matrix_for_label_helper[m_j][l_i][s_i_new] = l\n",
    "                s_i_new += 1\n",
    "\n",
    "            # 5. Average over all samples from the same label (basically kick-out the last\n",
    "            # dimension)\n",
    "            for m_j, mj in enumerate(sample_relation_matrix_for_label_helper):\n",
    "                for l_i, l in enumerate(mj):\n",
    "                    sample_relation_matrix_for_label[label][m_j][l_i] = np.mean(l).item()\n",
    "\n",
    "        avg_sample_relation_matrix_squared_negative_models_first = {}\n",
    "\n",
    "        # 6. subtract 1 (mainly for cosine distances) and square (but keep the sign)\n",
    "        for label, label_values in sample_relation_matrix_for_label.items():\n",
    "            avg_sample_relation_matrix_squared_negative_models_first[label] = [[0.] * layer_count\n",
    "                                                                               for _ in\n",
    "                                                                               range(model_count)]\n",
    "            for m_j, mj in enumerate(label_values):\n",
    "                for l_i, l in enumerate(mj):\n",
    "                    x = l - 1\n",
    "                    relation = x * x\n",
    "                    relation = relation if x >= 0 else relation * (-1)\n",
    "                    avg_sample_relation_matrix_squared_negative_models_first[label][m_j][\n",
    "                        l_i] = relation\n",
    "        return avg_sample_relation_matrix_squared_negative_models_first\n",
    "\n",
    "    @staticmethod\n",
    "    def __predict_for_single_model(model, local_data, device):\n",
    "        \"\"\"\n",
    "        Returns\n",
    "        - A matrix with Deep Layer Outputs with dimensions sample x layer x values.\n",
    "        - The labels for all samples in the client's training dataset\n",
    "        - The number of layers defined in the model\n",
    "        \"\"\"\n",
    "        num_layers = None\n",
    "        sample_label_list = []\n",
    "        predictions = []\n",
    "        model.eval()\n",
    "        model = model.to(device)\n",
    "        number_of_previous_samples = 0\n",
    "        for batch_id, batch in enumerate(local_data):\n",
    "            data, target = batch\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model.predict_internal_states(data)\n",
    "            if num_layers is None:\n",
    "                num_layers = len(output)\n",
    "            assert num_layers == len(output)\n",
    "\n",
    "            for layer_output_index, layer_output_values in enumerate(output):\n",
    "                for idx in range(target.shape[0]):\n",
    "                    sample_idx = number_of_previous_samples + idx\n",
    "                    assert len(predictions) >= sample_idx\n",
    "                    if len(predictions) == sample_idx:\n",
    "                        assert layer_output_index == 0\n",
    "                        predictions.append([])\n",
    "\n",
    "                    if layer_output_index == 0:\n",
    "                        expected_predictions = sample_idx + 1\n",
    "                    else:\n",
    "                        expected_predictions = number_of_previous_samples + target.shape[0]\n",
    "                    assert_msg = f'{len(predictions)} vs. {sample_idx} ({idx} {batch_id} '\n",
    "                    assert_msg += f'{layer_output_index} {number_of_previous_samples})'\n",
    "                    assert len(predictions) == expected_predictions, assert_msg\n",
    "                    assert_msg = f'{len(predictions[sample_idx])} {layer_output_index} '\n",
    "                    assert_msg += f'{sample_idx} {batch_id} {idx} {number_of_previous_samples}'\n",
    "                    assert len(predictions[sample_idx]) == layer_output_index, assert_msg\n",
    "                    value = layer_output_values[idx].clone().detach().cpu()\n",
    "                    predictions[sample_idx].append(value)\n",
    "            number_of_previous_samples += target.shape[0]\n",
    "            for t in target:\n",
    "                sample_label_list.append(t.detach().clone().cpu().item())\n",
    "        model.cpu()\n",
    "        return predictions, sample_label_list, num_layers\n",
    "\n",
    "    @staticmethod\n",
    "    def __do_predictions(models, global_model, local_data, device):\n",
    "        \"\"\"\n",
    "        Returns\n",
    "        - The Deep Layer Outputs for all models in a matrix of dimension\n",
    "          sample x model x layer x value\n",
    "        - The Deep Layer Outputs of the global model int he dimension sample x layer x value\n",
    "        - A dict containing lists of sample indices for each label class\n",
    "        - The number of layers from the model\n",
    "        \"\"\"\n",
    "        all_models_predictions = []\n",
    "        for model_index, model in enumerate(models):\n",
    "            predictions, _, _ = CrowdGuardClientValidation.__predict_for_single_model(model,\n",
    "                                                                                      local_data,\n",
    "                                                                                      device)\n",
    "            for sample_index, layer_predictions_for_sample in enumerate(predictions):\n",
    "                # why not just append?\n",
    "                if sample_index >= len(all_models_predictions):\n",
    "                    assert model_index == 0\n",
    "                    assert len(all_models_predictions) == sample_index\n",
    "                    all_models_predictions.append([])\n",
    "                all_models_predictions[sample_index].append(layer_predictions_for_sample)\n",
    "        tmp = CrowdGuardClientValidation.__predict_for_single_model(global_model, local_data,\n",
    "                                                                    device)\n",
    "        global_model_predictions, sample_label_list, n_layers = tmp\n",
    "        sample_indices_by_label = {}\n",
    "        for s_i, label in enumerate(sample_label_list):\n",
    "            if label not in sample_indices_by_label.keys():\n",
    "                sample_indices_by_label[label] = []\n",
    "            sample_indices_by_label[label].append(s_i)\n",
    "\n",
    "        return all_models_predictions, global_model_predictions, sample_indices_by_label, n_layers\n",
    "\n",
    "    @staticmethod\n",
    "    def __prune_poisoned_models(num_layers, total_number_of_clients, own_client_index,\n",
    "                                distances_by_metric, verbose=False):\n",
    "        detected_poisoned_models = []\n",
    "        for distance_type in distances_by_metric.keys():\n",
    "\n",
    "            # First load the distance Matrix for this client and the samples by labels.\n",
    "            distance_matrix_la_m_l = distances_by_metric[distance_type]\n",
    "\n",
    "            # We put all of our labels into one big row.\n",
    "            layer_length = num_layers * len(distance_matrix_la_m_l)\n",
    "            dist_matrix_m_lcon = [[0.] * layer_length for _ in range(total_number_of_clients)]\n",
    "            label_count = 0\n",
    "            for label_x, dist_matrix_m_l_for_label in distance_matrix_la_m_l.items():\n",
    "                for model_idx, model_values in enumerate(dist_matrix_m_l_for_label):\n",
    "                    for layer_idx, layer in enumerate(model_values):\n",
    "                        dist_matrix_m_lcon[model_idx][layer_idx + label_count * num_layers] = layer\n",
    "                label_count = label_count + 1\n",
    "\n",
    "            dist_matrix_m_l = dist_matrix_m_lcon\n",
    "\n",
    "            client_indices = [i for i, _ in enumerate(dist_matrix_m_l) if i != own_client_index]\n",
    "            pruned_indices = []\n",
    "            has_malicious_model = True\n",
    "            new_round_needed = True\n",
    "            prune_idx = 0\n",
    "\n",
    "            max_pruning_count = (len(dist_matrix_m_l) - 1) // 2\n",
    "\n",
    "            while has_malicious_model and new_round_needed:\n",
    "                # unique\n",
    "                pruned_indices_local = deepcopy(pruned_indices)\n",
    "                # Ignore the own label again and the pruned indices\n",
    "                pruned_cluster_input_m_l = [\n",
    "                    value for i, value in enumerate(dist_matrix_m_l) \n",
    "                    if i != own_client_index and i not in pruned_indices\n",
    "                    ]\n",
    "                pruned_client_indices = [\n",
    "                    i for i, value in enumerate(dist_matrix_m_l) \n",
    "                    if i != own_client_index and i not in pruned_indices\n",
    "                    ]\n",
    "\n",
    "                if len(pruned_cluster_input_m_l) <= 1:\n",
    "                    break\n",
    "\n",
    "                layer_values = {}\n",
    "\n",
    "                for m in pruned_cluster_input_m_l:\n",
    "                    for l_i, l in enumerate(m):\n",
    "                        if l_i not in layer_values.keys():\n",
    "                            layer_values[l_i] = []\n",
    "                        layer_values[l_i].append(l)\n",
    "\n",
    "                median_layer_values = []\n",
    "\n",
    "                for l_i, l_values in layer_values.items():\n",
    "                    median_layer_values.append(np.median(l_values).item())\n",
    "\n",
    "                median_graph = list(median_layer_values)\n",
    "\n",
    "                pca_list = []\n",
    "                for m in pruned_cluster_input_m_l:\n",
    "                    pca_list.append(m)\n",
    "\n",
    "                pca_list.append(median_graph)\n",
    "\n",
    "                scaled_data = preprocessing.scale(pca_list)\n",
    "\n",
    "                pca = PCA()\n",
    "                pca.fit(scaled_data)\n",
    "                pca_data = pca.transform(scaled_data)\n",
    "\n",
    "                cluster_input = []\n",
    "                cluster_input_plain = []\n",
    "                pca_one_data = pca_data.T[0]\n",
    "                for pca_one_value in pca_one_data:\n",
    "                    cluster_input.append([pca_one_value])\n",
    "                    cluster_input_plain.append(pca_one_value)\n",
    "\n",
    "                # Significance tests\n",
    "                median_val = np.median(cluster_input_plain)\n",
    "                if verbose:\n",
    "                    print(f'cluster_input_plain={cluster_input_plain}')\n",
    "                x_values = []\n",
    "                y_values = []\n",
    "                for value in cluster_input_plain:\n",
    "                    # Split the samples into two groups\n",
    "                    distance_value = abs(value - median_val)\n",
    "                    if value >= median_val:\n",
    "                        x_values.append(distance_value)\n",
    "                    else:\n",
    "                        y_values.append(distance_value)\n",
    "                print(f'Distance: {distance_type}, use y {len(y_values)}: {y_values}')\n",
    "                print(f'Distance: {distance_type}, use x {len(x_values)}: {x_values}')\n",
    "\n",
    "                # Statistical tests\n",
    "                t_value, t_p_value = ttest_ind(x_values, y_values)\n",
    "                ks_value, ks_p_value = kstest(x_values, y_values)\n",
    "                barlett_value, bartlett_p_value = levene(x_values, y_values)\n",
    "                # Outlier tests\n",
    "                # Creating boxplot\n",
    "                bp_result = plt.boxplot(cluster_input_plain, whis=5.5)\n",
    "                fliers = bp_result['fliers'][0].get_ydata()\n",
    "                outlier_boxplot = len(fliers)\n",
    "                plt.close()\n",
    "\n",
    "                # Outlier based on variance\n",
    "                deviation_mean = np.mean(cluster_input_plain)\n",
    "                deviation_std = abs(np.std(cluster_input_plain))\n",
    "\n",
    "                max_dist_rule_factor = 0\n",
    "                for cip in cluster_input_plain:\n",
    "                    cip_abs = abs(cip - deviation_mean)\n",
    "                    rule_factor = cip_abs / deviation_std\n",
    "                    if max_dist_rule_factor < rule_factor:\n",
    "                        max_dist_rule_factor = rule_factor\n",
    "\n",
    "                outlier_three_sigma = max_dist_rule_factor\n",
    "\n",
    "                has_malicious_model_t_threshold = True if t_p_value < 0.01 else False\n",
    "                has_malicious_model_ks_threshold = True if ks_p_value < 0.01 else False\n",
    "                has_malicious_model_bartlett_threshold = True if bartlett_p_value < 0.01 else False\n",
    "\n",
    "                has_boxplot_outlier = True if outlier_boxplot > 0 else False\n",
    "                has_three_sigma_outlier = True if outlier_three_sigma >= 3 else False\n",
    "\n",
    "                # Choose exit criterium\n",
    "                has_malicious_model = (has_malicious_model_t_threshold\n",
    "                                       or has_malicious_model_ks_threshold\n",
    "                                       or has_malicious_model_bartlett_threshold\n",
    "                                       or has_boxplot_outlier\n",
    "                                       or has_three_sigma_outlier)\n",
    "                \n",
    "                # print(f'{t_p_value:.2f}, {ks_p_value:.2f}, {bartlett_p_value:.2f}, {outlier_boxplot:.2f}, {outlier_three_sigma:.2f}')\n",
    "\n",
    "                ac_e = AgglomerativeClustering(n_clusters=2, distance_threshold=None,\n",
    "                                               compute_full_tree=True,\n",
    "                                               metric=\"euclidean\", memory=None,\n",
    "                                               connectivity=None,\n",
    "                                               linkage='single',\n",
    "                                               compute_distances=True).fit(cluster_input)\n",
    "                ac_e_labels: list = ac_e.labels_.tolist()\n",
    "                median_value_cluster_label = ac_e_labels[-1]\n",
    "                ac_e_malicious_class_indices = [idx for idx, val in enumerate(ac_e_labels) if\n",
    "                                                val != median_value_cluster_label]\n",
    "\n",
    "                for m_j, value in enumerate(pruned_client_indices):\n",
    "                    if m_j in ac_e_malicious_class_indices:\n",
    "                        pruned_indices_local.append(value)\n",
    "\n",
    "                pruned_indices_local = list(set(pruned_indices_local))\n",
    "\n",
    "                # If we now prune more than half, we stop and remove the best items from the last\n",
    "                # pruning list.\n",
    "                pruned_too_much = True\n",
    "                if len(pruned_indices_local) > max_pruning_count:\n",
    "                    dist_values_of_pruned_models = []\n",
    "                    for midx in ac_e_malicious_class_indices:\n",
    "                        dist_to_median = abs(cluster_input[midx][0] - cluster_input[-1][0])\n",
    "                        dist_values_of_pruned_models.append(dist_to_median)\n",
    "\n",
    "                    sorted_dist_values_of_pruned_models = list(dist_values_of_pruned_models)\n",
    "                    sorted_dist_values_of_pruned_models.sort()\n",
    "\n",
    "                    sorted_ac_e_malicious_class_indices = []\n",
    "                    for sdv in sorted_dist_values_of_pruned_models:\n",
    "                        dvidx = dist_values_of_pruned_models.index(sdv)\n",
    "                        for m_j, value in enumerate(pruned_client_indices):\n",
    "                            if m_j == ac_e_malicious_class_indices[dvidx]:\n",
    "                                sorted_ac_e_malicious_class_indices.append(value)\n",
    "                    overflowed_count = len(pruned_indices_local) - max_pruning_count\n",
    "                    for oc in range(overflowed_count):\n",
    "                        # Get the values of the clusters and remove the nearest ones\n",
    "                        # from pruned_indices_local\n",
    "                        pruned_indices_local.remove(sorted_ac_e_malicious_class_indices[-1])\n",
    "                        del sorted_ac_e_malicious_class_indices[-1]\n",
    "                    pruned_too_much = False\n",
    "\n",
    "                still_pruning = len(pruned_indices) < len(pruned_indices_local)\n",
    "                new_round_needed = still_pruning and pruned_too_much\n",
    "                if has_malicious_model and new_round_needed:\n",
    "                    pruned_indices = pruned_indices_local\n",
    "\n",
    "                prune_idx += 1\n",
    "\n",
    "            # Analyze the voting\n",
    "            for value in client_indices:\n",
    "                if value in pruned_indices:\n",
    "                    detected_poisoned_models.append(value)\n",
    "\n",
    "        return list(set(detected_poisoned_models))\n",
    "\n",
    "    @staticmethod\n",
    "    def validate_models(global_model, models, own_client_index, local_data, device):\n",
    "        tmp = CrowdGuardClientValidation.__do_predictions(models, global_model, local_data, device)\n",
    "        prediction_matrix, global_model_predictions, sample_indices_by_label, num_layers = tmp\n",
    "        distances_by_metric = {}\n",
    "        for dist_type in [DistanceMetric.COSINE, DistanceMetric.EUCLIDEAN]:\n",
    "            calculated_distances = CrowdGuardClientValidation.__distance_global_model_final_metric(\n",
    "                dist_type,\n",
    "                prediction_matrix,\n",
    "                global_model_predictions,\n",
    "                sample_indices_by_label,\n",
    "                own_client_index)\n",
    "            distances_by_metric[dist_type] = calculated_distances\n",
    "        result = CrowdGuardClientValidation.__prune_poisoned_models(num_layers, len(models),\n",
    "                                                                    own_client_index,\n",
    "                                                                    distances_by_metric)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ed5e31",
   "metadata": {},
   "source": [
    "## Workflow definition\n",
    "Next we import the FLSpec, placement decorators (aggregator/collaborator), and define the FedAvg helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee9e725",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "from openfl.experimental.workflow.interface import FLSpec\n",
    "from openfl.experimental.workflow.placement import aggregator, collaborator\n",
    "\n",
    "def FedAvg(models):  # NOQA: N802\n",
    "    \"\"\"\n",
    "    Return a Federated average model based on Fedavg algorithm: H. B. Mcmahan,\n",
    "    E. Moore, D. Ramage, S. Hampson, and B. A. Y.Arcas,\n",
    "    “Communication-efficient learning of deep networks from decentralized data,” 2017.\n",
    "\n",
    "    Args:\n",
    "        models: Python list of locally trained models by each collaborator\n",
    "    \"\"\"\n",
    "    new_model = models[0]\n",
    "    if len(models) > 1:\n",
    "        state_dicts = [model.state_dict() for model in models]\n",
    "        state_dict = new_model.state_dict()\n",
    "        for key in models[1].state_dict():\n",
    "            state_dict[key] = torch.from_numpy(\n",
    "                np.average([state[key].numpy() for state in state_dicts], axis=0))\n",
    "        new_model.load_state_dict(state_dict)\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c4a752",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "from sklearn.cluster import AgglomerativeClustering, DBSCAN\n",
    "\n",
    "class FederatedFlow_CrowdGuard(FLSpec):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        optimizer_type,\n",
    "        total_rounds=50,\n",
    "        top_model_accuracy=0,\n",
    "        pmr=0.25,\n",
    "        aggregation_algorithm='CrowdGuard',\n",
    "        **kwargs, \n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.aggregation_algorithm = aggregation_algorithm\n",
    "        self.model = model\n",
    "        self.global_model = Net()\n",
    "        self.pmr = pmr\n",
    "        self.start_time = None\n",
    "        self.collaborators = None\n",
    "        self.private = None\n",
    "        self.optimizer_type = optimizer_type\n",
    "        self.total_rounds = total_rounds\n",
    "        self.top_model_accuracy = top_model_accuracy\n",
    "        if torch.cuda.is_available():\n",
    "            self.device = torch.device(\n",
    "                \"cuda:1\"\n",
    "            )  # This will enable Ray library to reserve available GPU(s) for the task\n",
    "        elif torch.backends.mps.is_available():\n",
    "            self.device = torch.device(\"mps\")\n",
    "        else:\n",
    "            self.device = torch.device(\"cpu\")\n",
    "        print(f\"Using device: {self.device}\")\n",
    "        self.round_num = 0  # starting round\n",
    "        print(20 * \"#\")\n",
    "        print(f\"Round {self.round_num}...\")\n",
    "        print(20 * \"#\")\n",
    "        print(20 * \"#\")\n",
    "        print(f\"Round {self.round_num}...\")\n",
    "        print(20 * \"#\")\n",
    "\n",
    "    @aggregator\n",
    "    def start(self):\n",
    "        print(\"Performing initialization for model\")\n",
    "        self.collaborators = self.runtime.collaborators\n",
    "        self.private = 10\n",
    "        self.next(\n",
    "            self.train,\n",
    "            foreach=\"collaborators\",\n",
    "            exclude=[\"private\"],\n",
    "        )\n",
    "\n",
    "    @collaborator\n",
    "    def train(self):\n",
    "        self.collaborator_name = self.input\n",
    "        print(20 * \"#\")\n",
    "        print(f\"Performing model training for collaborator {self.input} in round {self.round_num}\")\n",
    "\n",
    "        self.model.to(self.device)\n",
    "        original_model = {n: d.clone() for n, d in self.model.state_dict().items()}\n",
    "        test(self.model, self.train_loader, self.device, move_to_cpu_afterward=False,\n",
    "             test_train='Train')\n",
    "        test(self.model, self.test_loader, self.device, move_to_cpu_afterward=False)\n",
    "        test(self.model, self.backdoor_test_loader, self.device, mode='Backdoor',\n",
    "             move_to_cpu_afterward=False)\n",
    "        self.optimizer = default_optimizer(self.model, self.optimizer_type)\n",
    "\n",
    "        self.model.train()\n",
    "        train_losses = []\n",
    "        for batch_idx, (data, target) in enumerate(self.train_loader):\n",
    "            data = data.to(self.device)\n",
    "            target = target.to(self.device)\n",
    "            self.optimizer.zero_grad()\n",
    "            output = self.model(data)\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            loss = criterion(output, target).to(self.device)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            if batch_idx % LOG_INTERVAL == 0:\n",
    "                train_losses.append(loss.item())\n",
    "\n",
    "        self.loss = np.mean(train_losses)\n",
    "        self.training_completed = True\n",
    "\n",
    "        test(self.model, self.train_loader, self.device, move_to_cpu_afterward=False,\n",
    "             test_train='Train')\n",
    "        test(self.model, self.test_loader, self.device, move_to_cpu_afterward=False)\n",
    "        test(self.model, self.backdoor_test_loader, self.device, mode='Backdoor',\n",
    "             move_to_cpu_afterward=False)\n",
    "        if 'malicious' in self.input:\n",
    "            weights = self.model.state_dict()\n",
    "            scaled = scale_update_of_model(weights, original_model, 1 / self.pmr)\n",
    "            self.model.load_state_dict(scaled)\n",
    "        self.model.to(\"cpu\")\n",
    "        torch.cuda.empty_cache()\n",
    "        if self.aggregation_algorithm == 'FedAVG':\n",
    "            self.next(self.fed_avg_aggregation, exclude=[\"training_completed\"])\n",
    "        else:\n",
    "            self.next(self.collect_models, exclude=[\"training_completed\"])\n",
    "\n",
    "    @aggregator\n",
    "    def fed_avg_aggregation(self, inputs):\n",
    "        self.all_models = {input.collaborator_name: input.model.cpu() for input in inputs}\n",
    "        self.model = FedAvg([m.cpu() for m in self.all_models.values()])\n",
    "        self.round_num += 1\n",
    "        if self.round_num + 1 < self.total_rounds:\n",
    "            self.next(self.train, foreach=\"collaborators\")\n",
    "        else:\n",
    "            self.next(self.end)\n",
    "\n",
    "    @aggregator\n",
    "    def collect_models(self, inputs):\n",
    "        # Following the CrowdGuard paper, this should be executed within SGX\n",
    "\n",
    "        self.all_models = {i.collaborator_name: i.model.cpu() for i in inputs}\n",
    "        self.next(self.local_validation, foreach=\"collaborators\")\n",
    "\n",
    "    @collaborator\n",
    "    def local_validation(self):\n",
    "        # Following the CrowdGuard paper, this should be executed within SGX\n",
    "        print(\n",
    "            f\"Performing model validation for collaborator {self.input} in round {self.round_num}\"\n",
    "        )\n",
    "        self.collaborator_name = self.input\n",
    "        all_names = list(self.all_models.keys())\n",
    "        all_models = [self.all_models[n] for n in all_names]\n",
    "        own_client_index = all_names.index(self.collaborator_name)\n",
    "        detected_suspicious_models = CrowdGuardClientValidation.validate_models(self.global_model,\n",
    "                                                                                all_models,\n",
    "                                                                                own_client_index,\n",
    "                                                                                self.train_loader,\n",
    "                                                                                self.device)\n",
    "        detected_suspicious_models = sorted(detected_suspicious_models)\n",
    "        print(\n",
    "            f'Suspicious Models detected by {own_client_index}: {detected_suspicious_models}')\n",
    "\n",
    "        votes_of_this_client = []\n",
    "        for c in range(len(all_models)):\n",
    "            if c == own_client_index:\n",
    "                votes_of_this_client.append(VOTE_FOR_BENIGN)\n",
    "            elif c in detected_suspicious_models:\n",
    "                votes_of_this_client.append(VOTE_FOR_POISONED)\n",
    "            else:\n",
    "                votes_of_this_client.append(VOTE_FOR_BENIGN)\n",
    "        self.votes_of_this_client = {}\n",
    "        for name, vote in zip(all_names, votes_of_this_client):\n",
    "            self.votes_of_this_client[name] = vote\n",
    "\n",
    "        self.next(self.defend)\n",
    "\n",
    "    @aggregator\n",
    "    def defend(self, inputs):\n",
    "        # Following the CrowdGuard paper, this should be executed within SGX\n",
    "\n",
    "        all_names = list(self.all_models.keys())\n",
    "        all_votes_by_name = {i.collaborator_name: i.votes_of_this_client for i in inputs}\n",
    "\n",
    "        all_models = [self.all_models[name] for name in all_names]\n",
    "        binary_votes = [[all_votes_by_name[own_name][val_name] for val_name in all_names] for\n",
    "                        own_name in all_names]\n",
    "\n",
    "        ac_e = AgglomerativeClustering(n_clusters=2, distance_threshold=None,\n",
    "                                       compute_full_tree=True,\n",
    "                                       metric=\"euclidean\", memory=None, connectivity=None,\n",
    "                                       linkage='single',\n",
    "                                       compute_distances=True).fit(binary_votes)\n",
    "        ac_e_labels: list = ac_e.labels_.tolist()\n",
    "        agglomerative_result = create_cluster_map_from_labels(len(all_names), ac_e_labels)\n",
    "        print(f'Agglomerative Clustering: {agglomerative_result}')\n",
    "        agglomerative_negative_cluster = agglomerative_result[\n",
    "            determine_biggest_cluster(agglomerative_result)]\n",
    "\n",
    "        db_scan_input_idx_list = agglomerative_negative_cluster\n",
    "        print(f'DBScan Input: {db_scan_input_idx_list}')\n",
    "        db_scan_input_list = [binary_votes[vote_id] for vote_id in db_scan_input_idx_list]\n",
    "\n",
    "        db = DBSCAN(eps=0.5, min_samples=1).fit(db_scan_input_list)\n",
    "        dbscan_clusters = create_cluster_map_from_labels(len(agglomerative_negative_cluster),\n",
    "                                                         db.labels_.tolist())\n",
    "        biggest_dbscan_cluster = dbscan_clusters[determine_biggest_cluster(dbscan_clusters)]\n",
    "        print(f'DBScan Clustering: {biggest_dbscan_cluster}')\n",
    "\n",
    "        single_sample_of_biggest_cluster = biggest_dbscan_cluster[0]\n",
    "        final_voting = db_scan_input_list[single_sample_of_biggest_cluster]\n",
    "        negatives = [i for i, vote in enumerate(final_voting) if vote == VOTE_FOR_BENIGN]\n",
    "        recognized_benign_models = [all_models[n] for n in negatives]\n",
    "\n",
    "        print(f'Negatives: {negatives}')\n",
    "\n",
    "        self.model = FedAvg([m.cpu() for m in recognized_benign_models])\n",
    "        del inputs\n",
    "        self.round_num += 1\n",
    "        if self.round_num < self.total_rounds:\n",
    "            print(f'Finished round {self.round_num}/{self.total_rounds}')\n",
    "            self.next(self.train, foreach=\"collaborators\")\n",
    "        else:\n",
    "            self.next(self.end)\n",
    "\n",
    "    @aggregator\n",
    "    def end(self):\n",
    "        print(20 * \"#\")\n",
    "        print(\"All rounds completed successfully\")\n",
    "        print(20 * \"#\")\n",
    "        print(\"This is the end of the flow\")\n",
    "        print(20 * \"#\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5371b6d",
   "metadata": {},
   "source": [
    "## Defining and Initializing the Federated Runtime\n",
    "We initialize the Federated Runtime by providing:\n",
    "- `director_info`: The director's connection information \n",
    "- `authorized_collaborators`: A list of authorized collaborators\n",
    "- `notebook_path`: Path to this Jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1715a373",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "from openfl.experimental.workflow.runtime import FederatedRuntime\n",
    "\n",
    "director_info = {\n",
    "    'director_node_fqdn':'localhost',\n",
    "    'director_port':50050,\n",
    "}\n",
    "\n",
    "authorized_collaborators = ['Amsterdam', 'Bangalore', 'Chandler', 'Detroit']\n",
    "\n",
    "federated_runtime = FederatedRuntime(\n",
    "    collaborators=authorized_collaborators,\n",
    "    director=director_info, \n",
    "    notebook_path='./FederatedCrowdGuard.ipynb',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de9684f",
   "metadata": {},
   "source": [
    "The status of the connected Envoys can be checked using the `get_envoys()` method of the `federated_runtime`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1be87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "federated_runtime.get_envoys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eaeca25",
   "metadata": {},
   "source": [
    "With the federated_runtime now instantiated, we will proceed to deploy the workspace and run the experiment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d19819",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "seed_random_generators(RANDOM_SEED)\n",
    "\n",
    "model = Net()\n",
    "pmr = NUMBER_OF_MALICIOUS_CLIENTS / TOTAL_CLIENT_NUMBER\n",
    "\n",
    "flflow = FederatedFlow_CrowdGuard(\n",
    "    model,\n",
    "    optimizer_type='SGD',\n",
    "    total_rounds = 5,\n",
    "    top_model_accuracy = 0,\n",
    "    pmr = pmr,\n",
    "    aggregation_algorithm = 'CrowdGuard'\n",
    ")\n",
    "\n",
    "flflow.runtime = federated_runtime\n",
    "flflow.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
