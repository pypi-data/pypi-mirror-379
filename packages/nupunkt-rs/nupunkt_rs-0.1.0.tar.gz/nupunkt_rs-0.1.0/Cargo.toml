[package]
name = "nupunkt-rs"
version = "0.1.0"
edition = "2021"
description = "High-performance Rust implementation of nupunkt sentence/paragraph tokenization"
readme = "README.md"
license = "MIT"
repository = "https://github.com/alea-institute/nupunkt-rs"
keywords = ["nlp", "tokenization", "sentence-boundary", "punkt", "python"]
authors = ["ALEA Institute <hello@aleainstitute.ai>"]
homepage = "https://aleainstitute.ai"
[lib]
name = "nupunkt_rs"
crate-type = ["cdylib", "rlib"]

[features]
default = []
default-model = []

[[bin]]
name = "nupunkt"
path = "src/bin/nupunkt.rs"

[dependencies]
ahash = "0.8.12"
anyhow = "1.0.98"
clap = { version = "4.5.20", features = ["derive"] }
flate2 = "1.1.2"
lru = "0.16.0"
once_cell = "1.21.3"
pyo3 = { version = "0.24.0", features = ["extension-module", "abi3-py311"] }
regex = "1.11.1"
serde = { version = "1.0.219", features = ["derive"] }
serde_json = "1.0.142"
smallvec = { version = "1.15.1", features = ["serde", "union"] }

[profile.release]
opt-level = 3
lto = true
codegen-units = 1
strip = true

[[bench]]
name = "tokenization"
harness = false

[dev-dependencies]
criterion = "0.7.0"
proptest = "1.7.0"
