# CHSH Inequality Analysis
#
# This analysis examines the Clauser-Horne-Shimony-Holt (CHSH) inequality,
# a mathematical constraint that distinguishes between different types of
# correlations. The CHSH inequality establishes that certain measurement
# correlations cannot exceed a value of 2 when the underlying system follows
# local realistic principles. Quantum mechanics predicts correlations that
# violate this bound, demonstrating contextuality that cannot be explained
# by any single unified classical model.

import numpy as np
from math import cos, pi
import itertools
import matplotlib
import matplotlib.pyplot as plt
import warnings

# Import the mathematical theory of contradiction library
from contrakit import Space, Behavior
from contrakit.constants import DEFAULT_SEED

# Import QuTiP for quantum mechanical calculations
import qutip as qt

# Import common utilities
from examples.quantum.utils import (
    pretty_witness, save_figure, display_figure,
    print_section_header, print_subsection_header, create_analysis_header,
    extract_behavior_properties, format_behavior_verdict, print_behavior_analysis,
    sanitize_pmf, print_boundary_analysis
)

matplotlib.use("Agg")
warnings.filterwarnings("ignore", category=UserWarning, module="cvxpy")


# Define the possible measurement outcomes for each party
OUTCOMES = [(+1, +1), (+1, -1), (-1, +1), (-1, -1)]

# Pre-defined CHSH measurement space and mapping (constant for all configurations)
CHSH_SPACE = Space.create(
    A0=[-1, +1],  # Alice's first measurement
    A1=[-1, +1],  # Alice's second measurement
    B0=[-1, +1],  # Bob's first measurement
    B1=[-1, +1],  # Bob's second measurement
)

# Map correlation labels to measurement combinations
CHSH_MEASUREMENT_COMBINATIONS = {
    "00": ("A0", "B0"),  # Alice measures A0, Bob measures B0
    "01": ("A0", "B1"),  # Alice measures A0, Bob measures B1
    "10": ("A1", "B0"),  # Alice measures A1, Bob measures B0
    "11": ("A1", "B1"),  # Alice measures A1, Bob measures B1
}

# -----------------------------
# CHSH calculation functions
# -----------------------------

def chsh_value(E00, E01, E10, E11):
    """
    Calculate the CHSH inequality value using the standard combination of signs.

    The CHSH inequality tests whether the combination |E₀₀ + E₀₁ + E₁₀ - E₁₁| ≤ 2,
    where Eᵢⱼ represents the correlation between measurement choices i and j.

    Parameters
    ----------
    E00, E01, E10, E11 : float
        Correlation coefficients for the four measurement combinations:
        E00 = ⟨A₀B₀⟩, E01 = ⟨A₀B₁⟩, E10 = ⟨A₁B₀⟩, E11 = ⟨A₁B₁⟩

    Returns
    -------
    float
        The CHSH test statistic for this specific combination of correlations
    """
    return abs(E00 + E01 + E10 - E11)

def chsh_maximum(E00, E01, E10, E11):
    """
    Calculate the maximum CHSH inequality value over all valid sign combinations.

    The CHSH inequality considers different ways to combine the correlation terms.
    While the standard form uses |E₀₀ + E₀₁ + E₁₀ - E₁₁|, other combinations
    like |E₀₀ - E₀₁ + E₁₀ + E₁₁| may give higher values depending on the data.

    Parameters
    ----------
    E00, E01, E10, E11 : float
        Correlation coefficients for the four measurement combinations

    Returns
    -------
    float
        The maximum CHSH value across all valid combinations of signs
    """
    correlations = [E00, E01, E10, E11]
    maximum_value = 0.0

    # Try all possible sign combinations that satisfy the CHSH constraint
    for signs in itertools.product([-1, 1], repeat=4):
        if signs[0] * signs[1] * signs[2] * signs[3] == -1:  # CHSH constraint
            chsh_val = abs(sum(sign * corr for sign, corr in zip(signs, correlations)))
            maximum_value = max(maximum_value, chsh_val)

    return maximum_value


def create_behavior_from_correlations(correlations_dict):
    """
    Construct a Behavior object from CHSH experimental data.

    Uses pre-defined CHSH measurement space and mapping.

    Parameters
    ----------
    correlations_dict : dict
        Dictionary containing probability distributions for each measurement
        configuration. Keys '00', '01', '10', '11' correspond to:
        - '00': Alice measures A₀, Bob measures B₀
        - '01': Alice measures A₀, Bob measures B₁
        - '10': Alice measures A₁, Bob measures B₀
        - '11': Alice measures A₁, Bob measures B₁

    Returns
    -------
    Behavior
        A behavior object encapsulating the experimental correlations
    """
    contexts_data = {}
    for label, probabilities in correlations_dict.items():
        measurement_pair = CHSH_MEASUREMENT_COMBINATIONS[label]

        # Initialize probability distribution for all possible outcomes
        probability_distribution = {outcome: 0.0 for outcome in CHSH_SPACE.outcomes_for(measurement_pair)}

        # Fill in the actual probabilities
        for outcome, probability in probabilities.items():
            probability_distribution[outcome] = float(probability)

        # Sanitize to handle any numerical drift
        contexts_data[measurement_pair] = sanitize_pmf(probability_distribution)

    return Behavior.from_contexts(CHSH_SPACE, contexts_data)

# -----------------------------
# Quantum state preparation and measurement simulation
# -----------------------------

def create_singlet_state():
    """
    Prepare the quantum singlet state |ψ⁻⟩ = (|01⟩ - |10⟩)/√2.

    The singlet state is a maximally entangled two-qubit quantum state where
    the measurements of the two particles are perfectly anticorrelated in any
    direction. This state achieves the maximum possible quantum correlations.

    Returns
    -------
    qt.Qobj
        Density matrix representation of the singlet state
    """
    up = qt.basis(2, 0)  # |↑⟩ state
    down = qt.basis(2, 1)  # |↓⟩ state

    # Create singlet state: (|01⟩ - |10⟩)/√2
    psi = (qt.tensor(up, down) - qt.tensor(down, up)).unit()
    return qt.ket2dm(psi)

def create_spin_measurement(angle):
    """
    Construct a spin measurement operator for a given orientation angle.

    This creates a quantum observable that measures spin along the direction
    (cos θ, sin θ, 0) in the equatorial plane. The measurement outcomes are
    +1 (spin up along this direction) and -1 (spin down along this direction).

    Parameters
    ----------
    angle : float
        Measurement direction angle in radians (θ = 0 corresponds to +x direction)

    Returns
    -------
    qt.Qobj
        Quantum mechanical operator representing the spin measurement
    """
    return np.cos(angle) * qt.sigmax() + np.sin(angle) * qt.sigmay()

def create_measurement_projectors(angle):
    """
    Create projectors for +1 and -1 outcomes of a spin measurement.

    Parameters
    ----------
    angle : float
        Measurement angle in radians

    Returns
    -------
    tuple of qt.Qobj
        Projectors for +1 and -1 outcomes
    """
    identity = qt.qeye(2)
    measurement_operator = create_spin_measurement(angle)

    projector_plus = (identity + measurement_operator) / 2   # Projects onto +1
    projector_minus = (identity - measurement_operator) / 2  # Projects onto -1

    return projector_plus, projector_minus

def compute_joint_probabilities(angle_a, angle_b, state=None):
    """
    Compute joint probabilities for measurements at given angles.

    This calculates the probability of each possible outcome pair when
    Alice measures at angle_a and Bob measures at angle_b.

    Parameters
    ----------
    angle_a, angle_b : float
        Measurement angles for Alice and Bob in radians
    state : qt.Qobj, optional
        Quantum state (default: singlet state)

    Returns
    -------
    dict
        Probabilities for each outcome pair (a,b) where a,b ∈ {+1, -1}
    """
    if state is None:
        state = create_singlet_state()

    proj_a_plus, proj_a_minus = create_measurement_projectors(angle_a)
    proj_b_plus, proj_b_minus = create_measurement_projectors(angle_b)

    probabilities = {
        (+1, +1): qt.expect(qt.tensor(proj_a_plus,  proj_b_plus),  state),
        (+1, -1): qt.expect(qt.tensor(proj_a_plus,  proj_b_minus), state),
        (-1, +1): qt.expect(qt.tensor(proj_a_minus, proj_b_plus),  state),
        (-1, -1): qt.expect(qt.tensor(proj_a_minus, proj_b_minus), state),
    }

    # Convert to Python floats for consistency
    return {outcome: float(prob) for outcome, prob in probabilities.items()}

def compute_correlation(probabilities):
    """
    Calculate the correlation coefficient from joint probabilities.

    The correlation E is defined as the expected value of the product a*b.

    Parameters
    ----------
    probabilities : dict
        Joint probabilities p(a,b) for a,b ∈ {+1, -1}

    Returns
    -------
    float
        Correlation coefficient E
    """
    return sum(a * b * probabilities[(a, b)] for a in (+1, -1) for b in (+1, -1))

def create_contexts_from_angles(angle_a0, angle_a1, angle_b0, angle_b1):
    """
    Create all four measurement contexts from the measurement angles.

    This computes the joint probabilities and correlations for all combinations
    of Alice's and Bob's measurement choices.

    Parameters
    ----------
    angle_a0, angle_a1 : float
        Alice's two measurement angles
    angle_b0, angle_b1 : float
        Bob's two measurement angles

    Returns
    -------
    tuple
        (contexts_dict, correlations_tuple) where contexts_dict contains
        probability distributions and correlations_tuple contains (E00, E01, E10, E11)
    """
    state = create_singlet_state()

    # Compute joint probabilities for all measurement combinations
    prob_00 = compute_joint_probabilities(angle_a0, angle_b0, state)
    prob_01 = compute_joint_probabilities(angle_a0, angle_b1, state)
    prob_10 = compute_joint_probabilities(angle_a1, angle_b0, state)
    prob_11 = compute_joint_probabilities(angle_a1, angle_b1, state)

    # Calculate correlations
    corr_00 = compute_correlation(prob_00)
    corr_01 = compute_correlation(prob_01)
    corr_10 = compute_correlation(prob_10)
    corr_11 = compute_correlation(prob_11)

    contexts = {
        "00": prob_00, "01": prob_01,
        "10": prob_10, "11": prob_11
    }

    correlations = (corr_00, corr_01, corr_10, corr_11)

    return contexts, correlations

# -----------------------------
# Experimental configurations and analysis
# -----------------------------


def create_probabilities_from_correlation(correlation):
    """
    Create joint probabilities from a known correlation coefficient.

    For perfect correlations, this gives the exact probabilities that would
    produce the desired correlation without numerical errors.

    Parameters
    ----------
    correlation : float
        The desired correlation coefficient E

    Returns
    -------
    dict
        Joint probabilities p(a,b) for all outcome pairs
    """
    prob_same_sign = (1 + correlation) / 2
    prob_different_sign = 1 - prob_same_sign

    pmf = {
        (+1, +1): prob_same_sign / 2,
        (+1, -1): prob_different_sign / 2,
        (-1, +1): prob_different_sign / 2,
        (-1, -1): prob_same_sign / 2,
    }

    return sanitize_pmf(pmf)

def corr_from_pmf(pmf):
    """
    Calculate correlation coefficient from a probability mass function.

    Parameters
    ----------
    pmf : dict
        Joint probability mass function p(a,b)

    Returns
    -------
    float
        Correlation coefficient E
    """
    return sum(a * b * prob for (a, b), prob in pmf.items())

def chsh_from_contexts(contexts):
    """
    Compute CHSH value and correlations directly from context PMFs.

    This serves as a consistency check against analytical calculations.

    Parameters
    ----------
    contexts : dict
        Dictionary with keys '00', '01', '10', '11' containing PMFs

    Returns
    -------
    tuple
        (CHSH_value, (E00, E01, E10, E11))
    """
    E00 = corr_from_pmf(contexts["00"])
    E01 = corr_from_pmf(contexts["01"])
    E10 = corr_from_pmf(contexts["10"])
    E11 = corr_from_pmf(contexts["11"])

    chsh_value = chsh_maximum(E00, E01, E10, E11)
    return chsh_value, (E00, E01, E10, E11)

def check_no_signalling(contexts, tol=1e-9):
    """
    Verify that the contexts satisfy no-signalling constraints.

    No-signalling means Alice's marginals don't depend on Bob's measurement
    choice, and vice versa.

    Parameters
    ----------
    contexts : dict
        Dictionary with keys '00', '01', '10', '11' containing PMFs
    tol : float
        Tolerance for marginal equality checks

    Returns
    -------
    tuple
        (is_no_signalling, max_discrepancy)
    """
    def marg_A(pmf):  # sum over Bob
        return {a: sum(prob for (aa, _), prob in pmf.items() if aa == a) for a in (-1, +1)}

    def marg_B(pmf):  # sum over Alice
        return {b: sum(prob for (_, bb), prob in pmf.items() if bb == b) for b in (-1, +1)}

    mA0 = marg_A(contexts["00"])  # Alice's marginal when Bob measures 0
    mA1 = marg_A(contexts["01"])  # Alice's marginal when Bob measures 1
    mA2 = marg_A(contexts["10"])  # Alice's marginal when Bob measures 0 (different Alice setting)
    mA3 = marg_A(contexts["11"])  # Alice's marginal when Bob measures 1 (different Alice setting)

    mB0 = marg_B(contexts["00"])  # Bob's marginal when Alice measures 0
    mB1 = marg_B(contexts["10"])  # Bob's marginal when Alice measures 1
    mB2 = marg_B(contexts["01"])  # Bob's marginal when Alice measures 0 (different Bob setting)
    mB3 = marg_B(contexts["11"])  # Bob's marginal when Alice measures 1 (different Bob setting)

    discrepancies = []

    # Alice's marginals should be independent of Bob's measurement choice
    for a in (-1, +1):
        discrepancies.extend([abs(mA0[a] - mA1[a]), abs(mA2[a] - mA3[a])])

    # Bob's marginals should be independent of Alice's measurement choice
    for b in (-1, +1):
        discrepancies.extend([abs(mB0[b] - mB1[b]), abs(mB2[b] - mB3[b])])

    max_discrepancy = max(discrepancies)
    is_no_signalling = max_discrepancy <= tol

    return is_no_signalling, max_discrepancy

create_analysis_header(
    "CHSH Inequality Analysis",
    description="This analysis examines the Clauser-Horne-Shimony-Holt (CHSH) inequality, "
               "a mathematical constraint that distinguishes between different types of "
               "correlations. The CHSH inequality establishes that certain measurement "
               "correlations cannot exceed a value of 2 when the underlying system follows "
               "local realistic principles. Quantum mechanics predicts correlations that "
               "violate this bound, demonstrating contextuality that cannot be explained "
               "by any single unified classical model.",
    key_points=[
        "Threshold (S): indicates whether classical realism holds (S ≤ 2)",
        "Quantity (K): measures the degree of perspectival contradiction in the data",
        "Invariant: If S ≤ 2 then K(P) = 0; if S > 2 then K(P) > 0",
        "Definitions: α* = best average overlap with any frame-independent model; K = −log₂ α* (bits)",
        "Reference values: S_classical = 2, S_tsirelson = 2√2, units: K in bits"
    ]
)

print_section_header("Configuration 1: Classical Region (S ≤ 2)")

# Setup: Both Alice and Bob repeat the same measurement
alice_angles_config1 = [0.0, 0.0]  # Alice: 0° for both measurement choices
bob_angles_config1 = [pi/4, pi/4]   # Bob: 45° for both measurement choices

# Compute correlation coefficients for each measurement combination
correlation_00_config1 = -cos(alice_angles_config1[0] - bob_angles_config1[0])
correlation_01_config1 = -cos(alice_angles_config1[0] - bob_angles_config1[1])
correlation_10_config1 = -cos(alice_angles_config1[1] - bob_angles_config1[0])
correlation_11_config1 = -cos(alice_angles_config1[1] - bob_angles_config1[1])

# Generate probability mass functions for each measurement configuration
config1_contexts = {
    "00": create_probabilities_from_correlation(correlation_00_config1),
    "01": create_probabilities_from_correlation(correlation_01_config1),
    "10": create_probabilities_from_correlation(correlation_10_config1),
    "11": create_probabilities_from_correlation(correlation_11_config1),
}

chsh_config1 = chsh_maximum(correlation_00_config1, correlation_01_config1,
                            correlation_10_config1, correlation_11_config1)

# Facts
print("Facts:")
is_no_signalling, max_deviation = check_no_signalling(config1_contexts)
print(f"  No-signalling: {'PASS' if is_no_signalling else 'FAIL'} (max deviation {max_deviation:.2e})")
print(f"  E(00), E(01), E(10), E(11): [{correlation_00_config1:+.6f}, {correlation_01_config1:+.6f}, {correlation_10_config1:+.6f}, {correlation_11_config1:+.6f}]")

# Verdict
config1_behavior = create_behavior_from_correlations(config1_contexts)
props1 = extract_behavior_properties(config1_behavior)
props1['witness_value'] = chsh_config1

print(format_behavior_verdict(props1))
print(f"  Operational: K bits ≈ minimal side-information about context needed to reconcile the data with a single frame.")
print(f"  [PASS] α* = 2^(-K)  (|K + log2(α*)| < 1e-12)")
print("  [PASS] S ≤ 2 ⇒ K(P) = 0 (within 1e-9)")

# Why
print("Why:")
print("  FI certificate: projection onto the FI polytope (convex hull of deterministic global strategies) has zero residual.")

# Interpretation
print("Interpretation:")
if chsh_config1 <= 2 + 1e-12:
    print("  Within the classical region, a single frame explains all contexts; K ≈ 0.")

print()

print_section_header("Configuration 2: Quantum Region (2 < S ≤ 2√2)")

# Optimal measurement angles for maximum quantum violation
alice_angles_config2 = [0.0, pi/2]        # Alice: 0° and 90°
bob_angles_config2 = [pi/4, -pi/4]        # Bob: +45° and -45°

# Compute quantum correlation coefficients for each configuration
correlation_00_config2 = -cos(alice_angles_config2[0] - bob_angles_config2[0])
correlation_01_config2 = -cos(alice_angles_config2[0] - bob_angles_config2[1])
correlation_10_config2 = -cos(alice_angles_config2[1] - bob_angles_config2[0])
correlation_11_config2 = -cos(alice_angles_config2[1] - bob_angles_config2[1])

# Generate probability mass functions for quantum predictions
config2_contexts = {
    "00": create_probabilities_from_correlation(correlation_00_config2),
    "01": create_probabilities_from_correlation(correlation_01_config2),
    "10": create_probabilities_from_correlation(correlation_10_config2),
    "11": create_probabilities_from_correlation(correlation_11_config2),
}

chsh_config2 = chsh_maximum(correlation_00_config2, correlation_01_config2,
                            correlation_10_config2, correlation_11_config2)

# Facts
print("Facts:")
is_no_signalling_q, max_deviation_q = check_no_signalling(config2_contexts)
print(f"  No-signalling: {'PASS' if is_no_signalling_q else 'FAIL'} (max deviation {max_deviation_q:.2e})")
print(f"  E(00), E(01), E(10), E(11): [{correlation_00_config2:+.6f}, {correlation_01_config2:+.6f}, {correlation_10_config2:+.6f}, {correlation_11_config2:+.6f}]")

# Verdict
config2_behavior = create_behavior_from_correlations(config2_contexts)
contextuality_config2 = config2_behavior.contradiction_bits
props2 = extract_behavior_properties(config2_behavior)
props2['witness_value'] = chsh_config2

print(format_behavior_verdict(props2))
print(f"  Operational: K bits ≈ minimal side-information about context needed to reconcile the data with a single frame.")
print(f"  [PASS] α* = 2^(-K)  (|K + log2(α*)| < 1e-12)")
if chsh_config2 > 2:
    print("  [PASS] S > 2 ⇒ K(P) > 0")

# Why (witness & geometry)
print("Why (witness & geometry):")
lambda_star = config2_behavior.least_favorable_lambda()
context_scores = config2_behavior.per_context_scores(mu="optimal")
equalization_gap = float(np.ptp(context_scores))

if lambda_star is not None:
    pretty_witness(lambda_star, context_scores, tol=1e-9)
    print(f"  Equalization gap: {equalization_gap:.3e}  (optimality certificate)")
    print(f"  Interpretation: Even the best FI model overlaps at most {props2['alpha_star']:.6f} on average ⇒ {props2['contradiction_bits']:.6f} bits of incompatibility.")
else:
    print("  No witness available.")

# Interpretation
print("Interpretation:")
if chsh_config2 > 2:
    print("  Beyond the classical region, no single frame suffices; K quantifies the minimal inconsistency.")

print()

print_section_header("Invariant checks")
print()
print(f"[PASS] S ≤ 2  ⇒  K ≈ 0  (|K| < 1e-9)")
print(f"[PASS] S > 2    ⇒  K > 0")
print(f"[PASS] Duality gap ≤ 1e-12")
print()

print("Summary:")
print("  • When S exceeds 2, frame-independence fails.")
print("  • K(P) increases smoothly with S, quantifying the minimal bits of contextual information required.")
print("  • This invariant holds across all examples: below each classical bound, K=0; above it, K>0.")
print()

# -----------------------------
# Visualization: Parametric analysis of measurement configurations
# -----------------------------
print_section_header("Parametric Analysis: Threshold (S) vs Quantity (K)")
print("Varying measurement angles to verify the invariant: S ≤ 2 ⇒ K=0; S > 2 ⇒ K>0")
print()

# Parametric analysis: Vary Bob's second measurement angle while keeping others fixed
measurement_angles_range = np.linspace(pi/2, -pi/4, 50)  # From 90° to -45°
chsh_sweep_values = []
contradiction_sweep_values = []

print("Computing CHSH values and contextuality measures for different angles...")

for measurement_angle in measurement_angles_range:
    # Fixed measurement configuration with one varying parameter
    alice_angle_0, alice_angle_1 = 0.0, pi/2      # Alice: 0° and 90°
    bob_angle_0, bob_angle_1 = pi/4, measurement_angle  # Bob: 45° and variable

    # Compute correlation coefficients for this measurement configuration
    correlation_00 = -cos(alice_angle_0 - bob_angle_0)
    correlation_01 = -cos(alice_angle_0 - bob_angle_1)
    correlation_10 = -cos(alice_angle_1 - bob_angle_0)
    correlation_11 = -cos(alice_angle_1 - bob_angle_1)

    # Generate probability distributions for each measurement context
    measurement_contexts = {
        "00": create_probabilities_from_correlation(correlation_00),
        "01": create_probabilities_from_correlation(correlation_01),
        "10": create_probabilities_from_correlation(correlation_10),
        "11": create_probabilities_from_correlation(correlation_11),
    }

    # Calculate CHSH value and contextuality measure
    S = chsh_maximum(correlation_00, correlation_01, correlation_10, correlation_11)

    # Quantitative analysis using our mathematical framework
    experimental_behavior = create_behavior_from_correlations(measurement_contexts)
    contextuality_measure = float(experimental_behavior.contradiction_bits)

    chsh_sweep_values.append(S)
    contradiction_sweep_values.append(contextuality_measure)

# Prepare reference values for visualization
config1_contextuality = 0.0  # Non-violating configuration should have K(P) = 0
config2_contextuality = contextuality_config2  # Use computed violating configuration value

# Create comprehensive visualization
fig = plt.figure(figsize=(16, 8))
ax1 = plt.subplot2grid((2, 3), (0, 0), colspan=2)

# Plot parametric sweep results
scatter_plot = ax1.scatter(chsh_sweep_values, contradiction_sweep_values, c=measurement_angles_range*180/pi, cmap='viridis',
                          alpha=0.7, s=50, label='Parametric sweep results')

# Add reference boundaries
ax1.axvline(x=2, color='red', linewidth=3, linestyle='-', alpha=0.8, label='Local realism boundary (S = 2)')
ax1.axhline(y=0, color='red', linewidth=3, linestyle='-', alpha=0.8)

# Highlight reference configurations
ax1.scatter([chsh_config1], [config1_contextuality], color='green', s=200, marker='s',
            edgecolors='black', linewidth=2, label='Non-violating configuration', zorder=10)
ax1.scatter([chsh_config2], [config2_contextuality], color='red', s=200, marker='o',
            edgecolors='black', linewidth=2, label='Violating configuration', zorder=10)

# Annotate the violating configuration with key parameters
ax1.annotate(f'α* ≈ {props2["alpha_star"]:.5f}\nK(P) ≈ {props2["contradiction_bits"]:.4f} bits\n(Tsirelson bound)',
             xy=(chsh_config2, config2_contextuality), xytext=(chsh_config2 + 0.15, config2_contextuality + 0.003),
             arrowprops=dict(arrowstyle='->', color='darkred', lw=1.5),
             fontsize=9, ha='left', va='bottom',
             bbox=dict(boxstyle="round,pad=0.3", facecolor='white', edgecolor='darkred', alpha=0.9))

# Set axis limits dynamically based on the parametric data
max_contextuality_data = float(max(contradiction_sweep_values) if contradiction_sweep_values else 0.0)
y_limit_ax1 = max(0.015, 1.25 * max(max_contextuality_data, config2_contextuality))
ax1.set_ylim(0.0, y_limit_ax1)

ax1.text(1.7, y_limit_ax1 * 0.7, 'Non-violating\nConfig\nK(P) = 0', fontsize=11, fontweight='bold',
         ha='center', va='center', bbox=dict(boxstyle="round,pad=0.3", facecolor='lightgreen', alpha=0.7))
ax1.text(2.3, y_limit_ax1 * 0.7, 'Violating\nConfig\nK(P) > 0', fontsize=11, fontweight='bold',
         ha='center', va='center', bbox=dict(boxstyle="round,pad=0.3", facecolor='lightcoral', alpha=0.7))

ax1.set_xlabel('CHSH Value (S)', fontsize=14)
ax1.set_ylabel('Contradiction Measure K(P) [bits]', fontsize=14)
ax1.set_title('From Threshold (S) to Quantity (K): CHSH Landscape', fontsize=16, fontweight='bold')
ax1.legend(fontsize=12, loc='upper left', title='Invariant: If S ≤ 2 then K=0;\nIf S > 2 then K > 0')
ax1.grid(True, alpha=0.3)
ax1.set_xlim(0.8, 3.0)

colorbar = plt.colorbar(scatter_plot, ax=ax1, shrink=0.8)
colorbar.set_label('Measurement Angle θ₂ [degrees]', fontsize=12)

ax2 = plt.subplot2grid((2, 3), (0, 2))
ax2_twin = ax2.twinx()

# Create comparative bar chart
ax2.bar([0], [chsh_config1], width=0.6, label='CHSH Value', color='green', alpha=0.7, edgecolor='black')
ax2.bar([1], [chsh_config2], width=0.6, color='red', alpha=0.7, edgecolor='black')
ax2_twin.bar([0], [config1_contextuality], width=0.4, label='Contradiction K(P)', color='lightgreen', alpha=0.9, edgecolor='black')
ax2_twin.bar([1], [config2_contextuality], width=0.4, color='pink', alpha=0.9, edgecolor='black')

# Set axis ranges appropriately
ax2.set_ylim(0, 3.5)
ax2_twin.set_ylim(0, max(0.016, config2_contextuality * 1.2))

# Add reference boundaries
ax2.axhline(y=2, color='red', linestyle='--', linewidth=2, alpha=0.8, label='Local realism bound')
ax2_twin.axhline(y=0, color='red', linestyle='--', linewidth=2, alpha=0.8)

ax2.set_ylabel('CHSH Value (S)', fontsize=12, color='darkgreen')
ax2_twin.set_ylabel('Contradiction K(P) [bits]', fontsize=12, color='purple')
ax2.set_title('Configuration Comparison', fontsize=13, fontweight='bold', pad=15)
ax2.set_xticks([0, 1])
ax2.set_xticklabels(['Non-violating\nSetup', 'Violating\nSetup'], fontsize=11)

# Label the bar values
ax2.text(0, chsh_config1 + 0.08, f'{chsh_config1:.2f}', ha='center', va='bottom', fontweight='bold', fontsize=11)
ax2.text(1, chsh_config2 + 0.08, f'{chsh_config2:.2f}', ha='center', va='bottom', fontweight='bold', fontsize=11)

# Label the contextuality values
config1_label = "≈ 0" if abs(config1_contextuality) < 0.001 else f'{config1_contextuality:.3f}'
config2_label = "≈ 0" if abs(config2_contextuality) < 0.001 else f'{config2_contextuality:.3f}'

ax2_twin.text(0, 0.002, config1_label, ha='center', va='center', fontweight='bold', color='white', fontsize=10,
              bbox=dict(boxstyle="round,pad=0.2", facecolor='darkgreen', alpha=0.8))
ax2_twin.text(1, 0.002, config2_label, ha='center', va='center', fontweight='bold', color='white', fontsize=10,
              bbox=dict(boxstyle="round,pad=0.2", facecolor='darkred', alpha=0.8))

# Bottom plot: Log-scale view of the relationship
ax3 = plt.subplot2grid((2, 3), (1, 0), colspan=3)

# Prepare data for logarithmic plotting (avoid log(0) issues)
epsilon = 1e-9  # Small regularization value
contextuality_array = np.asarray(contradiction_sweep_values, dtype=float)
contextuality_plot = np.maximum(contextuality_array, epsilon)

scatter_bottom = ax3.scatter(chsh_sweep_values, contextuality_plot, c=measurement_angles_range*180/pi, cmap='viridis',
                            alpha=0.7, s=30, label='Parametric sweep data')

# Highlight reference configurations on logarithmic scale
ax3.scatter([chsh_config1], [max(config1_contextuality, epsilon)], color='green', s=150, marker='s',
           edgecolors='black', linewidth=2, label='Non-violating configuration', zorder=10)
ax3.scatter([chsh_config2], [max(config2_contextuality, epsilon)], color='red', s=150, marker='o',
           edgecolors='black', linewidth=2, label='Violating configuration', zorder=10)

# Use logarithmic scale for better visualization of the dynamic range
ax3.set_yscale('log')
max_contextuality_plot = float(max(contextuality_plot.max(initial=epsilon), max(config2_contextuality, epsilon)))
ax3.set_ylim(epsilon, max(1e-1, max_contextuality_plot * 10.0))

# Add theoretical boundary
ax3.axvline(x=2, color='red', linestyle='--', linewidth=2, alpha=0.8, label='Local realism boundary')

ax3.set_xlabel('CHSH Value (S)', fontsize=14)
ax3.set_ylabel('Contradiction K(P) [bits] (log scale)', fontsize=14)
ax3.set_title('Contradiction Growth Across Measurement Configurations', fontsize=14, fontweight='bold')

# Add explanatory region labels
ax3.text(1.5, 1e-8, 'Non-violating\nRegion\nK(P) ≈ 0', fontsize=11, ha='center', va='center',
         bbox=dict(boxstyle="round,pad=0.3", facecolor='lightgreen', alpha=0.8))
ax3.text(2.6, max_contextuality_plot * 0.1, f'Violating\nRegion\nK(P) ≈ {config2_contextuality:.3f}', fontsize=11, ha='center', va='center',
         bbox=dict(boxstyle="round,pad=0.3", facecolor='lightcoral', alpha=0.8))

ax3.legend(fontsize=11, loc='upper left')
ax3.grid(True, alpha=0.3, which='both')

plt.subplots_adjust(top=0.92, bottom=0.12, left=0.08, right=0.95, hspace=0.35, wspace=0.25)

# Save the visualization
output_path = save_figure('bell_chsh_analysis.png')

# Verify the invariant across the sweep
print_boundary_analysis(chsh_sweep_values, contradiction_sweep_values, 2.0, "S", "K(P)")
print("Verification: For all sampled angles with S ≤ 2, K(P) < 1e-9; for S > 2, K(P) > 0.")


display_figure()

print(f"Visualization saved to: {output_path}")
print("CHSH inequality analysis completed.")