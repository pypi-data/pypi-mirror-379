abacusai.api_class.deployment
=============================

.. py:module:: abacusai.api_class.deployment


Classes
-------

.. autoapisummary::

   abacusai.api_class.deployment.PredictionArguments
   abacusai.api_class.deployment.OptimizationPredictionArguments
   abacusai.api_class.deployment.TimeseriesAnomalyPredictionArguments
   abacusai.api_class.deployment.ChatLLMPredictionArguments
   abacusai.api_class.deployment.RegressionPredictionArguments
   abacusai.api_class.deployment.ForecastingPredictionArguments
   abacusai.api_class.deployment.CumulativeForecastingPredictionArguments
   abacusai.api_class.deployment.NaturalLanguageSearchPredictionArguments
   abacusai.api_class.deployment.FeatureStorePredictionArguments
   abacusai.api_class.deployment._PredictionArgumentsFactory


Module Contents
---------------

.. py:class:: PredictionArguments

   Bases: :py:obj:`abacusai.api_class.abstract.ApiClass`


   An abstract class for prediction arguments specific to problem type.


   .. py:attribute:: _support_kwargs
      :type:  bool
      :value: True



   .. py:attribute:: kwargs
      :type:  dict


   .. py:attribute:: problem_type
      :type:  abacusai.api_class.enums.ProblemType
      :value: None



   .. py:method:: _get_builder()
      :classmethod:



.. py:class:: OptimizationPredictionArguments

   Bases: :py:obj:`PredictionArguments`


   Prediction arguments for the OPTIMIZATION problem type

   :param forced_assignments: Set of assignments to force and resolve before returning query results.
   :type forced_assignments: dict
   :param solve_time_limit_seconds: Maximum time in seconds to spend solving the query.
   :type solve_time_limit_seconds: float
   :param include_all_assignments: If True, will return all assignments, including assignments with value 0. Default is False.
   :type include_all_assignments: bool


   .. py:attribute:: forced_assignments
      :type:  dict
      :value: None



   .. py:attribute:: solve_time_limit_seconds
      :type:  float
      :value: None



   .. py:attribute:: include_all_assignments
      :type:  bool
      :value: None



   .. py:method:: __post_init__()


.. py:class:: TimeseriesAnomalyPredictionArguments

   Bases: :py:obj:`PredictionArguments`


   Prediction arguments for the TS_ANOMALY problem type

   :param start_timestamp: Timestamp from which anomalies have to be detected in the training data
   :type start_timestamp: str
   :param end_timestamp: Timestamp to which anomalies have to be detected in the training data
   :type end_timestamp: str
   :param get_all_item_data: If True, anomaly detection has to be performed on all the data related to input ids
   :type get_all_item_data: bool


   .. py:attribute:: start_timestamp
      :type:  str
      :value: None



   .. py:attribute:: end_timestamp
      :type:  str
      :value: None



   .. py:attribute:: get_all_item_data
      :type:  bool
      :value: None



   .. py:method:: __post_init__()


.. py:class:: ChatLLMPredictionArguments

   Bases: :py:obj:`PredictionArguments`


   Prediction arguments for the CHAT_LLM problem type

   :param llm_name: Name of the specific LLM backend to use to power the chat experience.
   :type llm_name: str
   :param num_completion_tokens: Default for maximum number of tokens for chat answers.
   :type num_completion_tokens: int
   :param system_message: The generative LLM system message.
   :type system_message: str
   :param temperature: The generative LLM temperature.
   :type temperature: float
   :param search_score_cutoff: Cutoff for the document retriever score. Matching search results below this score will be ignored.
   :type search_score_cutoff: float
   :param ignore_documents: If True, will ignore any documents and search results, and only use the messages to generate a response.
   :type ignore_documents: bool


   .. py:attribute:: llm_name
      :type:  str
      :value: None



   .. py:attribute:: num_completion_tokens
      :type:  int
      :value: None



   .. py:attribute:: system_message
      :type:  str
      :value: None



   .. py:attribute:: temperature
      :type:  float
      :value: None



   .. py:attribute:: search_score_cutoff
      :type:  float
      :value: None



   .. py:attribute:: ignore_documents
      :type:  bool
      :value: None



   .. py:method:: __post_init__()


.. py:class:: RegressionPredictionArguments

   Bases: :py:obj:`PredictionArguments`


   Prediction arguments for the PREDICTIVE_MODELING problem type

   :param explain_predictions: If true, will explain predictions.
   :type explain_predictions: bool
   :param explainer_type: Type of explainer to use for explanations.
   :type explainer_type: str


   .. py:attribute:: explain_predictions
      :type:  bool
      :value: None



   .. py:attribute:: explainer_type
      :type:  str
      :value: None



   .. py:method:: __post_init__()


.. py:class:: ForecastingPredictionArguments

   Bases: :py:obj:`PredictionArguments`


   Prediction arguments for the FORECASTING problem type

   :param num_predictions: The number of timestamps to predict in the future.
   :type num_predictions: int
   :param prediction_start: The start date for predictions (e.g., "2015-08-01T00:00:00" as input for mid-night of 2015-08-01).
   :type prediction_start: str
   :param explain_predictions: If True, explain predictions for forecasting.
   :type explain_predictions: bool
   :param explainer_type: Type of explainer to use for explanations.
   :type explainer_type: str
   :param get_item_data: If True, will return the data corresponding to items as well.
   :type get_item_data: bool


   .. py:attribute:: num_predictions
      :type:  int
      :value: None



   .. py:attribute:: prediction_start
      :type:  str
      :value: None



   .. py:attribute:: explain_predictions
      :type:  bool
      :value: None



   .. py:attribute:: explainer_type
      :type:  str
      :value: None



   .. py:attribute:: get_item_data
      :type:  bool
      :value: None



   .. py:method:: __post_init__()


.. py:class:: CumulativeForecastingPredictionArguments

   Bases: :py:obj:`PredictionArguments`


   Prediction arguments for the CUMULATIVE_FORECASTING problem type

   :param num_predictions: The number of timestamps to predict in the future.
   :type num_predictions: int
   :param prediction_start: The start date for predictions (e.g., "2015-08-01T00:00:00" as input for mid-night of 2015-08-01).
   :type prediction_start: str
   :param explain_predictions: If True, explain predictions for forecasting.
   :type explain_predictions: bool
   :param explainer_type: Type of explainer to use for explanations.
   :type explainer_type: str
   :param get_item_data: If True, will return the data corresponding to items as well.
   :type get_item_data: bool


   .. py:attribute:: num_predictions
      :type:  int
      :value: None



   .. py:attribute:: prediction_start
      :type:  str
      :value: None



   .. py:attribute:: explain_predictions
      :type:  bool
      :value: None



   .. py:attribute:: explainer_type
      :type:  str
      :value: None



   .. py:attribute:: get_item_data
      :type:  bool
      :value: None



   .. py:method:: __post_init__()


.. py:class:: NaturalLanguageSearchPredictionArguments

   Bases: :py:obj:`PredictionArguments`


   Prediction arguments for the NATURAL_LANGUAGE_SEARCH problem type

   :param llm_name: Name of the specific LLM backend to use to power the chat experience.
   :type llm_name: str
   :param num_completion_tokens: Default for maximum number of tokens for chat answers.
   :type num_completion_tokens: int
   :param system_message: The generative LLM system message.
   :type system_message: str
   :param temperature: The generative LLM temperature.
   :type temperature: float
   :param search_score_cutoff: Cutoff for the document retriever score. Matching search results below this score will be ignored.
   :type search_score_cutoff: float
   :param ignore_documents: If True, will ignore any documents and search results, and only use the messages to generate a response.
   :type ignore_documents: bool


   .. py:attribute:: llm_name
      :type:  str
      :value: None



   .. py:attribute:: num_completion_tokens
      :type:  int
      :value: None



   .. py:attribute:: system_message
      :type:  str
      :value: None



   .. py:attribute:: temperature
      :type:  float
      :value: None



   .. py:attribute:: search_score_cutoff
      :type:  float
      :value: None



   .. py:attribute:: ignore_documents
      :type:  bool
      :value: None



   .. py:method:: __post_init__()


.. py:class:: FeatureStorePredictionArguments

   Bases: :py:obj:`PredictionArguments`


   Prediction arguments for the FEATURE_STORE problem type

   :param limit_results: If provided, will limit the number of results to the value specified.
   :type limit_results: int


   .. py:attribute:: limit_results
      :type:  int
      :value: None



   .. py:method:: __post_init__()


.. py:class:: _PredictionArgumentsFactory

   Bases: :py:obj:`abacusai.api_class.abstract._ApiClassFactory`


   .. py:attribute:: config_abstract_class


   .. py:attribute:: config_class_key
      :value: 'problem_type'



   .. py:attribute:: config_class_map


