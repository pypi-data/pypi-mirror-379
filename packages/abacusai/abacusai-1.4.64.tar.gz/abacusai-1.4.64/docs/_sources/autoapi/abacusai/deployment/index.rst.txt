abacusai.deployment
===================

.. py:module:: abacusai.deployment


Classes
-------

.. autoapisummary::

   abacusai.deployment.Deployment


Module Contents
---------------

.. py:class:: Deployment(client, deploymentId=None, name=None, status=None, description=None, deployedAt=None, createdAt=None, projectId=None, modelId=None, modelVersion=None, featureGroupId=None, featureGroupVersion=None, callsPerSecond=None, autoDeploy=None, skipMetricsCheck=None, algoName=None, regions=None, error=None, batchStreamingUpdates=None, algorithm=None, pendingModelVersion=None, modelDeploymentConfig=None, predictionOperatorId=None, predictionOperatorVersion=None, pendingPredictionOperatorVersion=None, onlineFeatureGroupId=None, outputOnlineFeatureGroupId=None, realtimeMonitorId=None, runtimeConfigs=None, isSystemCreated=None, refreshSchedules={}, featureGroupExportConfig={}, defaultPredictionArguments={})

   Bases: :py:obj:`abacusai.return_class.AbstractApiClass`


   A model deployment

   :param client: An authenticated API Client instance
   :type client: ApiClient
   :param deploymentId: A unique identifier for the deployment.
   :type deploymentId: str
   :param name: A user-friendly name for the deployment.
   :type name: str
   :param status: The status of the deployment.
   :type status: str
   :param description: A description of the deployment.
   :type description: str
   :param deployedAt: The date and time when the deployment became active, in ISO-8601 format.
   :type deployedAt: str
   :param createdAt: The date and time when the deployment was created, in ISO-8601 format.
   :type createdAt: str
   :param projectId: A unique identifier for the project this deployment belongs to.
   :type projectId: str
   :param modelId: The model that is currently deployed.
   :type modelId: str
   :param modelVersion: The model version ID that is currently deployed.
   :type modelVersion: str
   :param featureGroupId: The feature group that is currently deployed.
   :type featureGroupId: str
   :param featureGroupVersion: The feature group version ID that is currently deployed.
   :type featureGroupVersion: str
   :param callsPerSecond: The number of calls per second the deployment can handle.
   :type callsPerSecond: int
   :param autoDeploy: A flag marking the deployment as eligible for auto deployments whenever any model in the project finishes training.
   :type autoDeploy: bool
   :param skipMetricsCheck: A flag to skip metric regression with this current deployment. This field is only relevant when auto_deploy is on
   :type skipMetricsCheck: bool
   :param algoName: The name of the algorithm that is currently deployed.
   :type algoName: str
   :param regions: A list of regions that the deployment has been deployed to.
   :type regions: list
   :param error: The relevant error, if the status is FAILED.
   :type error: str
   :param batchStreamingUpdates: A flag marking the feature group deployment as having enabled a background process which caches streamed-in rows for quicker lookup.
   :type batchStreamingUpdates: bool
   :param algorithm: The algorithm that is currently deployed.
   :type algorithm: str
   :param pendingModelVersion: The model that the deployment is switching to, or being stopped.
   :type pendingModelVersion: dict
   :param modelDeploymentConfig: The config for which model to be deployed.
   :type modelDeploymentConfig: dict
   :param predictionOperatorId: The prediction operator ID that is currently deployed.
   :type predictionOperatorId: str
   :param predictionOperatorVersion: The prediction operator version ID that is currently deployed.
   :type predictionOperatorVersion: str
   :param pendingPredictionOperatorVersion: The prediction operator version ID that the deployment is switching to, or being stopped.
   :type pendingPredictionOperatorVersion: str
   :param onlineFeatureGroupId: The online feature group ID that the deployment is running on
   :type onlineFeatureGroupId: id
   :param outputOnlineFeatureGroupId: The online feature group ID that the deployment is outputting results to
   :type outputOnlineFeatureGroupId: id
   :param realtimeMonitorId: The realtime monitor ID of the realtime-monitor that is associated with the deployment
   :type realtimeMonitorId: id
   :param runtimeConfigs: The runtime configurations of a deployment which is used by some of the usecases during prediction.
   :type runtimeConfigs: dict
   :param isSystemCreated: Whether the deployment is system created.
   :type isSystemCreated: bool
   :param refreshSchedules: A list of refresh schedules that indicate when the deployment will be updated to the latest model version.
   :type refreshSchedules: RefreshSchedule
   :param featureGroupExportConfig: The export config (file connector or database connector information) for feature group deployment exports.
   :type featureGroupExportConfig: FeatureGroupExportConfig
   :param defaultPredictionArguments: The default prediction arguments for prediction APIs
   :type defaultPredictionArguments: PredictionArguments


   .. py:attribute:: deployment_id
      :value: None



   .. py:attribute:: name
      :value: None



   .. py:attribute:: status
      :value: None



   .. py:attribute:: description
      :value: None



   .. py:attribute:: deployed_at
      :value: None



   .. py:attribute:: created_at
      :value: None



   .. py:attribute:: project_id
      :value: None



   .. py:attribute:: model_id
      :value: None



   .. py:attribute:: model_version
      :value: None



   .. py:attribute:: feature_group_id
      :value: None



   .. py:attribute:: feature_group_version
      :value: None



   .. py:attribute:: calls_per_second
      :value: None



   .. py:attribute:: auto_deploy
      :value: None



   .. py:attribute:: skip_metrics_check
      :value: None



   .. py:attribute:: algo_name
      :value: None



   .. py:attribute:: regions
      :value: None



   .. py:attribute:: error
      :value: None



   .. py:attribute:: batch_streaming_updates
      :value: None



   .. py:attribute:: algorithm
      :value: None



   .. py:attribute:: pending_model_version
      :value: None



   .. py:attribute:: model_deployment_config
      :value: None



   .. py:attribute:: prediction_operator_id
      :value: None



   .. py:attribute:: prediction_operator_version
      :value: None



   .. py:attribute:: pending_prediction_operator_version
      :value: None



   .. py:attribute:: online_feature_group_id
      :value: None



   .. py:attribute:: output_online_feature_group_id
      :value: None



   .. py:attribute:: realtime_monitor_id
      :value: None



   .. py:attribute:: runtime_configs
      :value: None



   .. py:attribute:: is_system_created
      :value: None



   .. py:attribute:: refresh_schedules


   .. py:attribute:: feature_group_export_config


   .. py:attribute:: default_prediction_arguments


   .. py:attribute:: deprecated_keys


   .. py:method:: __repr__()


   .. py:method:: to_dict()

      Get a dict representation of the parameters in this class

      :returns: The dict value representation of the class parameters
      :rtype: dict



   .. py:method:: create_webhook(endpoint, webhook_event_type, payload_template = None)

      Create a webhook attached to a given deployment ID.

      :param endpoint: URI that the webhook will send HTTP POST requests to.
      :type endpoint: str
      :param webhook_event_type: One of 'DEPLOYMENT_START', 'DEPLOYMENT_SUCCESS', or 'DEPLOYMENT_FAILED'.
      :type webhook_event_type: str
      :param payload_template: Template for the body of the HTTP POST requests. Defaults to {}.
      :type payload_template: dict

      :returns: The webhook attached to the deployment.
      :rtype: Webhook



   .. py:method:: list_webhooks()

      List all the webhooks attached to a given deployment.

      :param deployment_id: Unique identifier of the target deployment.
      :type deployment_id: str

      :returns: List of the webhooks attached to the given deployment ID.
      :rtype: list[Webhook]



   .. py:method:: refresh()

      Calls describe and refreshes the current object's fields

      :returns: The current object
      :rtype: Deployment



   .. py:method:: describe()

      Retrieves a full description of the specified deployment.

      :param deployment_id: Unique string identifier associated with the deployment.
      :type deployment_id: str

      :returns: Description of the deployment.
      :rtype: Deployment



   .. py:method:: update(description = None, auto_deploy = None, skip_metrics_check = None)

      Updates a deployment's properties.

      :param description: The new description for the deployment.
      :type description: str
      :param auto_deploy: Flag to enable the automatic deployment when a new Model Version finishes training.
      :type auto_deploy: bool
      :param skip_metrics_check: Flag to skip metric regression with this current deployment. This field is only relevant when auto_deploy is on
      :type skip_metrics_check: bool



   .. py:method:: rename(name)

      Updates a deployment's name

      :param name: The new deployment name.
      :type name: str



   .. py:method:: set_auto(enable = None)

      Enable or disable auto deployment for the specified deployment.

      When a model is scheduled to retrain, deployments with auto deployment enabled will be marked to automatically promote the new model version. After the newly trained model completes, a check on its metrics in comparison to the currently deployed model version will be performed. If the metrics are comparable or better, the newly trained model version is automatically promoted. If not, it will be marked as a failed model version promotion with an error indicating poor metrics performance.


      :param enable: Enable or disable the autoDeploy property of the deployment.
      :type enable: bool



   .. py:method:: set_model_version(model_version, algorithm = None, model_deployment_config = None)

      Promotes a model version and/or algorithm to be the active served deployment version

      :param model_version: A unique identifier for the model version.
      :type model_version: str
      :param algorithm: The algorithm to use for the model version. If not specified, the algorithm will be inferred from the model version.
      :type algorithm: str
      :param model_deployment_config: The deployment configuration for the model to deploy.
      :type model_deployment_config: dict



   .. py:method:: set_feature_group_version(feature_group_version)

      Promotes a feature group version to be served in the deployment.

      :param feature_group_version: Unique string identifier for the feature group version.
      :type feature_group_version: str



   .. py:method:: set_prediction_operator_version(prediction_operator_version)

      Promotes a prediction operator version to be served in the deployment.

      :param prediction_operator_version: Unique string identifier for the prediction operator version.
      :type prediction_operator_version: str



   .. py:method:: start()

      Restarts the specified deployment that was previously suspended.

      :param deployment_id: A unique string identifier associated with the deployment.
      :type deployment_id: str



   .. py:method:: stop()

      Stops the specified deployment.

      :param deployment_id: Unique string identifier of the deployment to be stopped.
      :type deployment_id: str



   .. py:method:: delete()

      Deletes the specified deployment. The deployment's models will not be affected. Note that the deployments are not recoverable after they are deleted.

      :param deployment_id: Unique string identifier of the deployment to delete.
      :type deployment_id: str



   .. py:method:: set_feature_group_export_file_connector_output(file_format = None, output_location = None)

      Sets the export output for the Feature Group Deployment to be a file connector.

      :param file_format: The type of export output, either CSV or JSON.
      :type file_format: str
      :param output_location: The file connector (cloud) location where the output should be exported.
      :type output_location: str



   .. py:method:: set_feature_group_export_database_connector_output(database_connector_id, object_name, write_mode, database_feature_mapping, id_column = None, additional_id_columns = None)

      Sets the export output for the Feature Group Deployment to a Database connector.

      :param database_connector_id: The unique string identifier of the database connector used.
      :type database_connector_id: str
      :param object_name: The object of the database connector to write to.
      :type object_name: str
      :param write_mode: The write mode to use when writing to the database connector, either UPSERT or INSERT.
      :type write_mode: str
      :param database_feature_mapping: The column/feature pairs mapping the features to the database columns.
      :type database_feature_mapping: dict
      :param id_column: The id column to use as the upsert key.
      :type id_column: str
      :param additional_id_columns: For database connectors which support it, a list of additional ID columns to use as a complex key for upserting.
      :type additional_id_columns: list



   .. py:method:: remove_feature_group_export_output()

      Removes the export type that is set for the Feature Group Deployment

      :param deployment_id: The ID of the deployment for which the export type is set.
      :type deployment_id: str



   .. py:method:: set_default_prediction_arguments(prediction_arguments, set_as_override = False)

      Sets the deployment config.

      :param prediction_arguments: The prediction arguments to set.
      :type prediction_arguments: PredictionArguments
      :param set_as_override: If True, use these arguments as overrides instead of defaults for predict calls
      :type set_as_override: bool

      :returns: description of the updated deployment.
      :rtype: Deployment



   .. py:method:: get_prediction_logs_records(limit = 10, last_log_request_id = '', last_log_timestamp = None)

      Retrieves the prediction request IDs for the most recent predictions made to the deployment.

      :param limit: The number of prediction log entries to retrieve up to the specified limit.
      :type limit: int
      :param last_log_request_id: The request ID of the last log entry to retrieve.
      :type last_log_request_id: str
      :param last_log_timestamp: A Unix timestamp in milliseconds specifying the timestamp for the last log entry.
      :type last_log_timestamp: int

      :returns: A list of prediction log records.
      :rtype: list[PredictionLogRecord]



   .. py:method:: create_alert(alert_name, condition_config, action_config)

      Create a deployment alert for the given conditions.

      Only support batch prediction usage now.


      :param alert_name: Name of the alert.
      :type alert_name: str
      :param condition_config: Condition to run the actions for the alert.
      :type condition_config: AlertConditionConfig
      :param action_config: Configuration for the action of the alert.
      :type action_config: AlertActionConfig

      :returns: Object describing the deployment alert.
      :rtype: MonitorAlert



   .. py:method:: list_alerts()

      List the monitor alerts associated with the deployment id.

      :param deployment_id: Unique string identifier for the deployment.
      :type deployment_id: str

      :returns: An array of deployment alerts.
      :rtype: list[MonitorAlert]



   .. py:method:: create_realtime_monitor(realtime_monitor_schedule = None, lookback_time = None)

      Real time monitors compute and monitor metrics of real time prediction data.

      :param realtime_monitor_schedule: The cron expression for triggering monitor.
      :type realtime_monitor_schedule: str
      :param lookback_time: Lookback time (in seconds) for each monitor trigger
      :type lookback_time: int

      :returns: Object describing the real-time monitor.
      :rtype: RealtimeMonitor



   .. py:method:: get_conversation_response(message, deployment_token, deployment_conversation_id = None, external_session_id = None, llm_name = None, num_completion_tokens = None, system_message = None, temperature = 0.0, filter_key_values = None, search_score_cutoff = None, chat_config = None, doc_infos = None, user_info = None, execute_usercode_tool = False)

      Return a conversation response which continues the conversation based on the input message and deployment conversation id (if exists).

      :param message: A message from the user
      :type message: str
      :param deployment_token: A token used to authenticate access to deployments created in this project. This token is only authorized to predict on deployments in this project, so it is safe to embed this model inside of an application or website.
      :type deployment_token: str
      :param deployment_conversation_id: The unique identifier of a deployment conversation to continue. If not specified, a new one will be created.
      :type deployment_conversation_id: str
      :param external_session_id: The user supplied unique identifier of a deployment conversation to continue. If specified, we will use this instead of a internal deployment conversation id.
      :type external_session_id: str
      :param llm_name: Name of the specific LLM backend to use to power the chat experience
      :type llm_name: str
      :param num_completion_tokens: Default for maximum number of tokens for chat answers
      :type num_completion_tokens: int
      :param system_message: The generative LLM system message
      :type system_message: str
      :param temperature: The generative LLM temperature
      :type temperature: float
      :param filter_key_values: A dictionary mapping column names to a list of values to restrict the retrived search results.
      :type filter_key_values: dict
      :param search_score_cutoff: Cutoff for the document retriever score. Matching search results below this score will be ignored.
      :type search_score_cutoff: float
      :param chat_config: A dictionary specifiying the query chat config override.
      :type chat_config: dict
      :param doc_infos: An optional list of documents use for the conversation. A keyword 'doc_id' is expected to be present in each document for retrieving contents from docstore.
      :type doc_infos: list
      :param execute_usercode_tool: If True, will return the tool output in the response.
      :type execute_usercode_tool: bool



   .. py:method:: get_conversation_response_with_binary_data(deployment_token, message, deployment_conversation_id = None, external_session_id = None, llm_name = None, num_completion_tokens = None, system_message = None, temperature = 0.0, filter_key_values = None, search_score_cutoff = None, chat_config = None, attachments = None)

      Return a conversation response which continues the conversation based on the input message and deployment conversation id (if exists).

      :param deployment_token: A token used to authenticate access to deployments created in this project. This token is only authorized to predict on deployments in this project, so it is safe to embed this model inside of an application or website.
      :type deployment_token: str
      :param message: A message from the user
      :type message: str
      :param deployment_conversation_id: The unique identifier of a deployment conversation to continue. If not specified, a new one will be created.
      :type deployment_conversation_id: str
      :param external_session_id: The user supplied unique identifier of a deployment conversation to continue. If specified, we will use this instead of a internal deployment conversation id.
      :type external_session_id: str
      :param llm_name: Name of the specific LLM backend to use to power the chat experience
      :type llm_name: str
      :param num_completion_tokens: Default for maximum number of tokens for chat answers
      :type num_completion_tokens: int
      :param system_message: The generative LLM system message
      :type system_message: str
      :param temperature: The generative LLM temperature
      :type temperature: float
      :param filter_key_values: A dictionary mapping column names to a list of values to restrict the retrived search results.
      :type filter_key_values: dict
      :param search_score_cutoff: Cutoff for the document retriever score. Matching search results below this score will be ignored.
      :type search_score_cutoff: float
      :param chat_config: A dictionary specifiying the query chat config override.
      :type chat_config: dict
      :param attachments: A dictionary of binary data to use to answer the queries.
      :type attachments: None



   .. py:method:: create_batch_prediction(table_name = None, name = None, global_prediction_args = None, batch_prediction_args = None, explanations = False, output_format = None, output_location = None, database_connector_id = None, database_output_config = None, refresh_schedule = None, csv_input_prefix = None, csv_prediction_prefix = None, csv_explanations_prefix = None, output_includes_metadata = None, result_input_columns = None, input_feature_groups = None)

      Creates a batch prediction job description for the given deployment.

      :param table_name: Name of the feature group table to write the results of the batch prediction. Can only be specified if outputLocation and databaseConnectorId are not specified. If tableName is specified, the outputType will be enforced as CSV.
      :type table_name: str
      :param name: Name of the batch prediction job.
      :type name: str
      :param batch_prediction_args: Batch Prediction args specific to problem type.
      :type batch_prediction_args: BatchPredictionArgs
      :param output_format: Format of the batch prediction output (CSV or JSON).
      :type output_format: str
      :param output_location: Location to write the prediction results. Otherwise, results will be stored in Abacus.AI.
      :type output_location: str
      :param database_connector_id: Unique identifier of a Database Connection to write predictions to. Cannot be specified in conjunction with outputLocation.
      :type database_connector_id: str
      :param database_output_config: Key-value pair of columns/values to write to the database connector. Only available if databaseConnectorId is specified.
      :type database_output_config: dict
      :param refresh_schedule: Cron-style string that describes a schedule in UTC to automatically run the batch prediction.
      :type refresh_schedule: str
      :param csv_input_prefix: Prefix to prepend to the input columns, only applies when output format is CSV.
      :type csv_input_prefix: str
      :param csv_prediction_prefix: Prefix to prepend to the prediction columns, only applies when output format is CSV.
      :type csv_prediction_prefix: str
      :param csv_explanations_prefix: Prefix to prepend to the explanation columns, only applies when output format is CSV.
      :type csv_explanations_prefix: str
      :param output_includes_metadata: If true, output will contain columns including prediction start time, batch prediction version, and model version.
      :type output_includes_metadata: bool
      :param result_input_columns: If present, will limit result files or feature groups to only include columns present in this list.
      :type result_input_columns: list
      :param input_feature_groups: A dict of {'<feature_group_type>': '<feature_group_id>'} which overrides the default input data of that type for the Batch Prediction. Default input data is the training data that was used for training the deployed model.
      :type input_feature_groups: dict

      :returns: The batch prediction description.
      :rtype: BatchPrediction



   .. py:method:: get_statistics_over_time(start_date, end_date)

      Return basic access statistics for the given window

      :param start_date: Timeline start date in ISO format.
      :type start_date: str
      :param end_date: Timeline end date in ISO format. The date range must be 7 days or less.
      :type end_date: str

      :returns: Object describing Time series data of the number of requests and latency over the specified time period.
      :rtype: DeploymentStatistics



   .. py:method:: describe_feature_group_row_process_by_key(primary_key_value)

      Gets the feature group row process.

      :param primary_key_value: The primary key value
      :type primary_key_value: str

      :returns: An object representing the feature group row process
      :rtype: FeatureGroupRowProcess



   .. py:method:: list_feature_group_row_processes(limit = None, status = None)

      Gets a list of feature group row processes.

      :param limit: The maximum number of processes to return. Defaults to None.
      :type limit: int
      :param status: The status of the processes to return. Defaults to None.
      :type status: str

      :returns: A list of object representing the feature group row process
      :rtype: list[FeatureGroupRowProcess]



   .. py:method:: get_feature_group_row_process_summary()

      Gets a summary of the statuses of the individual feature group processes.

      :param deployment_id: The deployment id for the process
      :type deployment_id: str

      :returns: An object representing the summary of the statuses of the individual feature group processes
      :rtype: FeatureGroupRowProcessSummary



   .. py:method:: reset_feature_group_row_process_by_key(primary_key_value)

      Resets a feature group row process so that it can be reprocessed

      :param primary_key_value: The primary key value
      :type primary_key_value: str

      :returns: An object representing the feature group row process.
      :rtype: FeatureGroupRowProcess



   .. py:method:: get_feature_group_row_process_logs_by_key(primary_key_value)

      Gets the logs for a feature group row process

      :param primary_key_value: The primary key value
      :type primary_key_value: str

      :returns: An object representing the logs for the feature group row process
      :rtype: FeatureGroupRowProcessLogs



   .. py:method:: create_conversation(name = None, external_application_id = None)

      Creates a deployment conversation.

      :param name: The name of the conversation.
      :type name: str
      :param external_application_id: The external application id associated with the deployment conversation.
      :type external_application_id: str

      :returns: The deployment conversation.
      :rtype: DeploymentConversation



   .. py:method:: list_conversations(external_application_id = None, conversation_type = None, fetch_last_llm_info = False, limit = None, search = None)

      Lists all conversations for the given deployment and current user.

      :param external_application_id: The external application id associated with the deployment conversation. If specified, only conversations created on that application will be listed.
      :type external_application_id: str
      :param conversation_type: The type of the conversation indicating its origin.
      :type conversation_type: DeploymentConversationType
      :param fetch_last_llm_info: If true, the LLM info for the most recent conversation will be fetched. Only applicable for system-created bots.
      :type fetch_last_llm_info: bool
      :param limit: The number of conversations to return. Defaults to 600.
      :type limit: int
      :param search: The search query to filter conversations by title.
      :type search: str

      :returns: The deployment conversations.
      :rtype: list[DeploymentConversation]



   .. py:method:: create_external_application(name = None, description = None, logo = None, theme = None)

      Creates a new External Application from an existing ChatLLM Deployment.

      :param name: The name of the External Application. If not provided, the name of the deployment will be used.
      :type name: str
      :param description: The description of the External Application. This will be shown to users when they access the External Application. If not provided, the description of the deployment will be used.
      :type description: str
      :param logo: The logo to be displayed.
      :type logo: str
      :param theme: The visual theme of the External Application.
      :type theme: dict

      :returns: The newly created External Application.
      :rtype: ExternalApplication



   .. py:method:: download_agent_attachment(attachment_id)

      Return an agent attachment.

      :param attachment_id: The attachment ID.
      :type attachment_id: str



   .. py:method:: wait_for_deployment(wait_states={'PENDING', 'DEPLOYING'}, timeout=900)

      A waiting call until deployment is completed.

      :param timeout: The waiting time given to the call to finish, if it doesn't finish by the allocated time, the call is said to be timed out.
      :type timeout: int



   .. py:method:: wait_for_pending_deployment_update(timeout=900)

      A waiting call until deployment is in a stable state, that pending model switch is completed and previous model is stopped.

      :param timeout: The waiting time given to the call to finish, if it doesn't finish by the allocated time, the call is said to be timed out.
      :type timeout: int

      :returns: the latest deployment object.
      :rtype: Deployment



   .. py:method:: get_status()

      Gets the status of the deployment.

      :returns: A string describing the status of a deploymet (pending, deploying, active, etc.).
      :rtype: str



   .. py:method:: create_refresh_policy(cron)

      To create a refresh policy for a deployment.

      :param cron: A cron style string to set the refresh time.
      :type cron: str

      :returns: The refresh policy object.
      :rtype: RefreshPolicy



   .. py:method:: list_refresh_policies()

      Gets the refresh policies in a list.

      :returns: A list of refresh policy objects.
      :rtype: List[RefreshPolicy]



