"""
Greeum v2.0 ÌÜµÌï© CLI ÏãúÏä§ÌÖú

ÏÇ¨Ïö©Î≤ï:
  greeum memory add "ÏÉàÎ°úÏö¥ Í∏∞Ïñµ"
  greeum memory search "Í≤ÄÏÉâÏñ¥"
  greeum mcp serve --transport stdio
  greeum api serve --port 5000
"""

try:
    import click
except ImportError:
    print("[ERROR] Click not installed. Install with: pip install greeum")
    import sys
    sys.exit(1)

import os
import sys
import sqlite3
import subprocess
import shutil
import time
from pathlib import Path
from typing import Optional, Dict, Any
from datetime import datetime

from ..config_store import (
    DEFAULT_DATA_DIR,
    DEFAULT_ST_MODEL,
    GreeumConfig,
    ensure_data_dir,
    load_config,
    mark_semantic_ready,
    save_config,
)
from ..core.database_manager import DatabaseManager
from ..core.stm_anchor_store import get_anchor_store
from ..core.branch_schema import BranchSchemaSQL
from ..embedding_models import (
    init_sentence_transformer,
    force_simple_fallback,
)
from ..worker.client import WriteServiceClient, resolve_endpoint, WorkerUnavailableError
from ..worker import ensure_http_worker, get_worker_state


def _backup_database_files(db_path: Path, label: str = "auto") -> Path:
    """Create timestamped backups of the primary database and auxiliary files."""

    data_dir = db_path.parent
    timestamp = datetime.utcnow().strftime("%Y%m%d_%H%M%S")
    backup_dir = data_dir / "backups"
    backup_dir.mkdir(parents=True, exist_ok=True)

    backup_path = backup_dir / f"memory_{label}_{timestamp}.db"
    if db_path.exists():
        shutil.copy(db_path, backup_path)

    for suffix in ("-wal", "-shm"):
        sidecar = Path(f"{db_path}{suffix}")
        if sidecar.exists():
            shutil.copy(sidecar, backup_dir / f"{sidecar.name}_{timestamp}")

    anchor_path = Path(os.environ.get("GREEUM_STM_DB", str(data_dir / "stm_anchors.db")))
    if anchor_path.exists():
        shutil.copy(anchor_path, backup_dir / f"stm_anchors_{label}_{timestamp}.db")

    return backup_path


def _reset_anchor_singleton() -> None:
    try:
        from ..core import stm_anchor_store

        with stm_anchor_store._singleton_lock:  # type: ignore[attr-defined]
            if stm_anchor_store._singleton is not None:  # type: ignore[attr-defined]
                try:
                    stm_anchor_store._singleton.close()  # type: ignore[attr-defined]
                except Exception:
                    pass
                stm_anchor_store._singleton = None  # type: ignore[attr-defined]
    except Exception:
        pass


def _remove_corrupt_database(db_path: Path) -> None:
    for suffix in ("", "-wal", "-shm"):
        target = Path(f"{db_path}{suffix}")
        if target.exists():
            target.unlink()

    anchor_path = Path(os.environ.get("GREEUM_STM_DB", str(db_path.parent / "stm_anchors.db")))
    if anchor_path.exists():
        try:
            anchor_path.unlink()
        except OSError:
            pass

    _reset_anchor_singleton()


def _ensure_database_ready(data_dir: Path, *, auto_accept: bool = False) -> None:
    db_path = data_dir / "memory.db"
    if not db_path.exists():
        return

    try:
        manager = DatabaseManager(connection_string=str(db_path))
        cursor = manager.conn.cursor()
    except sqlite3.DatabaseError as exc:
        message = str(exc).lower()
        if any(keyword in message for keyword in ("malformed", "not a database")):
            click.echo("‚ö†Ô∏è  Existing database appears to be corrupted or uses an unsupported schema.")
            if auto_accept or click.confirm("Automatically back up the old files and rebuild a fresh database?", default=True):
                backup_path = _backup_database_files(db_path, label="malformed")
                click.echo(f"   ‚Ä¢ Backup saved to {backup_path}")
                _remove_corrupt_database(db_path)
                click.echo("   ‚Ä¢ Removed corrupt database. A new one will be created on next run.")
                return
            raise click.ClickException("Setup aborted: database schema is malformed.")
        raise click.ClickException(f"Database initialization failed: {exc}")

    try:
        needs_migration = BranchSchemaSQL.check_migration_needed(cursor)
    except Exception as exc:
        manager.conn.close()
        raise click.ClickException(f"Migration check failed: {exc}")

    if not needs_migration:
        manager.conn.close()
        return

    click.echo("‚ö†Ô∏è  Existing database schema is older than the current release.")
    if not (auto_accept or click.confirm("Back up and upgrade the schema now?", default=True)):
        manager.conn.close()
        raise click.ClickException("Setup aborted: schema migration declined by user.")

    backup_path = _backup_database_files(db_path, label="schema")
    click.echo(f"   ‚Ä¢ Backup saved to {backup_path}")

    try:
        manager._apply_branch_migration(cursor)
        manager._initialize_branch_structures(cursor)
        manager.conn.commit()
    except Exception as exc:
        manager.conn.close()
        raise click.ClickException(f"Schema migration failed: {exc}")

    manager.conn.close()
    click.echo("   ‚Ä¢ Schema migration completed successfully.")



def _download_sentence_transformer(model: str) -> Path:
    try:
        from sentence_transformers import SentenceTransformer
    except ImportError as exc:
        raise ImportError(
            "sentence-transformers not installed. Install with 'pip install greeum[full]' "
            "or 'pip install sentence-transformers'."
        ) from exc

    cache_dir = Path.home() / ".cache" / "sentence_transformers"
    if os.getenv("GREEUM_DISABLE_ST"):
        raise RuntimeError("Semantic warmup skipped because GREEUM_DISABLE_ST is set.")
    SentenceTransformer(
        model,
        cache_folder=str(cache_dir),
        device=os.getenv("GREEUM_ST_DEVICE", None),
    )
    return cache_dir

@click.group()
@click.version_option()
@click.option('--verbose', '-v', is_flag=True, help='Enable verbose logging')
@click.option('--debug', is_flag=True, help='Enable debug logging (most verbose)')
@click.option('--quiet', '-q', is_flag=True, help='Suppress all non-essential output')
@click.pass_context
def main(ctx: click.Context, verbose: bool, debug: bool, quiet: bool):
    """Greeum Universal Memory System"""
    
    # ContextÏóê Î°úÍ∑∏ ÏÑ§Ï†ï Ï†ÄÏû•
    ctx.ensure_object(dict)
    ctx.obj['verbose'] = verbose
    ctx.obj['debug'] = debug
    ctx.obj['quiet'] = quiet
    
    # Console output ÏÑ§Ï†ïÏùÑ ÏúÑÌïú ÌôòÍ≤ΩÎ≥ÄÏàò ÏÑ§Ï†ï
    if verbose or debug:
        os.environ['GREEUM_CLI_VERBOSE'] = '1'
    else:
        os.environ.pop('GREEUM_CLI_VERBOSE', None)
    
    # Î°úÍ∑∏ Î†àÎ≤® ÏÑ§Ï†ï
    import logging
    
    if debug:
        log_level = logging.DEBUG
    elif verbose:
        log_level = logging.INFO
    elif quiet:
        log_level = logging.ERROR
    else:
        log_level = logging.WARNING  # Í∏∞Î≥∏Í∞í: Í≤ΩÍ≥† Ïù¥ÏÉÅÎßå ÌëúÏãú
    
    # Î°úÍ∑∏ Ìè¨Îß∑ ÏÑ§Ï†ï
    if debug:
        log_format = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    elif verbose:
        log_format = '%(levelname)s: %(message)s'
    else:
        log_format = '%(message)s'
    
    logging.basicConfig(
        level=log_level,
        format=log_format,
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    
    # ÌäπÏ†ï Î°úÍ±∞Îì§Ïùò Î†àÎ≤® Ï°∞Ï†ï (ÎÑàÎ¨¥ ÏãúÎÅÑÎü¨Ïö¥ Ïô∏Î∂Ä ÎùºÏù¥Î∏åÎü¨Î¶¨Îì§)
    if not debug:
        logging.getLogger('urllib3').setLevel(logging.WARNING)
        logging.getLogger('requests').setLevel(logging.WARNING)
        logging.getLogger('sqlalchemy').setLevel(logging.WARNING)

    # Ensure data directory from config is available if user hasn't set env vars
    config = load_config()
    data_dir = config.data_dir or str(DEFAULT_DATA_DIR)
    ensure_data_dir(data_dir)
    os.environ.setdefault('GREEUM_DATA_DIR', data_dir)


@main.command()
@click.option('--data-dir', type=click.Path(file_okay=False, dir_okay=True, writable=True), help='Custom data directory')
@click.option('--skip-warmup', is_flag=True, help='Skip SentenceTransformer warm-up step')
@click.option('--start-worker/--skip-worker', default=True, show_default=True, help='Launch background worker after setup completes')
def setup(data_dir: Optional[str], skip_warmup: bool, start_worker: bool):
    """Interactive first-time setup (data dir + optional warm-up)."""

    click.echo("üõ†Ô∏è  Greeum setup wizard")
    config = load_config()

    default_dir = data_dir or config.data_dir or str(DEFAULT_DATA_DIR)
    if data_dir:
        chosen_dir = str(Path(data_dir).expanduser())
        click.echo(f"Using data directory: {chosen_dir}")
    else:
        chosen_dir = click.prompt(
            "Data directory (used for memories, cache, logs)",
            default=str(Path(default_dir).expanduser()),
        )

    target_dir = ensure_data_dir(chosen_dir)
    os.environ['GREEUM_DATA_DIR'] = str(target_dir)
    try:
        _ensure_database_ready(Path(target_dir))
    except click.ClickException as exc:
        click.echo(f"[ERROR] {exc}")
        sys.exit(1)

    semantic_ready = config.semantic_ready
    warmup_performed = False

    if skip_warmup:
        click.echo("Skipping embedding warm-up (hash fallback will be used by default).")
    else:
        default_confirm = not config.semantic_ready
        if click.confirm("Run SentenceTransformer warm-up now?", default=default_confirm):
            click.echo(f"üì¶ Downloading {DEFAULT_ST_MODEL} ‚Ä¶")
            try:
                cache_dir = _download_sentence_transformer(DEFAULT_ST_MODEL)
            except ImportError as exc:
                click.echo(f"[ERROR] {exc}", err=True)
                semantic_ready = False
            except Exception as exc:  # noqa: BLE001
                click.echo(f"[ERROR] Warm-up failed: {exc}", err=True)
                semantic_ready = False
            else:
                click.echo(f"‚úÖ Warm-up complete. Model cached at {cache_dir}.")
                semantic_ready = True
                warmup_performed = True
        else:
            click.echo("Warm-up skipped. You can run 'greeum mcp warmup' later.")

    config.data_dir = str(target_dir)
    config.semantic_ready = semantic_ready
    save_config(config)

    if warmup_performed:
        mark_semantic_ready(True)
    elif not semantic_ready:
        mark_semantic_ready(False)

    worker_endpoint = None
    worker_log = None
    if start_worker:
        click.echo("\nüöÄ Launching background worker‚Ä¶")
        try:
            endpoint = ensure_http_worker(
                data_dir=Path(target_dir),
                semantic=semantic_ready,
                allow_spawn=True,
            )
            worker_endpoint = endpoint
            os.environ['GREEUM_MCP_HTTP'] = endpoint
            state = get_worker_state(Path(target_dir)) or {}
            worker_log = state.get('log')
        except Exception as exc:  # noqa: BLE001 - show warning only
            click.echo(f"[WARN] Failed to launch worker automatically: {exc}")
        else:
            click.echo(f"   ‚Ä¢ Worker endpoint: {worker_endpoint}")
            if worker_log:
                click.echo(f"   ‚Ä¢ Worker log: {worker_log}")
            else:
                click.echo("   ‚Ä¢ Worker log: <not recorded>")

    click.echo("\nSetup summary:")
    click.echo(f"   ‚Ä¢ Data directory: {target_dir}")
    click.echo(
        "   ‚Ä¢ Semantic embeddings: "
        + ("ready" if semantic_ready else "hash fallback (run warmup to enable)")
    )
    if start_worker and worker_endpoint:
        click.echo("   ‚Ä¢ Worker: running (auto-start)")
    elif start_worker:
        click.echo("   ‚Ä¢ Worker: failed to start (use 'greeum worker serve' later)")
    else:
        click.echo("   ‚Ä¢ Worker: skipped (use 'greeum worker serve' when needed)")
    click.echo("   ‚Ä¢ Next step: run 'greeum memory add ""Your first note""' to test the connection")
@main.group()
def memory():
    """Memory management commands (STM/LTM)"""
    pass

@main.group() 
def mcp():
    """MCP server commands"""
    pass

@main.group()
def worker():
    """Worker daemon utilities"""
    pass

@main.group()
def ltm():
    """Long-term memory (LTM) specialized commands"""
    pass

@main.group()
def stm():
    """Short-term memory (STM) specialized commands"""
    pass

@main.group()
def api():
    """API server commands"""
    pass

@main.group()
def slots():
    """AI Context Slots management (v2.5.1 enhanced)"""
    pass

@main.group()
def migrate():
    """Database migration commands (v2.5.3 AI-Powered Migration)"""
    pass

@main.group()
def backup():
    """Memory backup and restore commands (v2.6.1)"""
    pass

@main.group() 
def restore():
    """Memory restore commands (v2.6.1)"""
    pass

@main.group()
def dashboard():
    """Memory dashboard and analytics (v2.6.2)"""
    pass

@main.group()
def graph():
    """Graph network management (v3.0.0)"""
    pass

@main.group()
def metrics():
    """Metrics and performance monitoring"""
    pass

@main.group()
def validate():
    """Documentation and code validation"""
    pass

@main.command()
@click.option('--check', is_flag=True, help='ÏßÑÎã®Îßå ÏàòÌñâ')
@click.option('--fix', is_flag=True, help='ÏûêÎèô Î≥µÍµ¨ Ìè¨Ìï®')
@click.option('--force', is_flag=True, help='Í∞ïÏ†ú Î≥µÍµ¨')
@click.option('--no-backup', is_flag=True, help='Î∞±ÏóÖ ÏÉùÎûµ')
@click.option('--db-path', help='Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ Í≤ΩÎ°ú')
def doctor(check: bool, fix: bool, force: bool, no_backup: bool, db_path: str):
    """System diagnostics and repair tool (Ï≤¥ÌÅ¨, ÎßàÏù¥Í∑∏Î†àÏù¥ÏÖò, Ï†ïÎ¶¨, ÏµúÏ†ÅÌôî)"""
    try:
        from .doctor import GreeumDoctor

        doctor_instance = GreeumDoctor(db_path)

        # Î∞±ÏóÖ
        if (fix or force) and not no_backup:
            backup_path = doctor_instance.backup_database()
            click.echo(f"üì¶ Î∞±ÏóÖ ÏÉùÏÑ±: {backup_path}")

        # ÏßÑÎã®
        health = doctor_instance.check_health()
        doctor_instance.print_report(health)

        # Î≥µÍµ¨
        if fix or force or (not check and doctor_instance.issues):
            if not check and not fix and not force:
                response = click.confirm("\nÎ≥µÍµ¨Î•º ÏßÑÌñâÌïòÏãúÍ≤†ÏäµÎãàÍπå?", default=False)
                if not response:
                    click.echo("Î≥µÍµ¨Í∞Ä Ï∑®ÏÜåÎêòÏóàÏäµÎãàÎã§.")
                    return

            fixes = doctor_instance.fix_issues(force)
            if fixes:
                click.echo(f"\n‚úÖ Î≥µÍµ¨ ÏôÑÎ£å: {len(fixes)}Í∞ú Î¨∏Ï†ú Ìï¥Í≤∞")
                for fix_msg in fixes:
                    click.echo(f"  ‚Ä¢ {fix_msg}")

            # Ïû¨ÏßÑÎã®
            click.echo("\nüîÑ Î≥µÍµ¨ ÌõÑ Ïû¨ÏßÑÎã®...")
            health = doctor_instance.check_health()
            click.echo(f"\nÏµúÏ¢Ö ÏÉÅÌÉú: Ï†êÏàò {health['total_score']:.0f}/100")

        sys.exit(0 if health['total_score'] >= 70 else 1)

    except Exception as e:
        click.echo(f"‚ùå Ïò§Î•ò Î∞úÏÉù: {e}")
        sys.exit(1)


# Memory ÏÑúÎ∏åÎ™ÖÎ†πÏñ¥Îì§
def _maybe_call_http_tool(tool: str, arguments: Dict[str, Any]) -> Optional[Dict[str, Any]]:
    endpoint = os.getenv('GREEUM_MCP_HTTP')
    if not endpoint:
        return None

    import json
    import urllib.request
    import urllib.error
    import uuid

    payload = {
        "jsonrpc": "2.0",
        "id": str(uuid.uuid4()),
        "method": "tools/call",
        "params": {
            "name": tool,
            "arguments": arguments,
        },
    }

    timeout = float(os.getenv('GREEUM_HTTP_TIMEOUT', '30'))
    req = urllib.request.Request(
        endpoint,
        data=json.dumps(payload).encode('utf-8'),
        headers={'Content-Type': 'application/json'},
    )

    try:
        with urllib.request.urlopen(req, timeout=timeout) as resp:
            if resp.status == 204:
                return {}
            body = resp.read().decode('utf-8')
    except urllib.error.HTTPError as exc:
        detail = exc.read().decode('utf-8')
        raise RuntimeError(f"HTTP call failed: {exc.code} {detail}") from exc
    except urllib.error.URLError as exc:
        raise RuntimeError(f"HTTP call failed: {exc}") from exc

    try:
        message = json.loads(body)
    except json.JSONDecodeError as exc:
        raise RuntimeError(f"Invalid MCP HTTP response: {body}") from exc

    if 'error' in message:
        raise RuntimeError(f"MCP error: {message['error']}")

    return message.get('result')


def _decide_worker(use_worker_flag: bool, no_worker_flag: bool) -> Optional[bool]:
    if no_worker_flag:
        return False
    if use_worker_flag:
        return True
    env = os.getenv("GREEUM_USE_WORKER")
    if env:
        return env.lower() not in {"0", "false", "no", "off"}
    return None


def _try_worker_call(tool: str, arguments: Dict[str, Any], use_worker_flag: bool, no_worker_flag: bool, quiet: bool = False, config: Optional[GreeumConfig] = None) -> Optional[Dict[str, Any]]:
    decision = _decide_worker(use_worker_flag, no_worker_flag)
    endpoint = resolve_endpoint()

    if decision is False:
        return None

    if not endpoint:
        base_dir = os.environ.get("GREEUM_DATA_DIR")
        data_root = base_dir or (config.data_dir if config else str(DEFAULT_DATA_DIR))
        data_dir = Path(data_root).expanduser()
        semantic_ready = bool(config.semantic_ready) if config else False
        try:
            endpoint = ensure_http_worker(
                data_dir=data_dir,
                semantic=semantic_ready,
                allow_spawn=True,
            )
            if endpoint:
                os.environ["GREEUM_MCP_HTTP"] = endpoint
        except Exception as exc:  # noqa: BLE001 - surface fallback warning
            if not quiet:
                click.echo(f"[WARN] Auto worker unavailable ({exc}); using local execution.")
            endpoint = None

    try:
        if not endpoint:
            return None
        client = WriteServiceClient(endpoint)
        payload = client.call(tool, arguments)
        if isinstance(payload, dict):
            text_blocks = [
                block.get("text", "")
                for block in payload.get("content", [])
                if isinstance(block, dict) and block.get("type") == "text"
            ]
            if text_blocks:
                payload["text"] = "\n".join(block.strip() for block in text_blocks if block)
        return payload
    except WorkerUnavailableError as exc:
        if not quiet:
            click.echo(f"[WARN] Worker unavailable ({exc}); falling back to local execution.")
        return None


@memory.command()
@click.argument('content')
@click.option('--importance', '-i', default=0.5, help='Importance score (0.0-1.0)')
@click.option('--tags', '-t', help='Comma-separated tags')
@click.option('--slot', '-s', type=click.Choice(['A', 'B', 'C']), help='Insert near specified anchor slot')
@click.option('--use-worker', is_flag=True, help='Force using the worker endpoint when available')
@click.option('--no-worker', is_flag=True, help='Force local execution without contacting the worker')
def add(content: str, importance: float, tags: Optional[str], slot: Optional[str], use_worker: bool, no_worker: bool):
    """Add new memory to long-term storage"""
    try:
        config = load_config()
        worker_args = {
            "content": content,
            "importance": importance,
        }
        if tags:
            worker_args["metadata"] = {"tags": tags.split(',')}
        if slot:
            worker_args["slot"] = slot
        worker_response = _try_worker_call("add_memory", worker_args, use_worker, no_worker, config=config)
        if worker_response is not None:
            text = worker_response.get("text")
            if text:
                click.echo(text)
                return
            data = worker_response.get("data") or {}
            block_id = data.get("block_index", data.get("id", "unknown"))
            click.echo(f"‚úÖ Memory added via worker (Block #{block_id})")
            return

        if slot:
            # Use anchor-based write
            from ..api.write import write as anchor_write
            
            result = anchor_write(
                text=content,
                slot=slot,
                policy={'importance': importance, 'tags': tags}
            )
            
            click.echo(f"‚úÖ Memory added near anchor {slot} (Block #{result})")
            
        else:
            # Use traditional write
            from ..core import BlockManager, DatabaseManager
            from ..text_utils import process_user_input

            db_manager = DatabaseManager()
            block_manager = BlockManager(db_manager)
            
            # ÌÖçÏä§Ìä∏ Ï≤òÎ¶¨
            processed = process_user_input(content)
            keywords = processed.get('keywords', [])
            tag_list = tags.split(',') if tags else processed.get('tags', [])
            embedding = processed.get('embedding', [0.0] * 384)
            
            # Î∏îÎ°ù Ï∂îÍ∞Ä
            block = block_manager.add_block(
                context=content,
                keywords=keywords,
                tags=tag_list,
                embedding=embedding,
                importance=importance
            )
            
            if block:
                # block is now just the block_index (int) instead of a dict
                click.echo(f"‚úÖ Memory added (Block #{block})")
            else:
                click.echo("[ERROR] Failed to add memory")
            
    except Exception as e:
        click.echo(f"[ERROR] Error: {e}")
        sys.exit(1)

@memory.command()
@click.argument('query')
@click.option('--count', '-c', default=5, help='Number of results')
@click.option('--threshold', '-th', default=0.1, help='Similarity threshold')
@click.option('--slot', '-s', type=click.Choice(['A', 'B', 'C']), help='Use anchor-based localized search')
@click.option('--radius', '-r', type=int, help='Graph search radius (1-3)')
@click.option('--no-fallback', is_flag=True, help='Disable fallback to global search')
@click.option('--use-worker', is_flag=True, help='Force using the worker endpoint when available')
@click.option('--no-worker', is_flag=True, help='Force local execution without contacting the worker')
def search(query: str, count: int, threshold: float, slot: str, radius: int, no_fallback: bool, use_worker: bool, no_worker: bool):
    """Search memories by keywords/semantic similarity"""
    try:
        config = load_config()
        worker_args = {
            "query": query,
            "limit": count,
            "threshold": threshold,
            "fallback": not no_fallback,
        }
        if slot:
            worker_args["slot"] = slot
        worker_response = _try_worker_call("search_memory", worker_args, use_worker, no_worker, quiet=True, config=config)
        if worker_response is not None:
            text = worker_response.get("text")
            if text:
                click.echo(text)
                return
            items = worker_response.get('data', {}).get('items', [])
            if items:
                for idx, item in enumerate(items, 1):
                    snippet = (item.get('context') or '')[:80]
                    score = item.get('relevance_score', item.get('score'))
                    click.echo(f"{idx}. {snippet} (score={score})")
            else:
                click.echo("No results found (worker)")
            return

        from ..core.block_manager import BlockManager
        from ..core.database_manager import DatabaseManager

        # Use BlockManager for DFS-based search instead of SearchEngine
        db_manager = DatabaseManager()
        block_manager = BlockManager(db_manager)

        # Perform search with v3 DFS system
        result = block_manager.search_with_slots(
            query=query,
            limit=count,
            use_slots=True,
            entry="cursor",
            depth=3 if slot else 0,
            fallback=not no_fallback
        )

        # Extract blocks from result
        if isinstance(result, dict):
            blocks = result.get('items', [])
            metadata = result.get('meta', {})
        else:
            blocks = result
        metadata = result.get('metadata', {})
        timing = result.get('timing', {})
        
        if blocks:
            # Display search info
            if slot:
                search_type = f"üéØ Anchor-based search (slot {slot})"
                if metadata.get('fallback_used'):
                    search_type += " ‚Üí [PROCESS] Global fallback"
                click.echo(search_type)
                click.echo(f"   Hit rate: {metadata.get('local_hit_rate', 0):.1%}")
                click.echo(f"   Avg hops: {metadata.get('avg_hops', 0)}")
            else:
                click.echo("üîç Global semantic search")
            
            # Display timing
            total_ms = sum(timing.values())
            click.echo(f"   Search time: {total_ms:.1f}ms")
            
            click.echo(f"\nüìã Found {len(blocks)} memories:")
            for i, block in enumerate(blocks, 1):
                timestamp = block.get('timestamp', 'Unknown')
                content = block.get('context', 'No content')[:80]
                relevance = block.get('relevance_score', 0)
                final_score = block.get('final_score', relevance)
                
                click.echo(f"{i}. [{timestamp}] {content}...")
                click.echo(f"   Score: {final_score:.3f}")
        else:
            if slot and not no_fallback:
                click.echo(f"[ERROR] No memories found in anchor slot {slot}, and fallback disabled")
            else:
                click.echo("[ERROR] No memories found")

    except Exception as e:
        click.echo(f"[ERROR] Search failed: {e}")
        sys.exit(1)


@memory.command('reindex')
@click.option(
    '--data-dir',
    type=click.Path(file_okay=False, dir_okay=True, writable=True),
    help='Target data directory (defaults to configured data store)',
)
@click.option('--disable-faiss', is_flag=True, help='Skip FAISS vector index rebuild')
def memory_reindex(data_dir: Optional[str], disable_faiss: bool) -> None:
    """Rebuild branch-aware indices for the selected database."""
    from ..core.branch_index import BranchIndexManager

    if disable_faiss:
        os.environ['GREEUM_DISABLE_FAISS'] = 'true'

    if data_dir:
        target_dir = Path(data_dir).expanduser()
        db_path = target_dir if target_dir.suffix == '.db' else target_dir / 'memory.db'
        manager = DatabaseManager(connection_string=str(db_path))
    else:
        manager = DatabaseManager()

    click.echo('üîÑ Rebuilding branch indices...')
    try:
        branch_manager = BranchIndexManager(manager)
        stats = branch_manager.get_stats()
        click.echo(
            "‚úÖ Rebuilt {count} branches ({mode}, vectorized={vectorized}).".format(
                count=stats['branch_count'],
                mode=stats['mode'],
                vectorized=stats['vectorized_branches'],
            )
        )
    except Exception as exc:  # noqa: BLE001 - surface to CLI
        click.echo(f"[ERROR] Branch reindex failed: {exc}")
        sys.exit(1)
    finally:
        try:
            manager.conn.close()
        except Exception:
            pass
        except Exception:
            pass

# MCP ÏÑúÎ∏åÎ™ÖÎ†πÏñ¥Îì§
@mcp.command()
@click.option('--transport', '-t', default='stdio', help='Transport type (stdio/http/ws)')
@click.option('--port', '-p', default=3000, help='Port for HTTP or WebSocket transports')
@click.option('--host', default='127.0.0.1', show_default=True, help='Host for HTTP transport')
@click.option('--verbose', '-v', is_flag=True, help='Enable verbose logging (INFO level)')
@click.option('--debug', '-d', is_flag=True, help='Enable debug logging (DEBUG level)')
@click.option('--quiet', '-q', is_flag=True, help='[DEPRECATED] Use default behavior instead')
@click.option('--semantic/--no-semantic', default=False, show_default=True,
              help='Enable semantic embeddings (requires cached SentenceTransformer)')
def serve(transport: str, port: int, host: str, verbose: bool, debug: bool, quiet: bool, semantic: bool):
    """Start MCP server for Claude Code integration"""  
    config = load_config()
    # Î°úÍπÖ Î†àÎ≤® Í≤∞Ï†ï (ÏÉàÎ°úÏö¥ Ï†ïÏ±Ö: Í∏∞Î≥∏ÏùÄ Ï°∞Ïö©Ìï®)
    if debug:
        log_level = 'debug'
        click.echo(f"üîç Starting Greeum MCP server ({transport}) - DEBUG mode...")
    elif verbose:
        log_level = 'verbose'
        click.echo(f"[NOTE] Starting Greeum MCP server ({transport}) - VERBOSE mode...")
    else:
        log_level = 'quiet'
        # Í∏∞Î≥∏ÏùÄ Ï°∞Ïö©Ìï® (Ï∂úÎ†• ÏóÜÏùå)
    
    # --quiet ÌîåÎûòÍ∑∏ Ìò∏ÌôòÏÑ± Í≤ΩÍ≥†
    if quiet:
        if verbose or debug:
            click.echo("‚ö†Ô∏è  Warning: --quiet is deprecated and conflicts with --verbose/--debug")
        else:
            click.echo("‚ö†Ô∏è  Warning: --quiet is deprecated. Default behavior is now quiet.")
    
    if transport == 'stdio':
        ensure_data_dir(config.data_dir)
        os.environ.setdefault('GREEUM_DATA_DIR', config.data_dir)
        if semantic:
            # Allow explicit opt-in by clearing the fallback flag
            if os.getenv('GREEUM_DISABLE_ST'):
                os.environ.pop('GREEUM_DISABLE_ST')
            if verbose or debug and not config.semantic_ready:
                click.echo('[WARN] Semantic mode requested but warm-up is not recorded; first startup may take longer.')
            try:
                init_sentence_transformer(set_as_default=True)
            except RuntimeError as err:
                if verbose or debug:
                    click.echo(f'[WARN] {err}')
            except ImportError as err:
                if verbose or debug:
                    click.echo(f'[WARN] {err}')
                force_simple_fallback(set_as_default=True)
        else:
            os.environ.setdefault('GREEUM_DISABLE_ST', '1')
            if verbose or debug:
                if config.semantic_ready:
                    click.echo('[NOTE] Semantic embeddings available. Use --semantic to enable them for this session.')
                else:
                    click.echo('[NOTE] SentenceTransformer disabled (hash fallback). Use --semantic after warm-up to re-enable.')
            force_simple_fallback(set_as_default=True)
        try:
            # Native MCP Server ÏÇ¨Ïö© (FastMCP ÏôÑÏ†Ñ Î∞∞Ï†ú, anyio Í∏∞Î∞ò ÏïàÏ†ÑÌïú Ïã§Ìñâ)
            from ..mcp.native import run_server_sync
            run_server_sync(log_level=log_level)
        except ImportError as e:
            if verbose or debug:
                click.echo(f"Native MCP server import failed: {e}")
                click.echo("Please ensure anyio>=4.5 is installed: pip install anyio>=4.5")
            sys.exit(1)
        except KeyboardInterrupt:
            if verbose or debug:
                click.echo("\nMCP server stopped")
        except Exception as e:
            # anyio CancelledErrorÎèÑ Ïó¨Í∏∞ÏÑú Ï∫êÏπòÎê® - Ï°∞Ïö©Ìûà Ï≤òÎ¶¨
            error_msg = str(e)
            if "CancelledError" in error_msg or "cancelled" in error_msg.lower():
                if verbose or debug:
                    click.echo("\nMCP server stopped")
            else:
                if verbose or debug:
                    click.echo(f"MCP server error: {e}")
                sys.exit(1)
    elif transport == 'http':
        try:
            from ..mcp.native.http_server import run_http_server
            run_http_server(host=host, port=port, log_level=log_level)
        except RuntimeError as e:
            if verbose or debug:
                click.echo(str(e))
            sys.exit(1)
        except KeyboardInterrupt:
            if verbose or debug:
                click.echo("\nMCP HTTP server stopped")
        except Exception as e:
            if verbose or debug:
                click.echo(f"MCP HTTP server error: {e}")
            sys.exit(1)
    elif transport == 'websocket':
        try:
            # WebSocket transport (Ìñ•ÌõÑ ÌôïÏû•)
            from ..mcp.cli_entry import run_cli_server
            run_cli_server(transport='websocket', port=port)
        except ImportError as e:
            if verbose or debug:
                click.echo(f"MCP server import failed: {e}")
                click.echo("Please ensure all dependencies are installed")
            sys.exit(1)
        except NotImplementedError:
            if verbose or debug:
                click.echo(f"WebSocket transport not implemented yet")
            sys.exit(1)
        except KeyboardInterrupt:
            if verbose or debug:
                click.echo("\nMCP server stopped")
        except Exception as e:
            if verbose or debug:
                click.echo(f"MCP server error: {e}")
            sys.exit(1)
    else:
        if verbose or debug:
            click.echo(f"[ERROR] Transport '{transport}' not supported")
        sys.exit(1)


@worker.command('serve')
@click.option('--host', default='127.0.0.1', show_default=True)
@click.option('--port', default=8800, show_default=True, type=int)
@click.option('--semantic', is_flag=True, help='Enable semantic embeddings for the worker')
@click.option('--stdio', is_flag=True, help='Use STDIO transport instead of HTTP')
def worker_serve(host: str, port: int, semantic: bool, stdio: bool) -> None:
    """Start the long-running worker daemon."""
    transport = 'stdio' if stdio else 'http'
    cmd = [
        sys.executable,
        '-m',
        'greeum.cli',
        'mcp',
        'serve',
        '-t',
        transport,
    ]
    if not stdio:
        cmd += ['--host', host, '--port', str(port)]
    if semantic:
        cmd.append('--semantic')
    click.echo(f"Starting worker daemon ({'STDIO' if stdio else 'HTTP'})...")
    click.echo('Command: ' + ' '.join(cmd))
    try:
        subprocess.run(cmd, check=True)
    except subprocess.CalledProcessError as exc:
        click.echo(f"Worker exited with status {exc.returncode}")

@mcp.command('warmup')
@click.option('--model', default='sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2',
              show_default=True, help='SentenceTransformer model to pre-download')
def warmup_embeddings(model: str):
    """Download the semantic embedding model so --semantic starts instantly."""

    click.echo(f"üì¶ Downloading {model} ‚Ä¶")

    try:
        cache_dir = _download_sentence_transformer(model)
    except ImportError as exc:
        click.echo(f"[ERROR] {exc}", err=True)
        mark_semantic_ready(False)
        sys.exit(1)
    except Exception as exc:  # noqa: BLE001 - surface full error to user
        click.echo(f"[ERROR] Warm-up failed: {exc}", err=True)
        mark_semantic_ready(False)
        sys.exit(1)

    mark_semantic_ready(True)
    click.echo(f"‚úÖ Warm-up complete. Model cached at {cache_dir}.")
    click.echo("   Use 'greeum mcp serve --semantic' to enable semantic embeddings.")


# API ÏÑúÎ∏åÎ™ÖÎ†πÏñ¥Îì§  
@api.command()
@click.option('--port', '-p', default=5000, help='Server port')
@click.option('--host', '-h', default='localhost', help='Server host')
def serve(port: int, host: str):
    """Start REST API server"""
    click.echo(f"üåê Starting Greeum API server on {host}:{port}...")
    
    try:
        from ..api.memory_api import app
        import uvicorn
        uvicorn.run(app, host=host, port=port)
    except ImportError:
        click.echo("[ERROR] API server dependencies not installed. Try: pip install greeum[api]")
        sys.exit(1)
    except KeyboardInterrupt:
        click.echo("\nüëã API server stopped")

# LTM ÏÑúÎ∏åÎ™ÖÎ†πÏñ¥Îì§
@ltm.command()
@click.option('--trends', is_flag=True, help='Analyze emotional and topic trends')
@click.option('--period', '-p', default='6m', help='Analysis period (e.g., 6m, 1y)')
@click.option('--output', '-o', default='text', help='Output format (text/json)')
def analyze(trends: bool, period: str, output: str):
    """Analyze long-term memory patterns and trends"""
    click.echo(f"üîç Analyzing LTM patterns...")
    
    if trends:
        click.echo(f"üìä Trend analysis for period: {period}")
    
    try:
        from ..core import BlockManager, DatabaseManager
        import json
        from datetime import datetime, timedelta
        
        # Í∏∞Í∞Ñ ÌååÏã±
        period_map = {'m': 'months', 'y': 'years', 'd': 'days', 'w': 'weeks'}
        period_num = int(period[:-1])
        period_unit = period_map.get(period[-1], 'months')
        
        db_manager = DatabaseManager()
        block_manager = BlockManager(db_manager)
        
        # Ï†ÑÏ≤¥ Î∏îÎ°ù Ï°∞Ìöå
        all_blocks = block_manager.get_blocks()
        
        analysis = {
            "total_blocks": len(all_blocks),
            "analysis_period": period,
            "analysis_date": datetime.now().isoformat(),
            "summary": f"Analyzed {len(all_blocks)} memory blocks"
        }
        
        if trends:
            # ÌÇ§ÏõåÎìú ÎπàÎèÑ Î∂ÑÏÑù
            keyword_freq = {}
            for block in all_blocks:
                keywords = block.get('keywords', [])
                for keyword in keywords:
                    keyword_freq[keyword] = keyword_freq.get(keyword, 0) + 1
            
            # ÏÉÅÏúÑ ÌÇ§ÏõåÎìú
            top_keywords = sorted(keyword_freq.items(), key=lambda x: x[1], reverse=True)[:10]
            analysis["top_keywords"] = top_keywords
        
        if output == 'json':
            click.echo(json.dumps(analysis, indent=2, ensure_ascii=False))
        else:
            click.echo(f"[IMPROVE] Analysis Results:")
            click.echo(f"  ‚Ä¢ Total memories: {analysis['total_blocks']}")
            click.echo(f"  ‚Ä¢ Period: {analysis['analysis_period']}")
            if trends and 'top_keywords' in analysis:
                click.echo(f"  ‚Ä¢ Top keywords:")
                for keyword, freq in analysis['top_keywords'][:5]:
                    click.echo(f"    - {keyword}: {freq} times")
                    
    except Exception as e:
        click.echo(f"[ERROR] Analysis failed: {e}")
        sys.exit(1)

@ltm.command()
@click.option('--repair', is_flag=True, help='Attempt to repair integrity issues')
def verify(repair: bool):
    """Verify blockchain-like LTM integrity"""
    click.echo("üîç Verifying LTM blockchain integrity...")
    
    try:
        from ..core import BlockManager, DatabaseManager
        import hashlib
        
        db_manager = DatabaseManager()
        block_manager = BlockManager(db_manager)
        
        all_blocks = block_manager.get_blocks()
        
        issues = []
        verified_count = 0
        
        for i, block in enumerate(all_blocks):
            # Ìï¥Ïãú Í≤ÄÏ¶ù
            if 'hash' in block:
                # Î∏îÎ°ù Îç∞Ïù¥ÌÑ∞Î°úÎ∂ÄÌÑ∞ Ìï¥Ïãú Ïû¨Í≥ÑÏÇ∞
                block_data = {
                    'block_index': block.get('block_index'),
                    'timestamp': block.get('timestamp'),
                    'context': block.get('context'),
                    'prev_hash': block.get('prev_hash', '')
                }
                calculated_hash = hashlib.sha256(
                    str(block_data).encode()
                ).hexdigest()[:16]
                
                if block.get('hash') != calculated_hash:
                    issues.append(f"Block #{block.get('block_index', i)}: Hash mismatch")
                else:
                    verified_count += 1
            else:
                issues.append(f"Block #{block.get('block_index', i)}: Missing hash")
        
        # Í≤∞Í≥º Ï∂úÎ†•
        total_blocks = len(all_blocks)
        click.echo(f"‚úÖ Verified {verified_count}/{total_blocks} blocks")
        
        if issues:
            click.echo(f"‚ö†Ô∏è  Found {len(issues)} integrity issues:")
            for issue in issues[:10]:  # ÏµúÎåÄ 10Í∞úÎßå ÌëúÏãú
                click.echo(f"  ‚Ä¢ {issue}")
            
            if repair:
                click.echo("üî® Repair functionality not implemented yet")
        else:
            click.echo("[SUCCESS] All blocks verified successfully!")
                    
    except Exception as e:
        click.echo(f"[ERROR] Verification failed: {e}")
        sys.exit(1)

@ltm.command()
@click.option('--format', '-f', default='json', help='Export format (json/blockchain/csv)')
@click.option('--output', '-o', help='Output file path')
@click.option('--limit', '-l', type=int, help='Limit number of blocks')
def export(format: str, output: str, limit: int):
    """Export LTM data in various formats"""
    click.echo(f"üì§ Exporting LTM data (format: {format})...")
    
    try:
        from ..core import BlockManager, DatabaseManager
        import json
        import csv
        from pathlib import Path
        
        db_manager = DatabaseManager()
        block_manager = BlockManager(db_manager)
        
        all_blocks = block_manager.get_blocks()
        
        if limit:
            all_blocks = all_blocks[:limit]
        
        # Ï∂úÎ†• ÌååÏùº Í≤ΩÎ°ú Í≤∞Ï†ï
        if not output:
            from datetime import datetime
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output = f"greeum_ltm_export_{timestamp}.{format}"
        
        output_path = Path(output)
        
        if format == 'json':
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(all_blocks, f, indent=2, ensure_ascii=False)
                
        elif format == 'blockchain':
            # Î∏îÎ°ùÏ≤¥Ïù∏ ÌòïÌÉúÎ°ú Íµ¨Ï°∞Ìôî
            blockchain_data = {
                "chain_info": {
                    "total_blocks": len(all_blocks),
                    "export_date": datetime.now().isoformat(),
                    "format_version": "1.0"
                },
                "blocks": all_blocks
            }
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(blockchain_data, f, indent=2, ensure_ascii=False)
                
        elif format == 'csv':
            with open(output_path, 'w', newline='', encoding='utf-8') as f:
                if all_blocks:
                    writer = csv.DictWriter(f, fieldnames=all_blocks[0].keys())
                    writer.writeheader()
                    writer.writerows(all_blocks)
        
        click.echo(f"‚úÖ Exported {len(all_blocks)} blocks to: {output_path}")
        click.echo(f"üìÑ File size: {output_path.stat().st_size} bytes")
                    
    except Exception as e:
        click.echo(f"[ERROR] Export failed: {e}")
        sys.exit(1)

# STM ÏÑúÎ∏åÎ™ÖÎ†πÏñ¥Îì§
@stm.command()
@click.argument('content')
@click.option('--ttl', default='1h', help='Time to live (e.g., 1h, 30m, 2d)')
@click.option('--importance', '-i', default=0.3, help='Importance score (0.0-1.0)')
def add(content: str, ttl: str, importance: float):
    """Add content to short-term memory with TTL"""
    click.echo(f"[MEMORY] Adding to STM (TTL: {ttl})...")
    
    try:
        from ..core import STMManager, DatabaseManager
        import re
        from datetime import datetime, timedelta
        
        # TTL ÌååÏã±
        ttl_pattern = r'(\d+)([hmdw])'
        match = re.match(ttl_pattern, ttl.lower())
        if not match:
            click.echo("[ERROR] Invalid TTL format. Use: 1h, 30m, 2d, 1w")
            sys.exit(1)
        
        amount, unit = match.groups()
        amount = int(amount)
        
        unit_map = {'m': 'minutes', 'h': 'hours', 'd': 'days', 'w': 'weeks'}
        unit_name = unit_map.get(unit, 'hours')
        
        # TTL Í≥ÑÏÇ∞
        kwargs = {unit_name: amount}
        expiry_time = datetime.now() + timedelta(**kwargs)
        
        db_manager = DatabaseManager()
        stm_manager = STMManager(db_manager)
        
        # STMÏóê Ï∂îÍ∞Ä
        memory_data = {
            'content': content,
            'importance': importance,
            'ttl_seconds': int(timedelta(**kwargs).total_seconds()),
            'expiry_time': expiry_time.isoformat()
        }
        result = stm_manager.add_memory(memory_data)
        
        if result:
            click.echo(f"‚úÖ Added to STM (expires: {expiry_time.strftime('%Y-%m-%d %H:%M:%S')})")
        else:
            click.echo("[ERROR] Failed to add to STM")
            sys.exit(1)
                    
    except Exception as e:
        click.echo(f"[ERROR] STM add failed: {e}")
        sys.exit(1)

@stm.command()
@click.option('--threshold', '-t', default=0.8, help='Importance threshold for promotion')
@click.option('--dry-run', is_flag=True, help='Show what would be promoted without doing it')
def promote(threshold: float, dry_run: bool):
    """Promote important STM entries to LTM"""
    click.echo(f"üîù Promoting STM ‚Üí LTM (threshold: {threshold})...")
    
    try:
        from ..core import STMManager, BlockManager, DatabaseManager
        from ..text_utils import process_user_input
        
        db_manager = DatabaseManager()
        stm_manager = STMManager(db_manager)
        block_manager = BlockManager(db_manager)
        
        # STMÏóêÏÑú Î™®Îì† Ìï≠Î™© Ï°∞Ìöå (Ï∂©Î∂ÑÌûà ÌÅ∞ ÏàòÎ°ú)
        stm_entries = stm_manager.get_recent_memories(count=1000)
        
        candidates = []
        for entry in stm_entries:
            if entry.get('importance', 0) >= threshold:
                candidates.append(entry)
        
        if not candidates:
            click.echo(f"üì≠ No STM entries above threshold {threshold}")
            return
        
        click.echo(f"üéØ Found {len(candidates)} candidates for promotion:")
        
        promoted_count = 0
        for entry in candidates:
            content = entry.get('content', '')
            importance = entry.get('importance', 0)
            
            click.echo(f"  ‚Ä¢ {content[:50]}... (importance: {importance:.2f})")
            
            if not dry_run:
                # LTMÏúºÎ°ú ÏäπÍ≤©
                keywords, tags = process_user_input(content)
                
                # Í∞ÑÎã®Ìïú ÏûÑÎ≤†Îî© (Ïã§Ï†úÎ°úÎäî Îçî Ï†ïÍµêÌïòÍ≤å)
                simple_embedding = [hash(word) % 1000 / 1000.0 for word in content.split()[:10]]
                simple_embedding.extend([0.0] * (10 - len(simple_embedding)))  # 10Ï∞®ÏõêÏúºÎ°ú Ìå®Îî©
                
                ltm_block = block_manager.add_block(
                    context=content,
                    keywords=keywords,
                    tags=tags,
                    embedding=simple_embedding,
                    importance=importance,
                    metadata={'promoted_from_stm': True}
                )
                
                if ltm_block:
                    # STMÏóêÏÑú Ï†úÍ±∞
                    stm_manager.remove_memory(entry.get('id', ''))
                    promoted_count += 1
        
        if dry_run:
            click.echo(f"üîç Dry run: {len(candidates)} entries would be promoted")
        else:
            click.echo(f"‚úÖ Promoted {promoted_count}/{len(candidates)} entries to LTM")
                    
    except Exception as e:
        click.echo(f"[ERROR] Promotion failed: {e}")
        sys.exit(1)

@stm.command()
@click.option('--smart', is_flag=True, help='Use intelligent cleanup based on importance')
@click.option('--expired', is_flag=True, help='Remove only expired entries')
@click.option('--threshold', '-t', default=0.2, help='Remove entries below this importance')
def cleanup(smart: bool, expired: bool, threshold: float):
    """Clean up short-term memory entries"""
    click.echo("üßπ Cleaning up STM...")
    
    try:
        from ..core import STMManager, DatabaseManager
        from datetime import datetime
        
        db_manager = DatabaseManager()
        stm_manager = STMManager(db_manager)
        stm_entries = stm_manager.get_recent_memories(count=1000)
        
        if not stm_entries:
            click.echo("üì≠ STM is already empty")
            return
        
        removed_count = 0
        total_count = len(stm_entries)
        
        click.echo(f"üìä Total STM entries: {total_count}")
        
        for entry in stm_entries:
            should_remove = False
            reason = ""
            
            if expired:
                # ÎßåÎ£åÎêú Ìï≠Î™©Îßå Ï†úÍ±∞
                expiry = entry.get('expiry_time')
                if expiry and datetime.now() > datetime.fromisoformat(expiry):
                    should_remove = True
                    reason = "expired"
            
            elif smart:
                # ÏßÄÎä•Ìòï Ï†ïÎ¶¨
                importance = entry.get('importance', 0)
                if importance < threshold:
                    should_remove = True
                    reason = f"low importance ({importance:.2f} < {threshold})"
            
            else:
                # Í∏∞Î≥∏: ÎÇÆÏùÄ Ï§ëÏöîÎèÑÎßå
                importance = entry.get('importance', 0)
                if importance < 0.1:
                    should_remove = True
                    reason = "very low importance"
            
            if should_remove:
                entry_id = entry.get('id', '')
                content = entry.get('content', '')[:30]
                
                if stm_manager.remove_memory(entry_id):
                    click.echo(f"  üóëÔ∏è  Removed: {content}... ({reason})")
                    removed_count += 1
        
        click.echo(f"‚úÖ Cleanup complete: {removed_count}/{total_count} entries removed")
        click.echo(f"üìä Remaining STM entries: {total_count - removed_count}")
                    
    except Exception as e:
        click.echo(f"[ERROR] Cleanup failed: {e}")
        sys.exit(1)

# AI Context Slots ÏÑúÎ∏åÎ™ÖÎ†πÏñ¥Îì§ (v3.0.0.post5)
@slots.command()
def status():
    """Display current AI Context Slots status (v3.0.0.post5)"""
    click.echo("[MEMORY] AI Context Slots Status Report (v3.0.0.post5)")
    click.echo("=" * 50)
    
    try:
        from ..core.working_memory import AIContextualSlots
        from datetime import datetime
        
        # AI Context Slots Ïù∏Ïä§ÌÑ¥Ïä§ ÏÉùÏÑ±
        slots_instance = AIContextualSlots()
        
        # Ïä¨Î°Ø ÏÉÅÌÉú ÌôïÏù∏
        status = slots_instance.get_status()
        
        active_count = sum(1 for s in status.values() if s is not None)
        click.echo(f"Active Slots: {active_count}/3")
        
        for slot_name, slot_info in status.items():
            if slot_info:
                slot_type = slot_info['type']
                content = slot_info['content_preview']
                timestamp = slot_info['timestamp']
                importance = slot_info['importance']
                is_anchor = slot_info['is_anchor']
                
                # Ïä¨Î°Ø ÌÉÄÏûÖÎ≥Ñ ÏïÑÏù¥ÏΩò
                type_icon = {"context": "üéØ", "anchor": "‚öì", "buffer": "üìã"}.get(slot_type, "üîπ")
                
                click.echo(f"\n{type_icon} {slot_name.upper()} Slot ({slot_type})")
                click.echo(f"   Content: {content}")
                click.echo(f"   Importance: {importance:.2f}")
                click.echo(f"   Created: {timestamp}")
                
                if is_anchor and slot_info.get('anchor_block'):
                    click.echo(f"   [LINK] LTM Anchor: Block #{slot_info['anchor_block']}")
                    
            else:
                click.echo(f"\n‚≠ï {slot_name.upper()} Slot: Empty")
        
        click.echo("\n" + "=" * 50)
        click.echo("üí° Use 'greeum slots set <content>' to add to slots")
        click.echo("üí° Use 'greeum slots clear <slot_name>' to clear specific slot")
                    
    except Exception as e:
        click.echo(f"[ERROR] Error reading slots status: {e}")
        sys.exit(1)

@slots.command()
@click.argument('content')
@click.option('--importance', '-i', default=0.5, help='Importance score (0.0-1.0)')
@click.option('--ltm-anchor', type=int, help='LTM block ID for anchoring')
@click.option('--radius', default=5, help='Search radius for LTM anchor')
def set(content: str, importance: float, ltm_anchor: int, radius: int):
    """Add content to AI Context Slots with smart allocation"""
    click.echo(f"[MEMORY] Adding content to AI Context Slots...")
    
    try:
        from ..core.working_memory import AIContextualSlots
        
        # AI Context Slots Ïù∏Ïä§ÌÑ¥Ïä§ ÏÉùÏÑ±
        slots_instance = AIContextualSlots()
        
        # Ïª®ÌÖçÏä§Ìä∏ Íµ¨ÏÑ±
        context = {
            'importance': importance,
            'metadata': {'cli_command': True}
        }
        
        if ltm_anchor:
            context['ltm_block_id'] = ltm_anchor
            context['search_radius'] = radius
        
        # AIÍ∞Ä ÏµúÏ†Å Ïä¨Î°Ø Í≤∞Ï†ï
        used_slot = slots_instance.ai_decide_usage(content, context)
        
        # Í≤∞Í≥º Ï∂úÎ†•
        click.echo(f"‚úÖ Content added to {used_slot.upper()} slot")
        click.echo(f"[NOTE] Content: {content[:80]}{'...' if len(content) > 80 else ''}")
        click.echo(f"üéØ AI chose {used_slot} slot based on content analysis")
        
        if ltm_anchor:
            click.echo(f"[LINK] LTM Anchor: Block #{ltm_anchor} (radius: {radius})")
        
    except Exception as e:
        click.echo(f"[ERROR] Failed to add to slots: {e}")
        sys.exit(1)

@slots.command()
@click.argument('slot_name', type=click.Choice(['active', 'anchor', 'buffer', 'all']))
def clear(slot_name: str):
    """Clear specific slot or all slots"""
    click.echo(f"üóëÔ∏è  Clearing {slot_name} slot(s)...")
    
    try:
        from ..core.working_memory import AIContextualSlots
        
        # AI Context Slots Ïù∏Ïä§ÌÑ¥Ïä§ ÏÉùÏÑ±
        slots_instance = AIContextualSlots()
        
        if slot_name == "all":
            # Î™®Îì† Ïä¨Î°Ø ÎπÑÏö∞Í∏∞
            cleared_count = 0
            for slot in ['active', 'anchor', 'buffer']:
                if slots_instance.clear_slot(slot):
                    cleared_count += 1
            
            click.echo(f"‚úÖ Cleared {cleared_count} slots")
            
        else:
            # ÌäπÏ†ï Ïä¨Î°Ø ÎπÑÏö∞Í∏∞
            if slots_instance.clear_slot(slot_name):
                click.echo(f"‚úÖ Cleared {slot_name.upper()} slot")
            else:
                click.echo(f"‚ö†Ô∏è  {slot_name.upper()} slot was already empty")
        
    except Exception as e:
        click.echo(f"[ERROR] Failed to clear slot: {e}")
        sys.exit(1)

@slots.command()
@click.argument('query')
@click.option('--limit', '-l', default=5, help='Maximum number of results')
def search(query: str, limit: int):
    """Search using AI Context Slots integration"""
    click.echo(f"üîç Searching with AI Context Slots: '{query}'")
    
    try:
        from greeum.core import DatabaseManager
        from greeum.core.block_manager import BlockManager
        
        db_manager = DatabaseManager()
        block_manager = BlockManager(db_manager)
        
        # Ïä¨Î°Ø ÌÜµÌï© Í≤ÄÏÉâ Ïã§Ìñâ
        results = block_manager.search_with_slots(
            query=query, 
            limit=limit, 
            use_slots=True
        )
        
        if results:
            click.echo(f"üìã Found {len(results)} results:")
            
            for i, result in enumerate(results, 1):
                source = result.get('source', 'unknown')
                content = result.get('context', 'No content')[:80]
                importance = result.get('importance', 0)
                
                if source == 'working_memory':
                    slot_type = result.get('slot_type', 'unknown')
                    type_icon = {"context": "üéØ", "anchor": "‚öì", "buffer": "üìã"}.get(slot_type, "üîπ")
                    click.echo(f"{i}. {type_icon} [{slot_type.upper()} SLOT] {content}...")
                else:
                    block_index = result.get('block_index', '?')
                    click.echo(f"{i}. üìö [LTM #{block_index}] {content}...")
                
                click.echo(f"   Importance: {importance:.2f}")
        else:
            click.echo("[ERROR] No results found")
        
    except Exception as e:
        click.echo(f"[ERROR] Search failed: {e}")
        sys.exit(1)

# Migration ÏÑúÎ∏åÎ™ÖÎ†πÏñ¥Îì§ (v2.5.3 AI-Powered Migration)
@migrate.command()
@click.option('--data-dir', default='data', help='Data directory path')
@click.option('--force', is_flag=True, help='Force migration even if already v2.5.3')
def check(data_dir: str, force: bool):
    """Check database schema version and trigger migration if needed"""
    click.echo("üîç Checking Greeum database schema version...")
    
    try:
        from pathlib import Path

        db_path = Path(data_dir).expanduser() / "memory.db"
        db_path.parent.mkdir(parents=True, exist_ok=True)

        manager = DatabaseManager(str(db_path))
        cursor = manager.conn.cursor()

        needs_migration = BranchSchemaSQL.check_migration_needed(cursor)

        if force or needs_migration:
            manager._apply_branch_migration(cursor)
            manager._initialize_branch_structures(cursor)
            manager.conn.commit()
            click.echo("\n‚úÖ Branch schema migration applied.")
        else:
            click.echo("\n‚úÖ Branch schema already up to date.")

        manager.conn.close()
        sys.exit(0)

    except Exception as e:
        click.echo(f"[ERROR] Migration check failed: {e}")
        sys.exit(1)

@migrate.command()
@click.option('--data-dir', default='data', help='Data directory path')
def status(data_dir: str):
    """Check current migration status and schema version"""
    click.echo("üìä Greeum Database Migration Status")
    click.echo("=" * 40)
    
    try:
        from pathlib import Path

        db_path = Path(data_dir).expanduser() / "memory.db"

        if not db_path.exists():
            click.echo("üìÇ Database Status: Not found")
            click.echo("   This appears to be a new installation")
            return

        manager = DatabaseManager(str(db_path))
        cursor = manager.conn.cursor()

        cursor.execute("PRAGMA table_info(blocks)")
        columns = {row[1] for row in cursor.fetchall()}
        branch_columns = {
            'root', 'before', 'after', 'xref',
            'slot', 'branch_similarity', 'branch_created_at'
        }

        branch_ready = branch_columns.issubset(columns)
        anchor_store = get_anchor_store()
        slot_rows = [
            (slot_name, slot_data.anchor_block)
            for slot_name, slot_data in anchor_store.get_slots().items()
        ]

        click.echo(f"üìÇ Database Size: {db_path.stat().st_size} bytes")
        click.echo(f"üìã Branch Columns Present: {'yes' if branch_ready else 'no'}")

        if slot_rows:
            click.echo("\nüéØ STM Slots:")
            for slot_name, block_hash in slot_rows:
                head = block_hash[:8] + '...' if block_hash else 'None'
                click.echo(f"   ‚Ä¢ {slot_name}: head={head}")
        else:
            click.echo("\n‚ö†Ô∏è  STM anchor entries not initialized yet.")

        pending = BranchSchemaSQL.check_migration_needed(cursor)
        click.echo("\n‚úÖ Migration Status: {}".format("Ready" if not pending else "Additional migration required"))

        manager.conn.close()

    except Exception as e:
        click.echo(f"[ERROR] Status check failed: {e}")
        sys.exit(1)

@migrate.command()
@click.option('--data-dir', default='data', help='Data directory path')
@click.option('--yes', '-y', is_flag=True, help='Run without interactive prompts')
def doctor(data_dir: str, yes: bool):
    """Repair legacy or malformed databases."""

    data_path = Path(data_dir).expanduser()
    if data_path.is_file():
        db_path = data_path
        data_path = db_path.parent
    else:
        db_path = data_path / 'memory.db'

    if not db_path.exists():
        click.echo(f"üìÇ No database found at {db_path}. Nothing to repair.")
        return

    try:
        _ensure_database_ready(data_path, auto_accept=yes)
        click.echo("‚úÖ Schema check completed. Database is ready.")
    except click.ClickException as exc:
        click.echo(f"‚ùå Repair aborted: {exc}")


@migrate.command()
@click.option('--data-dir', default='data', help='Data directory path')
def validate(data_dir: str):
    """Run PRAGMA integrity_check on the active database."""

    data_path = Path(data_dir).expanduser()
    if data_path.is_file():
        db_path = data_path
    else:
        db_path = data_path / 'memory.db'

    if not db_path.exists():
        click.echo(f"üìÇ Database not found at {db_path}")
        return

    try:
        conn = sqlite3.connect(str(db_path))
        result = conn.execute("PRAGMA integrity_check").fetchone()[0]
        conn.close()
    except sqlite3.DatabaseError as exc:
        click.echo(f"‚ùå Integrity check failed to run: {exc}")
        return

    if result.lower() == 'ok':
        click.echo("‚úÖ Integrity check OK")
    else:
        click.echo(f"‚ùå Integrity issues detected: {result}")


@migrate.command()
@click.option('--data-dir', default='data', help='Data directory path')
@click.option('--keep-backups', default=5, help='Number of backups to keep')
def cleanup(data_dir: str, keep_backups: int):
    """Remove old backup files, keeping the most recent N entries."""

    data_path = Path(data_dir).expanduser()
    backup_dir = data_path / 'backups'
    if not backup_dir.exists():
        click.echo("üìÇ No backups directory found.")
        return

    backup_files = sorted(
        [p for p in backup_dir.iterdir() if p.is_file()],
        key=lambda p: p.stat().st_mtime,
        reverse=True,
    )

    if len(backup_files) <= keep_backups:
        click.echo(f"‚úÖ {len(backup_files)} backups found. Nothing to remove.")
        return

    to_remove = backup_files[keep_backups:]
    for path in to_remove:
        path.unlink(missing_ok=True)

    click.echo(f"üßπ Removed {len(to_remove)} old backups. Kept {keep_backups} recent copies.")

# v2.6.1 Backup ÏÑúÎ∏åÎ™ÖÎ†πÏñ¥Îì§
@backup.command()
@click.option('--output', '-o', required=True, help='Î∞±ÏóÖ ÌååÏùº Ï†ÄÏû• Í≤ΩÎ°ú')
@click.option('--include-metadata/--no-metadata', default=True, help='ÏãúÏä§ÌÖú Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ Ìè¨Ìï® Ïó¨Î∂Ä')
def export(output: str, include_metadata: bool):
    """Ï†ÑÏ≤¥ Î©îÎ™®Î¶¨Î•º Î∞±ÏóÖ ÌååÏùºÎ°ú ÎÇ¥Î≥¥ÎÇ¥Í∏∞"""
    try:
        from ..core.backup_restore import MemoryBackupEngine
        # from ..core.hierarchical_memory import HierarchicalMemorySystem  # REMOVED: File deleted
        from ..core.database_manager import DatabaseManager
        from pathlib import Path
        
        click.echo("[PROCESS] Î©îÎ™®Î¶¨ Î∞±ÏóÖÏùÑ ÏãúÏûëÌï©ÎãàÎã§...")
        
        # Í≥ÑÏ∏µÏ†Å Î©îÎ™®Î¶¨ ÏãúÏä§ÌÖú Ï¥àÍ∏∞Ìôî - SIMPLIFIED
        db_manager = DatabaseManager()
        # HierarchicalMemorySystem removed - using DatabaseManager directly
        
        backup_engine = MemoryBackupEngine(db_manager)
        success = backup_engine.create_backup(output, include_metadata)
        
        if success:
            click.echo(f"‚úÖ Î∞±ÏóÖ ÏôÑÎ£å: {output}")
            backup_path = Path(output)
            if backup_path.exists():
                size_mb = backup_path.stat().st_size / (1024 * 1024)
                click.echo(f"üìÅ ÌååÏùº ÌÅ¨Í∏∞: {size_mb:.2f} MB")
        else:
            click.echo("[ERROR] Î∞±ÏóÖ ÏÉùÏÑ±Ïóê Ïã§Ìå®ÌñàÏäµÎãàÎã§")
            
    except Exception as e:
        click.echo(f"üí• Î∞±ÏóÖ Ï§ë Ïò§Î•ò: {e}")


@backup.command()
@click.option('--schedule', type=click.Choice(['hourly', 'daily', 'weekly', 'monthly']), 
              required=True, help='Î∞±ÏóÖ Ï£ºÍ∏∞ ÏÑ§Ï†ï')
@click.option('--output-dir', '-d', help='Î∞±ÏóÖ Ï†ÄÏû• ÎîîÎ†âÌÜ†Î¶¨ (Í∏∞Î≥∏: ~/greeum-backups)')
@click.option('--max-backups', type=int, default=10, help='Î≥¥Ï°¥Ìï† ÏµúÎåÄ Î∞±ÏóÖ Ïàò (Í∏∞Î≥∏: 10Í∞ú)')
@click.option('--enable/--disable', default=True, help='ÏûêÎèô Î∞±ÏóÖ ÌôúÏÑ±Ìôî/ÎπÑÌôúÏÑ±Ìôî')
def auto(schedule: str, output_dir: str, max_backups: int, enable: bool):
    """ÏûêÎèô Î∞±ÏóÖ Ïä§ÏºÄÏ§Ñ ÏÑ§Ï†ï Î∞è Í¥ÄÎ¶¨
    
    Examples:
        greeum backup auto --schedule daily --output-dir ~/backups
        greeum backup auto --schedule weekly --max-backups 5
        greeum backup auto --schedule daily --disable
    """
    try:
        from pathlib import Path
        import json
        import os
        
        if not output_dir:
            output_dir = str(Path.home() / "greeum-backups")
        
        # Î∞±ÏóÖ ÎîîÎ†âÌÜ†Î¶¨ ÏÉùÏÑ±
        backup_path = Path(output_dir)
        backup_path.mkdir(parents=True, exist_ok=True)
        
        # ÏûêÎèô Î∞±ÏóÖ ÏÑ§Ï†ï ÌååÏùº Í≤ΩÎ°ú
        config_file = backup_path / "auto_backup_config.json"
        
        if enable:
            # ÏûêÎèô Î∞±ÏóÖ ÌôúÏÑ±Ìôî
            from datetime import datetime
            
            config = {
                "enabled": True,
                "schedule": schedule,
                "output_dir": str(backup_path),
                "max_backups": max_backups,
                "last_backup": None,
                "created_at": datetime.now().isoformat()
            }
            
            with open(config_file, 'w', encoding='utf-8') as f:
                json.dump(config, f, indent=2, ensure_ascii=False)
            
            click.echo(f"‚úÖ ÏûêÎèô Î∞±ÏóÖ ÌôúÏÑ±ÌôîÎê®")
            click.echo(f"   [DATE] Ï£ºÍ∏∞: {schedule}")
            click.echo(f"   üìÅ ÎîîÎ†âÌÜ†Î¶¨: {output_dir}")
            click.echo(f"   üî¢ ÏµúÎåÄ Î∞±ÏóÖ Ïàò: {max_backups}Í∞ú")
            click.echo()
            click.echo("üí° ÏûêÎèô Î∞±ÏóÖ Ïã§Ìñâ Î∞©Î≤ï:")
            
            if schedule == 'hourly':
                cron_expr = "0 * * * *"
            elif schedule == 'daily':
                cron_expr = "0 2 * * *"  # ÏÉàÎ≤Ω 2Ïãú
            elif schedule == 'weekly':
                cron_expr = "0 2 * * 0"  # ÏùºÏöîÏùº ÏÉàÎ≤Ω 2Ïãú
            else:  # monthly
                cron_expr = "0 2 1 * *"  # Îß§Ïõî 1Ïùº ÏÉàÎ≤Ω 2Ïãú
            
            click.echo(f"   crontabÏóê Ï∂îÍ∞Ä: {cron_expr} greeum backup run-auto")
            click.echo("   ÎòêÎäî ÏãúÏä§ÌÖú Ïä§ÏºÄÏ§ÑÎü¨Î•º ÏÇ¨Ïö©ÌïòÏó¨ 'greeum backup run-auto' Ïã§Ìñâ")
            
        else:
            # ÏûêÎèô Î∞±ÏóÖ ÎπÑÌôúÏÑ±Ìôî
            if config_file.exists():
                config_file.unlink()
                click.echo("‚úÖ ÏûêÎèô Î∞±ÏóÖÏù¥ ÎπÑÌôúÏÑ±ÌôîÎêòÏóàÏäµÎãàÎã§")
            else:
                click.echo("‚ÑπÔ∏è  ÏûêÎèô Î∞±ÏóÖÏù¥ Ïù¥ÎØ∏ ÎπÑÌôúÏÑ±Ìôî ÏÉÅÌÉúÏûÖÎãàÎã§")
                
    except Exception as e:
        click.echo(f"üí• ÏûêÎèô Î∞±ÏóÖ ÏÑ§Ï†ï Ïã§Ìå®: {e}")


@backup.command()
def run_auto():
    """ÏûêÎèô Î∞±ÏóÖ Ïã§Ìñâ (Ïä§ÏºÄÏ§ÑÎü¨ÏóêÏÑú Ìò∏Ï∂ú)
    
    Ïù¥ Î™ÖÎ†πÏñ¥Îäî cronÏù¥ÎÇò ÏãúÏä§ÌÖú Ïä§ÏºÄÏ§ÑÎü¨ÏóêÏÑú Ìò∏Ï∂úÎê©ÎãàÎã§.
    """
    try:
        from pathlib import Path
        from datetime import datetime, timedelta
        import json
        import glob
        
        # Í∏∞Î≥∏ Î∞±ÏóÖ ÎîîÎ†âÌÜ†Î¶¨
        backup_dir = Path.home() / "greeum-backups"
        config_file = backup_dir / "auto_backup_config.json"
        
        if not config_file.exists():
            click.echo("‚ö†Ô∏è  ÏûêÎèô Î∞±ÏóÖÏù¥ ÏÑ§Ï†ïÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§. 'greeum backup auto' Î™ÖÎ†πÏñ¥Î•º Î®ºÏ†Ä Ïã§ÌñâÌïòÏÑ∏Ïöî")
            return
        
        # ÏÑ§Ï†ï Î°úÎìú
        with open(config_file, 'r', encoding='utf-8') as f:
            config = json.load(f)
        
        if not config.get('enabled', False):
            click.echo("‚ÑπÔ∏è  ÏûêÎèô Î∞±ÏóÖÏù¥ ÎπÑÌôúÏÑ±ÌôîÎêòÏñ¥ ÏûàÏäµÎãàÎã§")
            return
        
        schedule = config['schedule']
        max_backups = config.get('max_backups', 10)
        last_backup = config.get('last_backup')
        
        # ÎßàÏßÄÎßâ Î∞±ÏóÖ Ïù¥ÌõÑ Ï∂©Î∂ÑÌïú ÏãúÍ∞ÑÏù¥ ÏßÄÎÇ¨ÎäîÏßÄ ÌôïÏù∏
        now = datetime.now()
        should_backup = True
        
        if last_backup:
            last_backup_time = datetime.fromisoformat(last_backup)
            
            if schedule == 'hourly' and now - last_backup_time < timedelta(hours=1):
                should_backup = False
            elif schedule == 'daily' and now - last_backup_time < timedelta(days=1):
                should_backup = False
            elif schedule == 'weekly' and now - last_backup_time < timedelta(weeks=1):
                should_backup = False
            elif schedule == 'monthly' and now - last_backup_time < timedelta(days=30):
                should_backup = False
        
        if not should_backup:
            click.echo("‚ÑπÔ∏è  ÏïÑÏßÅ Î∞±ÏóÖ ÏãúÍ∞ÑÏù¥ ÏïÑÎãôÎãàÎã§")
            return
        
        # Î∞±ÏóÖ Ïã§Ìñâ
        timestamp = now.strftime("%Y%m%d_%H%M%S")
        backup_filename = f"auto_backup_{timestamp}.json"
        backup_path = backup_dir / backup_filename
        
        click.echo(f"[PROCESS] ÏûêÎèô Î∞±ÏóÖ Ïã§Ìñâ: {backup_filename}")
        
        # Î∞±ÏóÖ ÏóîÏßÑ Ï¥àÍ∏∞Ìôî Î∞è Î∞±ÏóÖ Ïã§Ìñâ
        from ..core.backup_restore import MemoryBackupEngine
        # from ..core.hierarchical_memory import HierarchicalMemorySystem  # REMOVED: File deleted
        from ..core.database_manager import DatabaseManager
        
        db_manager = DatabaseManager()
        
        backup_engine = MemoryBackupEngine(db_manager)
        success = backup_engine.create_backup(str(backup_path), include_metadata=True)
        
        if success:
            # Î∞±ÏóÖ ÏÑ§Ï†ï ÏóÖÎç∞Ïù¥Ìä∏
            config['last_backup'] = now.isoformat()
            with open(config_file, 'w', encoding='utf-8') as f:
                json.dump(config, f, indent=2, ensure_ascii=False)
            
            # Ïò§ÎûòÎêú Î∞±ÏóÖ ÌååÏùº Ï†ïÎ¶¨
            backup_pattern = str(backup_dir / "auto_backup_*.json")
            backup_files = sorted(glob.glob(backup_pattern), reverse=True)  # ÏµúÏã†Î∂ÄÌÑ∞
            
            if len(backup_files) > max_backups:
                old_backups = backup_files[max_backups:]
                for old_backup in old_backups:
                    Path(old_backup).unlink()
                    click.echo(f"üóëÔ∏è  Ïò§ÎûòÎêú Î∞±ÏóÖ ÏÇ≠Ï†ú: {Path(old_backup).name}")
            
            file_size = backup_path.stat().st_size / (1024 * 1024)
            click.echo(f"‚úÖ ÏûêÎèô Î∞±ÏóÖ ÏôÑÎ£å: {backup_filename} ({file_size:.2f} MB)")
            click.echo(f"üìä Î≥¥Ï°¥Îêú Î∞±ÏóÖ Ïàò: {min(len(backup_files), max_backups)}Í∞ú")
            
        else:
            click.echo("[ERROR] ÏûêÎèô Î∞±ÏóÖ Ïã§Ìå®")
            
    except Exception as e:
        click.echo(f"üí• ÏûêÎèô Î∞±ÏóÖ Ïã§Ìñâ Ïã§Ìå®: {e}")


@backup.command()
def status():
    """ÏûêÎèô Î∞±ÏóÖ ÏÉÅÌÉú ÌôïÏù∏"""
    try:
        from pathlib import Path
        from datetime import datetime
        import json
        import glob
        
        backup_dir = Path.home() / "greeum-backups"
        config_file = backup_dir / "auto_backup_config.json"
        
        if not config_file.exists():
            click.echo("‚ö™ ÏûêÎèô Î∞±ÏóÖ: ÎØ∏ÏÑ§Ï†ï")
            click.echo("üí° 'greeum backup auto --schedule daily' Î°ú ÏÑ§Ï†ïÌïòÏÑ∏Ïöî")
            return
        
        with open(config_file, 'r', encoding='utf-8') as f:
            config = json.load(f)
        
        status_emoji = "üü¢" if config.get('enabled', False) else "üî¥"
        status_text = "ÌôúÏÑ±Ìôî" if config.get('enabled', False) else "ÎπÑÌôúÏÑ±Ìôî"
        
        click.echo(f"{status_emoji} ÏûêÎèô Î∞±ÏóÖ: {status_text}")
        
        if config.get('enabled', False):
            click.echo(f"   [DATE] Ï£ºÍ∏∞: {config.get('schedule', 'unknown')}")
            click.echo(f"   üìÅ ÎîîÎ†âÌÜ†Î¶¨: {config.get('output_dir', 'unknown')}")
            click.echo(f"   üî¢ ÏµúÎåÄ Î≥¥Ï°¥: {config.get('max_backups', 10)}Í∞ú")
            
            last_backup = config.get('last_backup')
            if last_backup:
                click.echo(f"   üïí ÎßàÏßÄÎßâ Î∞±ÏóÖ: {last_backup}")
            else:
                click.echo(f"   üïí ÎßàÏßÄÎßâ Î∞±ÏóÖ: ÏóÜÏùå")
        
        # Î∞±ÏóÖ ÌååÏùº Î™©Î°ù
        backup_pattern = str(backup_dir / "auto_backup_*.json")
        backup_files = sorted(glob.glob(backup_pattern), reverse=True)
        
        if backup_files:
            click.echo(f"\nüìã Î∞±ÏóÖ ÌååÏùº ({len(backup_files)}Í∞ú):")
            for backup_file in backup_files[:5]:  # ÏµúÎåÄ 5Í∞úÎßå ÌëúÏãú
                backup_path = Path(backup_file)
                size_mb = backup_path.stat().st_size / (1024 * 1024)
                mtime = datetime.fromtimestamp(backup_path.stat().st_mtime)
                click.echo(f"   ‚Ä¢ {backup_path.name} ({size_mb:.2f} MB, {mtime.strftime('%Y-%m-%d %H:%M')})")
            
            if len(backup_files) > 5:
                click.echo(f"   ... Î∞è {len(backup_files) - 5}Í∞ú Îçî")
        else:
            click.echo("\nüìã Î∞±ÏóÖ ÌååÏùº: ÏóÜÏùå")
            
    except Exception as e:
        click.echo(f"üí• ÏûêÎèô Î∞±ÏóÖ ÏÉÅÌÉú ÌôïÏù∏ Ïã§Ìå®: {e}")


# v2.6.1 Restore ÏÑúÎ∏åÎ™ÖÎ†πÏñ¥Îì§
@restore.command()
@click.argument('backup_file', type=click.Path(exists=True))
@click.option('--from-date', help='ÏãúÏûë ÎÇ†Ïßú (YYYY-MM-DD)')
@click.option('--to-date', help='ÎÅù ÎÇ†Ïßú (YYYY-MM-DD)')  
@click.option('--keywords', help='ÌÇ§ÏõåÎìú ÌïÑÌÑ∞ (ÏâºÌëúÎ°ú Íµ¨Î∂Ñ)')
@click.option('--layers', help='Í≥ÑÏ∏µ ÌïÑÌÑ∞ (working,stm,ltm Ï§ë ÏÑ†ÌÉù)')
@click.option('--importance-min', type=float, help='ÏµúÏÜå Ï§ëÏöîÎèÑ (0.0-1.0)')
@click.option('--importance-max', type=float, help='ÏµúÎåÄ Ï§ëÏöîÎèÑ (0.0-1.0)')
@click.option('--tags', help='ÌÉúÍ∑∏ ÌïÑÌÑ∞ (ÏâºÌëúÎ°ú Íµ¨Î∂Ñ)')
@click.option('--merge/--replace', default=False, help='Î≥ëÌï© Î™®Îìú (Í∏∞Î≥∏: ÍµêÏ≤¥)')
@click.option('--preview/--execute', default=True, help='ÎØ∏Î¶¨Î≥¥Í∏∞Îßå ÌëúÏãú (Í∏∞Î≥∏: ÎØ∏Î¶¨Î≥¥Í∏∞)')
def from_file(
    backup_file: str,
    from_date: str,
    to_date: str, 
    keywords: str,
    layers: str,
    importance_min: float,
    importance_max: float,
    tags: str,
    merge: bool,
    preview: bool
):
    """Î∞±ÏóÖ ÌååÏùºÎ°úÎ∂ÄÌÑ∞ Î©îÎ™®Î¶¨ Î≥µÏõê"""
    try:
        from ..core.backup_restore import MemoryRestoreEngine, RestoreFilter
        # from ..core.hierarchical_memory import HierarchicalMemorySystem  # REMOVED
        from ..core.database_manager import DatabaseManager
        # from ..core.memory_layer import MemoryLayerType  # REMOVED
        from datetime import datetime
        
        # Î≥µÏõê ÌïÑÌÑ∞ ÏÉùÏÑ±
        date_from = None
        if from_date:
            try:
                date_from = datetime.strptime(from_date, '%Y-%m-%d')
            except ValueError:
                click.echo(f"‚ö†Ô∏è ÏûòÎ™ªÎêú ÏãúÏûë ÎÇ†Ïßú ÌòïÏãù: {from_date}")
        
        date_to = None
        if to_date:
            try:
                date_to = datetime.strptime(to_date, '%Y-%m-%d') 
            except ValueError:
                click.echo(f"‚ö†Ô∏è ÏûòÎ™ªÎêú ÎÅù ÎÇ†Ïßú ÌòïÏãù: {to_date}")
        
        keyword_list = None
        if keywords:
            keyword_list = [kw.strip() for kw in keywords.split(',') if kw.strip()]
        
        layer_list = None
        if layers:
            # Simplified layer mapping without MemoryLayerType enum
            layer_names = [layer.strip().lower() for layer in layers.split(',')]
            layer_list = layer_names  # Just pass as strings
        
        tag_list = None
        if tags:
            tag_list = [tag.strip() for tag in tags.split(',') if tag.strip()]
        
        filter_config = RestoreFilter(
            date_from=date_from,
            date_to=date_to,
            keywords=keyword_list,
            layers=layer_list,
            importance_min=importance_min,
            importance_max=importance_max,
            tags=tag_list
        )
        
        # Í≥ÑÏ∏µÏ†Å Î©îÎ™®Î¶¨ ÏãúÏä§ÌÖú Ï¥àÍ∏∞Ìôî - SIMPLIFIED
        db_manager = DatabaseManager()
        # HierarchicalMemorySystem removed - using DatabaseManager directly
        
        restore_engine = MemoryRestoreEngine(system)
        
        if preview:
            # ÎØ∏Î¶¨Î≥¥Í∏∞ ÌëúÏãú
            click.echo("üîç Î≥µÏõê ÎØ∏Î¶¨Î≥¥Í∏∞Î•º ÏÉùÏÑ±Ìï©ÎãàÎã§...")
            preview_text = restore_engine.preview_restore(backup_file, filter_config)
            click.echo(preview_text)
            
            if click.confirm('Î≥µÏõêÏùÑ ÏßÑÌñâÌïòÏãúÍ≤†ÏäµÎãàÍπå?'):
                preview = False  # Ïã§Ï†ú Î≥µÏõêÏúºÎ°ú Ï†ÑÌôò
            else:
                click.echo("Î≥µÏõêÏù¥ Ï∑®ÏÜåÎêòÏóàÏäµÎãàÎã§")
                return
        
        if not preview:
            # Ïã§Ï†ú Î≥µÏõê Ïã§Ìñâ
            click.echo("[PROCESS] Î©îÎ™®Î¶¨ Î≥µÏõêÏùÑ ÏãúÏûëÌï©ÎãàÎã§...")
            
            result = restore_engine.restore_from_backup(
                backup_file=backup_file,
                filter_config=filter_config,
                merge_mode=merge,
                dry_run=False
            )
            
            # Í≤∞Í≥º ÌëúÏãú
            if result.success:
                click.echo("‚úÖ Î≥µÏõê ÏôÑÎ£å!")
                click.echo(f"üìä Î≥µÏõê Í≤∞Í≥º:")
                click.echo(f"   [MEMORY] Working Memory: {result.working_count}Í∞ú")
                click.echo(f"   [FAST] STM: {result.stm_count}Í∞ú") 
                click.echo(f"   üèõÔ∏è  LTM: {result.ltm_count}Í∞ú")
                click.echo(f"   [IMPROVE] Ï¥ù Ï≤òÎ¶¨: {result.total_processed}Í∞ú")
                click.echo(f"   ‚è±Ô∏è  ÏÜåÏöî ÏãúÍ∞Ñ: {result.execution_time:.2f}Ï¥à")
                
                if result.error_count > 0:
                    click.echo(f"   ‚ö†Ô∏è  Ïò§Î•ò: {result.error_count}Í∞ú")
                    for error in result.errors[:5]:  # ÏµúÎåÄ 5Í∞ú Ïò§Î•òÎßå ÌëúÏãú
                        click.echo(f"      - {error}")
            else:
                click.echo("[ERROR] Î≥µÏõêÏóê Ïã§Ìå®ÌñàÏäµÎãàÎã§")
                for error in result.errors:
                    click.echo(f"   üí• {error}")
                    
    except Exception as e:
        click.echo(f"üí• Î≥µÏõê Ï§ë Ïò§Î•ò: {e}")


# v2.6.2 Dashboard ÏÑúÎ∏åÎ™ÖÎ†πÏñ¥Îì§
@dashboard.command()
@click.option('--output', '-o', help='Í≤∞Í≥ºÎ•º ÌååÏùºÎ°ú Ï†ÄÏû•Ìï† Í≤ΩÎ°ú')
@click.option('--json-format', is_flag=True, help='JSON ÌòïÌÉúÎ°ú Ï∂úÎ†•')
def overview(output: str, json_format: bool):
    """Î©îÎ™®Î¶¨ ÏãúÏä§ÌÖú Ï†ÑÏ≤¥ Í∞úÏöî ÌëúÏãú"""
    try:
        from ..core.dashboard import get_dashboard_system
        import json
        
        dashboard_system = get_dashboard_system()
        overview_data = dashboard_system.get_overview()
        
        if json_format or output:
            # JSON ÌòïÌÉúÎ°ú Ï∂úÎ†•
            json_output = json.dumps(overview_data, indent=2, ensure_ascii=False)
            
            if output:
                with open(output, 'w', encoding='utf-8') as f:
                    f.write(json_output)
                click.echo(f"‚úÖ ÎåÄÏãúÎ≥¥Îìú Î¶¨Ìè¨Ìä∏ Ï†ÄÏû•Îê®: {output}")
            else:
                click.echo(json_output)
        else:
            # ÏÇ¨Ïö©Ïûê ÏπúÌôîÏ†Å ÌòïÌÉúÎ°ú Ï∂úÎ†•
            _display_dashboard_overview(overview_data)
            
    except Exception as e:
        click.echo(f"üí• ÎåÄÏãúÎ≥¥Îìú Í∞úÏöî ÏÉùÏÑ± Ïã§Ìå®: {e}")


@dashboard.command()
@click.option('--format', 'output_format', type=click.Choice(['simple', 'detailed', 'json']), 
              default='simple', help='Ï∂úÎ†• ÌòïÌÉú')
def health(output_format: str):
    """ÏãúÏä§ÌÖú Í±¥Í∞ïÎèÑ ÌôïÏù∏"""
    try:
        from ..core.dashboard import get_dashboard_system
        import json
        
        dashboard_system = get_dashboard_system()
        health_data = dashboard_system.get_system_health()
        
        if output_format == 'json':
            click.echo(json.dumps(health_data.__dict__, indent=2, ensure_ascii=False, default=str))
        elif output_format == 'detailed':
            _display_health_detailed(health_data)
        else:
            _display_health_simple(health_data)
            
    except Exception as e:
        click.echo(f"üí• ÏãúÏä§ÌÖú Í±¥Í∞ïÎèÑ ÌôïÏù∏ Ïã§Ìå®: {e}")


@dashboard.command()
@click.option('--output', '-o', required=True, help='Î¶¨Ìè¨Ìä∏ ÌååÏùº Ï†ÄÏû• Í≤ΩÎ°ú')
@click.option('--include-details/--no-details', default=True, 
              help='ÏÉÅÏÑ∏ Í≥ÑÏ∏µ Î∂ÑÏÑù Ìè¨Ìï® Ïó¨Î∂Ä')
def export(output: str, include_details: bool):
    """ÏôÑÏ†ÑÌïú ÎåÄÏãúÎ≥¥Îìú Î¶¨Ìè¨Ìä∏ ÎÇ¥Î≥¥ÎÇ¥Í∏∞"""
    try:
        from ..core.dashboard import get_dashboard_system
        from pathlib import Path
        
        dashboard_system = get_dashboard_system()
        
        success = dashboard_system.export_dashboard_report(
            output_path=output,
            include_details=include_details
        )
        
        if success:
            file_size = Path(output).stat().st_size / 1024  # KB
            click.echo(f"‚úÖ ÎåÄÏãúÎ≥¥Îìú Î¶¨Ìè¨Ìä∏ ÏÉùÏÑ± ÏôÑÎ£å: {output} ({file_size:.1f} KB)")
            
            if include_details:
                click.echo("üìä ÏÉÅÏÑ∏ Í≥ÑÏ∏µ Î∂ÑÏÑù Ìè¨Ìï®")
            else:
                click.echo("üìã Í∏∞Î≥∏ Í∞úÏöîÎßå Ìè¨Ìï®")
        else:
            click.echo("[ERROR] Î¶¨Ìè¨Ìä∏ ÏÉùÏÑ±Ïóê Ïã§Ìå®ÌñàÏäµÎãàÎã§")
            
    except Exception as e:
        click.echo(f"üí• Î¶¨Ìè¨Ìä∏ ÎÇ¥Î≥¥ÎÇ¥Í∏∞ Ïã§Ìå®: {e}")


# ÎåÄÏãúÎ≥¥Îìú Ï∂úÎ†• Ìó¨Ìçº Ìï®ÏàòÎì§
def _display_dashboard_overview(data: dict):
    """ÏÇ¨Ïö©Ïûê ÏπúÌôîÏ†Å ÎåÄÏãúÎ≥¥Îìú Í∞úÏöî Ï∂úÎ†•"""
    stats = data['memory_stats']
    health = data['system_health']
    
    click.echo("[MEMORY] Greeum Memory Dashboard")
    click.echo("=" * 50)
    
    # Í∏∞Î≥∏ ÌÜµÍ≥Ñ
    click.echo(f"üìä Ï†ÑÏ≤¥ Î©îÎ™®Î¶¨: {stats['total_memories']}Í∞ú")
    click.echo(f"   [MEMORY] Working Memory: {stats['working_memory_count']}Í∞ú")
    click.echo(f"   [FAST] STM: {stats['stm_count']}Í∞ú")
    click.echo(f"   üèõÔ∏è  LTM: {stats['ltm_count']}Í∞ú")
    
    click.echo()
    
    # ÏãúÏä§ÌÖú Í±¥Í∞ïÎèÑ
    health_percent = health['overall_health'] * 100
    health_emoji = "üü¢" if health_percent >= 80 else "üü°" if health_percent >= 60 else "üî¥"
    click.echo(f"{health_emoji} ÏãúÏä§ÌÖú Í±¥Í∞ïÎèÑ: {health_percent:.1f}%")
    
    # Ïö©Îüâ Ï†ïÎ≥¥
    click.echo(f"üíæ Ï¥ù Ïö©Îüâ: {stats['total_size_mb']:.1f} MB")
    click.echo(f"[FAST] ÌèâÍ∑† Í≤ÄÏÉâ ÏãúÍ∞Ñ: {health['avg_search_time_ms']:.1f}ms")
    
    # Í≤ΩÍ≥†ÏÇ¨Ìï≠
    if health['warnings']:
        click.echo("\n‚ö†Ô∏è  Ï£ºÏùòÏÇ¨Ìï≠:")
        for warning in health['warnings']:
            click.echo(f"   ‚Ä¢ {warning}")
    
    # Í∂åÏû•ÏÇ¨Ìï≠
    if health['recommendations']:
        click.echo("\nüí° Í∂åÏû•ÏÇ¨Ìï≠:")
        for rec in health['recommendations']:
            click.echo(f"   ‚Ä¢ {rec}")
    
    # Ïù∏Í∏∞ ÌÇ§ÏõåÎìú
    if 'popular_keywords' in stats:
        click.echo("\nüî• Ïù∏Í∏∞ ÌÇ§ÏõåÎìú:")
        for keyword, count in stats['popular_keywords'][:5]:
            click.echo(f"   #{keyword} ({count}Ìöå)")


def _display_health_simple(health):
    """Í∞ÑÎã®Ìïú Í±¥Í∞ïÎèÑ Ï∂úÎ†•"""
    health_percent = health.overall_health * 100
    health_emoji = "üü¢" if health_percent >= 80 else "üü°" if health_percent >= 60 else "üî¥"
    
    click.echo(f"{health_emoji} ÏãúÏä§ÌÖú Í±¥Í∞ïÎèÑ: {health_percent:.1f}%")
    
    if health_percent >= 80:
        click.echo("‚úÖ ÏãúÏä§ÌÖúÏù¥ Ï†ïÏÉÅÏ†ÅÏúºÎ°ú ÏûëÎèôÌïòÍ≥† ÏûàÏäµÎãàÎã§")
    elif health_percent >= 60:
        click.echo("‚ö†Ô∏è  ÏãúÏä§ÌÖúÏóê ÏïΩÍ∞ÑÏùò Ï£ºÏùòÍ∞Ä ÌïÑÏöîÌï©ÎãàÎã§")
    else:
        click.echo("üî¥ ÏãúÏä§ÌÖú Ï†êÍ≤ÄÏù¥ ÌïÑÏöîÌï©ÎãàÎã§")


def _display_health_detailed(health):
    """ÏÉÅÏÑ∏Ìïú Í±¥Í∞ïÎèÑ Ï∂úÎ†•"""
    _display_health_simple(health)
    
    click.echo(f"\n[IMPROVE] ÏÑ±Îä• ÏßÄÌëú:")
    click.echo(f"   Í≤ÄÏÉâ ÏÜçÎèÑ: {health.avg_search_time_ms:.1f}ms")
    click.echo(f"   Î©îÎ™®Î¶¨ ÏÇ¨Ïö©Îüâ: {health.memory_usage_mb:.1f}MB")
    click.echo(f"   Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ ÌÅ¨Í∏∞: {health.database_size_mb:.1f}MB")
    
    click.echo(f"\nüéØ ÌíàÏßà ÏßÄÌëú:")
    click.echo(f"   ÌèâÍ∑† ÌíàÏßà Ï†êÏàò: {health.avg_quality_score:.2f}")
    click.echo(f"   Ï§ëÎ≥µÎ•†: {health.duplicate_rate * 100:.1f}%")
    click.echo(f"   ÏäπÍ∏â ÏÑ±Í≥µÎ•†: {health.promotion_success_rate * 100:.1f}%")
    
    if health.warnings:
        click.echo(f"\n‚ö†Ô∏è  Í≤ΩÍ≥†:")
        for warning in health.warnings:
            click.echo(f"   ‚Ä¢ {warning}")
    
    if health.recommendations:
        click.echo(f"\nüí° Í∂åÏû•ÏÇ¨Ìï≠:")
        for rec in health.recommendations:
            click.echo(f"   ‚Ä¢ {rec}")


# v2.7.0: Causal Reasoning Commands
@main.group()
def causal():
    """Causal reasoning and relationship analysis commands"""
    pass


@causal.command()
@click.argument('block_id', type=int)
@click.option('--format', 'output_format', type=click.Choice(['simple', 'detailed', 'json']), 
              default='simple', help='Output format')
def relationships(block_id: int, output_format: str):
    """Show causal relationships for a specific memory block"""
    try:
        from greeum.core import DatabaseManager
        from greeum.core.block_manager import BlockManager
        
        db_manager = DatabaseManager()
        block_manager = BlockManager(db_manager)
        
        # Get the block info
        block = db_manager.get_block(block_id)
        if not block:
            click.echo(f"‚ùå Block #{block_id} not found", err=True)
            return
        
        # Get causal relationships
        relationships = block_manager.get_causal_relationships(block_id)
        
        if output_format == 'json':
            import json
            click.echo(json.dumps({
                'block_id': block_id,
                'relationships': relationships
            }, indent=2, ensure_ascii=False))
            return
        
        if not relationships:
            click.echo(f"üîç No causal relationships found for block #{block_id}")
            return
        
        click.echo(f"üîó Causal relationships for block #{block_id}:")
        click.echo(f"   Context: {block['context'][:60]}...")
        click.echo()
        
        for i, rel in enumerate(relationships, 1):
            source_id = rel['source_block_id']
            target_id = rel['target_block_id']
            relation_type = rel['relation_type']
            confidence = rel['confidence']
            
            # Determine direction
            if source_id == block_id:
                direction = "‚Üí"
                other_id = target_id
                role = "Causes"
            else:
                direction = "‚Üê"
                other_id = source_id
                role = "Caused by"
            
            # Get other block context
            other_block = db_manager.get_block(other_id)
            other_context = other_block['context'][:50] + "..." if other_block else "Unknown"
            
            confidence_emoji = "üî•" if confidence >= 0.8 else "‚ö°" if confidence >= 0.6 else "üí°"
            
            click.echo(f"{i}. {confidence_emoji} {role} Block #{other_id} ({confidence:.2f})")
            click.echo(f"   {direction} {other_context}")
            click.echo(f"   Type: {relation_type}")
            
            if output_format == 'detailed':
                import json
                keywords = json.loads(rel.get('keywords_matched', '[]'))
                if keywords:
                    click.echo(f"   Keywords: {', '.join(keywords)}")
                
                temporal_gap = rel.get('temporal_gap_hours')
                if temporal_gap is not None:
                    if temporal_gap < 1:
                        gap_str = f"{temporal_gap * 60:.0f} minutes"
                    elif temporal_gap < 24:
                        gap_str = f"{temporal_gap:.1f} hours"
                    else:
                        gap_str = f"{temporal_gap / 24:.1f} days"
                    click.echo(f"   Time gap: {gap_str}")
            
            click.echo()
        
    except Exception as e:
        click.echo(f"‚ùå Error analyzing relationships: {e}", err=True)


@causal.command()
@click.argument('start_block_id', type=int)
@click.option('--depth', default=3, help='Maximum chain depth to explore')
@click.option('--format', 'output_format', type=click.Choice(['simple', 'detailed', 'json']), 
              default='simple', help='Output format')
def chain(start_block_id: int, depth: int, output_format: str):
    """Find causal relationship chains starting from a block"""
    try:
        from greeum.core import DatabaseManager
        from greeum.core.block_manager import BlockManager
        
        db_manager = DatabaseManager()
        block_manager = BlockManager(db_manager)
        
        # Get the starting block
        start_block = db_manager.get_block(start_block_id)
        if not start_block:
            click.echo(f"‚ùå Start block #{start_block_id} not found", err=True)
            return
        
        # Find causal chain
        chain_results = block_manager.find_causal_chain(start_block_id, depth)
        
        if output_format == 'json':
            import json
            click.echo(json.dumps({
                'start_block_id': start_block_id,
                'chain': chain_results
            }, indent=2, ensure_ascii=False))
            return
        
        if not chain_results:
            click.echo(f"üîç No causal chains found starting from block #{start_block_id}")
            return
        
        click.echo(f"üîó Causal chain starting from block #{start_block_id}:")
        click.echo(f"   Start: {start_block['context'][:60]}...")
        click.echo()
        
        # Group by depth for better visualization
        by_depth = {}
        for item in chain_results:
            d = item['depth']
            if d not in by_depth:
                by_depth[d] = []
            by_depth[d].append(item)
        
        for depth_level in sorted(by_depth.keys()):
            items = by_depth[depth_level]
            indent = "  " * (depth_level + 1)
            
            for item in items:
                confidence = item['confidence']
                target_block = item['target_block']
                target_context = target_block['context'][:50] + "..."
                
                confidence_emoji = "üî•" if confidence >= 0.8 else "‚ö°" if confidence >= 0.6 else "üí°"
                
                click.echo(f"{indent}‚Üì {confidence_emoji} Block #{item['target_id']} ({confidence:.2f})")
                click.echo(f"{indent}   {target_context}")
                
                if output_format == 'detailed':
                    click.echo(f"{indent}   Type: {item['relation_type']}")
        
    except Exception as e:
        click.echo(f"‚ùå Error finding causal chain: {e}", err=True)


@causal.command()
@click.option('--format', 'output_format', type=click.Choice(['simple', 'detailed', 'json']), 
              default='simple', help='Output format')
def stats(output_format: str):
    """Show causal reasoning detection statistics"""
    try:
        from greeum.core import DatabaseManager
        from greeum.core.block_manager import BlockManager
        
        db_manager = DatabaseManager()
        block_manager = BlockManager(db_manager)
        
        # Get statistics
        statistics = block_manager.get_causal_statistics()
        
        if 'error' in statistics:
            click.echo(f"‚ùå {statistics['error']}", err=True)
            return
        
        if output_format == 'json':
            import json
            click.echo(json.dumps(statistics, indent=2, ensure_ascii=False))
            return
        
        click.echo("üìä Causal Reasoning Statistics")
        click.echo("=" * 35)
        
        # Detection summary
        total_analyzed = statistics.get('total_analyzed', 0)
        relationships_found = statistics.get('relationships_found', 0)
        accuracy_estimate = statistics.get('accuracy_estimate', 0.0)
        
        click.echo(f"\nüîç Detection Summary:")
        click.echo(f"   Total blocks analyzed: {total_analyzed}")
        click.echo(f"   Relationships found: {relationships_found}")
        if total_analyzed > 0:
            detection_rate = (relationships_found / total_analyzed) * 100
            click.echo(f"   Detection rate: {detection_rate:.1f}%")
        click.echo(f"   Estimated accuracy: {accuracy_estimate:.1f}%")
        
        # Confidence distribution
        high_conf = statistics.get('high_confidence', 0)
        medium_conf = statistics.get('medium_confidence', 0)
        low_conf = statistics.get('low_confidence', 0)
        
        click.echo(f"\nüìà Confidence Distribution:")
        click.echo(f"   üî• High (‚â•0.8): {high_conf}")
        click.echo(f"   ‚ö° Medium (0.5-0.8): {medium_conf}")
        click.echo(f"   üí° Low (<0.5): {low_conf}")
        
        # Relationship types
        by_type = statistics.get('by_type', {})
        if by_type:
            click.echo(f"\nüè∑Ô∏è  Relationship Types:")
            for rel_type, count in by_type.items():
                if count > 0:
                    click.echo(f"   {rel_type}: {count}")
        
        # Database statistics
        total_stored = statistics.get('total_stored', 0)
        stored_dist = statistics.get('stored_confidence_distribution', {})
        
        if output_format == 'detailed':
            click.echo(f"\nüíæ Storage Statistics:")
            click.echo(f"   Total stored relationships: {total_stored}")
            
            if stored_dist:
                click.echo(f"   Stored confidence distribution:")
                for level, count in stored_dist.items():
                    click.echo(f"     {level}: {count}")
        
    except Exception as e:
        click.echo(f"‚ùå Error getting causal statistics: {e}", err=True)


# Import and register graph commands
try:
    from .graph import graph_group
    main.commands.pop('graph', None)
    main.add_command(graph_group, name='graph')
except ImportError:
    pass  # Graph CLI not available

# Import and register metrics commands
try:
    from .metrics_cli import metrics_group
    # Replace the empty metrics group with the real one
    main.commands.pop('metrics', None)
    main.add_command(metrics_group, name='metrics')
except ImportError:
    pass  # Metrics CLI not available

# Import and register validate commands  
try:
    from .validate_cli import validate_group
    # Replace the empty validate group with the real one
    main.commands.pop('validate', None)
    main.add_command(validate_group, name='validate')
except ImportError:
    pass  # Validate CLI not available


if __name__ == '__main__':
    main()
