"""
Greeum v2.0 ÌÜµÌï© CLI ÏãúÏä§ÌÖú

ÏÇ¨Ïö©Î≤ï:
  greeum memory add "ÏÉàÎ°úÏö¥ Í∏∞Ïñµ"
  greeum memory search "Í≤ÄÏÉâÏñ¥"
  greeum mcp serve --transport stdio
  greeum api serve --port 5000
"""

try:
    import click
except ImportError:
    print("[ERROR] Click not installed. Install with: pip install greeum")
    import sys
    sys.exit(1)

import os
import sys
import sqlite3
import subprocess
from pathlib import Path
from typing import Optional, Dict, Any
from datetime import datetime

from ..config_store import (
    DEFAULT_DATA_DIR,
    DEFAULT_ST_MODEL,
    GreeumConfig,
    ensure_data_dir,
    load_config,
    mark_semantic_ready,
    save_config,
)
from ..core.database_manager import DatabaseManager
from ..core.stm_anchor_store import get_anchor_store
from ..core.branch_schema import BranchSchemaSQL
from ..embedding_models import (
    init_sentence_transformer,
    force_simple_fallback,
)
from ..worker.client import WriteServiceClient, resolve_endpoint, WorkerUnavailableError
from ..worker import ensure_http_worker, get_worker_state


def _download_sentence_transformer(model: str) -> Path:
    try:
        from sentence_transformers import SentenceTransformer
    except ImportError as exc:
        raise ImportError(
            "sentence-transformers not installed. Install with 'pip install greeum[full]' "
            "or 'pip install sentence-transformers'."
        ) from exc

    cache_dir = Path.home() / ".cache" / "sentence_transformers"
    if os.getenv("GREEUM_DISABLE_ST"):
        raise RuntimeError("Semantic warmup skipped because GREEUM_DISABLE_ST is set.")
    SentenceTransformer(
        model,
        cache_folder=str(cache_dir),
        device=os.getenv("GREEUM_ST_DEVICE", None),
    )
    return cache_dir

@click.group()
@click.version_option()
@click.option('--verbose', '-v', is_flag=True, help='Enable verbose logging')
@click.option('--debug', is_flag=True, help='Enable debug logging (most verbose)')
@click.option('--quiet', '-q', is_flag=True, help='Suppress all non-essential output')
@click.pass_context
def main(ctx: click.Context, verbose: bool, debug: bool, quiet: bool):
    """Greeum Universal Memory System"""
    
    # ContextÏóê Î°úÍ∑∏ ÏÑ§Ï†ï Ï†ÄÏû•
    ctx.ensure_object(dict)
    ctx.obj['verbose'] = verbose
    ctx.obj['debug'] = debug
    ctx.obj['quiet'] = quiet
    
    # Console output ÏÑ§Ï†ïÏùÑ ÏúÑÌïú ÌôòÍ≤ΩÎ≥ÄÏàò ÏÑ§Ï†ï
    if verbose or debug:
        os.environ['GREEUM_CLI_VERBOSE'] = '1'
    else:
        os.environ.pop('GREEUM_CLI_VERBOSE', None)
    
    # Î°úÍ∑∏ Î†àÎ≤® ÏÑ§Ï†ï
    import logging
    
    if debug:
        log_level = logging.DEBUG
    elif verbose:
        log_level = logging.INFO
    elif quiet:
        log_level = logging.ERROR
    else:
        log_level = logging.WARNING  # Í∏∞Î≥∏Í∞í: Í≤ΩÍ≥† Ïù¥ÏÉÅÎßå ÌëúÏãú
    
    # Î°úÍ∑∏ Ìè¨Îß∑ ÏÑ§Ï†ï
    if debug:
        log_format = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    elif verbose:
        log_format = '%(levelname)s: %(message)s'
    else:
        log_format = '%(message)s'
    
    logging.basicConfig(
        level=log_level,
        format=log_format,
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    
    # ÌäπÏ†ï Î°úÍ±∞Îì§Ïùò Î†àÎ≤® Ï°∞Ï†ï (ÎÑàÎ¨¥ ÏãúÎÅÑÎü¨Ïö¥ Ïô∏Î∂Ä ÎùºÏù¥Î∏åÎü¨Î¶¨Îì§)
    if not debug:
        logging.getLogger('urllib3').setLevel(logging.WARNING)
        logging.getLogger('requests').setLevel(logging.WARNING)
        logging.getLogger('sqlalchemy').setLevel(logging.WARNING)

    # Ensure data directory from config is available if user hasn't set env vars
    config = load_config()
    data_dir = config.data_dir or str(DEFAULT_DATA_DIR)
    ensure_data_dir(data_dir)
    os.environ.setdefault('GREEUM_DATA_DIR', data_dir)


@main.command()
@click.option('--data-dir', type=click.Path(file_okay=False, dir_okay=True, writable=True), help='Custom data directory')
@click.option('--skip-warmup', is_flag=True, help='Skip SentenceTransformer warm-up step')
@click.option('--start-worker/--skip-worker', default=True, show_default=True, help='Launch background worker after setup completes')
def setup(data_dir: Optional[str], skip_warmup: bool, start_worker: bool):
    """Interactive first-time setup (data dir + optional warm-up)."""

    click.echo("üõ†Ô∏è  Greeum setup wizard")
    config = load_config()

    default_dir = data_dir or config.data_dir or str(DEFAULT_DATA_DIR)
    if data_dir:
        chosen_dir = str(Path(data_dir).expanduser())
        click.echo(f"Using data directory: {chosen_dir}")
    else:
        chosen_dir = click.prompt(
            "Data directory (used for memories, cache, logs)",
            default=str(Path(default_dir).expanduser()),
        )

    target_dir = ensure_data_dir(chosen_dir)
    os.environ['GREEUM_DATA_DIR'] = str(target_dir)

    semantic_ready = config.semantic_ready
    warmup_performed = False

    if skip_warmup:
        click.echo("Skipping embedding warm-up (hash fallback will be used by default).")
    else:
        default_confirm = not config.semantic_ready
        if click.confirm("Run SentenceTransformer warm-up now?", default=default_confirm):
            click.echo(f"üì¶ Downloading {DEFAULT_ST_MODEL} ‚Ä¶")
            try:
                cache_dir = _download_sentence_transformer(DEFAULT_ST_MODEL)
            except ImportError as exc:
                click.echo(f"[ERROR] {exc}", err=True)
                semantic_ready = False
            except Exception as exc:  # noqa: BLE001
                click.echo(f"[ERROR] Warm-up failed: {exc}", err=True)
                semantic_ready = False
            else:
                click.echo(f"‚úÖ Warm-up complete. Model cached at {cache_dir}.")
                semantic_ready = True
                warmup_performed = True
        else:
            click.echo("Warm-up skipped. You can run 'greeum mcp warmup' later.")

    config.data_dir = str(target_dir)
    config.semantic_ready = semantic_ready
    save_config(config)

    if warmup_performed:
        mark_semantic_ready(True)
    elif not semantic_ready:
        mark_semantic_ready(False)

    worker_endpoint = None
    worker_log = None
    if start_worker:
        click.echo("\nüöÄ Launching background worker‚Ä¶")
        try:
            endpoint = ensure_http_worker(
                data_dir=Path(target_dir),
                semantic=semantic_ready,
                allow_spawn=True,
            )
            worker_endpoint = endpoint
            os.environ['GREEUM_MCP_HTTP'] = endpoint
            state = get_worker_state(Path(target_dir)) or {}
            worker_log = state.get('log')
        except Exception as exc:  # noqa: BLE001 - show warning only
            click.echo(f"[WARN] Failed to launch worker automatically: {exc}")
        else:
            click.echo(f"   ‚Ä¢ Worker endpoint: {worker_endpoint}")
            if worker_log:
                click.echo(f"   ‚Ä¢ Worker log: {worker_log}")
            else:
                click.echo("   ‚Ä¢ Worker log: <not recorded>")

    click.echo("\nSetup summary:")
    click.echo(f"   ‚Ä¢ Data directory: {target_dir}")
    click.echo(
        "   ‚Ä¢ Semantic embeddings: "
        + ("ready" if semantic_ready else "hash fallback (run warmup to enable)")
    )
    if start_worker and worker_endpoint:
        click.echo("   ‚Ä¢ Worker: running (auto-start)")
    elif start_worker:
        click.echo("   ‚Ä¢ Worker: failed to start (use 'greeum worker serve' later)")
    else:
        click.echo("   ‚Ä¢ Worker: skipped (use 'greeum worker serve' when needed)")
    click.echo("   ‚Ä¢ Next step: run 'greeum memory add ""Your first note""' to test the connection")
@main.group()
def memory():
    """Memory management commands (STM/LTM)"""
    pass

@main.group() 
def mcp():
    """MCP server commands"""
    pass

@main.group()
def worker():
    """Worker daemon utilities"""
    pass

@main.group()
def ltm():
    """Long-term memory (LTM) specialized commands"""
    pass

@main.group()
def stm():
    """Short-term memory (STM) specialized commands"""
    pass

@main.group()
def api():
    """API server commands"""
    pass

@main.group()
def slots():
    """AI Context Slots management (v2.5.1 enhanced)"""
    pass

@main.group()
def migrate():
    """Database migration commands (v2.5.3 AI-Powered Migration)"""
    pass

@main.group()
def backup():
    """Memory backup and restore commands (v2.6.1)"""
    pass

@main.group() 
def restore():
    """Memory restore commands (v2.6.1)"""
    pass

@main.group()
def dashboard():
    """Memory dashboard and analytics (v2.6.2)"""
    pass

@main.group()
def graph():
    """Graph network management (v3.0.0)"""
    pass

@main.group()
def metrics():
    """Metrics and performance monitoring"""
    pass

@main.group()
def validate():
    """Documentation and code validation"""
    pass

@main.command()
@click.option('--check', is_flag=True, help='ÏßÑÎã®Îßå ÏàòÌñâ')
@click.option('--fix', is_flag=True, help='ÏûêÎèô Î≥µÍµ¨ Ìè¨Ìï®')
@click.option('--force', is_flag=True, help='Í∞ïÏ†ú Î≥µÍµ¨')
@click.option('--no-backup', is_flag=True, help='Î∞±ÏóÖ ÏÉùÎûµ')
@click.option('--db-path', help='Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ Í≤ΩÎ°ú')
def doctor(check: bool, fix: bool, force: bool, no_backup: bool, db_path: str):
    """System diagnostics and repair tool (Ï≤¥ÌÅ¨, ÎßàÏù¥Í∑∏Î†àÏù¥ÏÖò, Ï†ïÎ¶¨, ÏµúÏ†ÅÌôî)"""
    try:
        from .doctor import GreeumDoctor

        doctor_instance = GreeumDoctor(db_path)

        # Î∞±ÏóÖ
        if (fix or force) and not no_backup:
            backup_path = doctor_instance.backup_database()
            click.echo(f"üì¶ Î∞±ÏóÖ ÏÉùÏÑ±: {backup_path}")

        # ÏßÑÎã®
        health = doctor_instance.check_health()
        doctor_instance.print_report(health)

        # Î≥µÍµ¨
        if fix or force or (not check and doctor_instance.issues):
            if not check and not fix and not force:
                response = click.confirm("\nÎ≥µÍµ¨Î•º ÏßÑÌñâÌïòÏãúÍ≤†ÏäµÎãàÍπå?", default=False)
                if not response:
                    click.echo("Î≥µÍµ¨Í∞Ä Ï∑®ÏÜåÎêòÏóàÏäµÎãàÎã§.")
                    return

            fixes = doctor_instance.fix_issues(force)
            if fixes:
                click.echo(f"\n‚úÖ Î≥µÍµ¨ ÏôÑÎ£å: {len(fixes)}Í∞ú Î¨∏Ï†ú Ìï¥Í≤∞")
                for fix_msg in fixes:
                    click.echo(f"  ‚Ä¢ {fix_msg}")

            # Ïû¨ÏßÑÎã®
            click.echo("\nüîÑ Î≥µÍµ¨ ÌõÑ Ïû¨ÏßÑÎã®...")
            health = doctor_instance.check_health()
            click.echo(f"\nÏµúÏ¢Ö ÏÉÅÌÉú: Ï†êÏàò {health['total_score']:.0f}/100")

        sys.exit(0 if health['total_score'] >= 70 else 1)

    except Exception as e:
        click.echo(f"‚ùå Ïò§Î•ò Î∞úÏÉù: {e}")
        sys.exit(1)


# Memory ÏÑúÎ∏åÎ™ÖÎ†πÏñ¥Îì§
def _maybe_call_http_tool(tool: str, arguments: Dict[str, Any]) -> Optional[Dict[str, Any]]:
    endpoint = os.getenv('GREEUM_MCP_HTTP')
    if not endpoint:
        return None

    import json
    import urllib.request
    import urllib.error
    import uuid

    payload = {
        "jsonrpc": "2.0",
        "id": str(uuid.uuid4()),
        "method": "tools/call",
        "params": {
            "name": tool,
            "arguments": arguments,
        },
    }

    timeout = float(os.getenv('GREEUM_HTTP_TIMEOUT', '30'))
    req = urllib.request.Request(
        endpoint,
        data=json.dumps(payload).encode('utf-8'),
        headers={'Content-Type': 'application/json'},
    )

    try:
        with urllib.request.urlopen(req, timeout=timeout) as resp:
            if resp.status == 204:
                return {}
            body = resp.read().decode('utf-8')
    except urllib.error.HTTPError as exc:
        detail = exc.read().decode('utf-8')
        raise RuntimeError(f"HTTP call failed: {exc.code} {detail}") from exc
    except urllib.error.URLError as exc:
        raise RuntimeError(f"HTTP call failed: {exc}") from exc

    try:
        message = json.loads(body)
    except json.JSONDecodeError as exc:
        raise RuntimeError(f"Invalid MCP HTTP response: {body}") from exc

    if 'error' in message:
        raise RuntimeError(f"MCP error: {message['error']}")

    return message.get('result')


def _decide_worker(use_worker_flag: bool, no_worker_flag: bool) -> Optional[bool]:
    if no_worker_flag:
        return False
    if use_worker_flag:
        return True
    env = os.getenv("GREEUM_USE_WORKER")
    if env:
        return env.lower() not in {"0", "false", "no", "off"}
    return None


def _try_worker_call(tool: str, arguments: Dict[str, Any], use_worker_flag: bool, no_worker_flag: bool, quiet: bool = False, config: Optional[GreeumConfig] = None) -> Optional[Dict[str, Any]]:
    decision = _decide_worker(use_worker_flag, no_worker_flag)
    endpoint = resolve_endpoint()

    if decision is False:
        return None

    if not endpoint:
        base_dir = os.environ.get("GREEUM_DATA_DIR")
        data_root = base_dir or (config.data_dir if config else str(DEFAULT_DATA_DIR))
        data_dir = Path(data_root).expanduser()
        semantic_ready = bool(config.semantic_ready) if config else False
        try:
            endpoint = ensure_http_worker(
                data_dir=data_dir,
                semantic=semantic_ready,
                allow_spawn=True,
            )
            if endpoint:
                os.environ["GREEUM_MCP_HTTP"] = endpoint
        except Exception as exc:  # noqa: BLE001 - surface fallback warning
            if not quiet:
                click.echo(f"[WARN] Auto worker unavailable ({exc}); using local execution.")
            endpoint = None

    try:
        if not endpoint:
            return None
        client = WriteServiceClient(endpoint)
        payload = client.call(tool, arguments)
        if isinstance(payload, dict):
            text_blocks = [
                block.get("text", "")
                for block in payload.get("content", [])
                if isinstance(block, dict) and block.get("type") == "text"
            ]
            if text_blocks:
                payload["text"] = "\n".join(block.strip() for block in text_blocks if block)
        return payload
    except WorkerUnavailableError as exc:
        if not quiet:
            click.echo(f"[WARN] Worker unavailable ({exc}); falling back to local execution.")
        return None


@memory.command()
@click.argument('content')
@click.option('--importance', '-i', default=0.5, help='Importance score (0.0-1.0)')
@click.option('--tags', '-t', help='Comma-separated tags')
@click.option('--slot', '-s', type=click.Choice(['A', 'B', 'C']), help='Insert near specified anchor slot')
@click.option('--use-worker', is_flag=True, help='Force using the worker endpoint when available')
@click.option('--no-worker', is_flag=True, help='Force local execution without contacting the worker')
def add(content: str, importance: float, tags: Optional[str], slot: Optional[str], use_worker: bool, no_worker: bool):
    """Add new memory to long-term storage"""
    try:
        config = load_config()
        worker_args = {
            "content": content,
            "importance": importance,
        }
        if tags:
            worker_args["metadata"] = {"tags": tags.split(',')}
        if slot:
            worker_args["slot"] = slot
        worker_response = _try_worker_call("add_memory", worker_args, use_worker, no_worker, config=config)
        if worker_response is not None:
            text = worker_response.get("text")
            if text:
                click.echo(text)
                return
            data = worker_response.get("data") or {}
            block_id = data.get("block_index", data.get("id", "unknown"))
            click.echo(f"‚úÖ Memory added via worker (Block #{block_id})")
            return

        if slot:
            # Use anchor-based write
            from ..api.write import write as anchor_write
            
            result = anchor_write(
                text=content,
                slot=slot,
                policy={'importance': importance, 'tags': tags}
            )
            
            click.echo(f"‚úÖ Memory added near anchor {slot} (Block #{result})")
            
        else:
            # Use traditional write
            from ..core import BlockManager, DatabaseManager
            from ..text_utils import process_user_input

            db_manager = DatabaseManager()
            block_manager = BlockManager(db_manager)
            
            # ÌÖçÏä§Ìä∏ Ï≤òÎ¶¨
            processed = process_user_input(content)
            keywords = processed.get('keywords', [])
            tag_list = tags.split(',') if tags else processed.get('tags', [])
            embedding = processed.get('embedding', [0.0] * 384)
            
            # Î∏îÎ°ù Ï∂îÍ∞Ä
            block = block_manager.add_block(
                context=content,
                keywords=keywords,
                tags=tag_list,
                embedding=embedding,
                importance=importance
            )
            
            if block:
                # block is now just the block_index (int) instead of a dict
                click.echo(f"‚úÖ Memory added (Block #{block})")
            else:
                click.echo("[ERROR] Failed to add memory")
            
    except Exception as e:
        click.echo(f"[ERROR] Error: {e}")
        sys.exit(1)

@memory.command()
@click.argument('query')
@click.option('--count', '-c', default=5, help='Number of results')
@click.option('--threshold', '-th', default=0.1, help='Similarity threshold')
@click.option('--slot', '-s', type=click.Choice(['A', 'B', 'C']), help='Use anchor-based localized search')
@click.option('--radius', '-r', type=int, help='Graph search radius (1-3)')
@click.option('--no-fallback', is_flag=True, help='Disable fallback to global search')
@click.option('--use-worker', is_flag=True, help='Force using the worker endpoint when available')
@click.option('--no-worker', is_flag=True, help='Force local execution without contacting the worker')
def search(query: str, count: int, threshold: float, slot: str, radius: int, no_fallback: bool, use_worker: bool, no_worker: bool):
    """Search memories by keywords/semantic similarity"""
    try:
        config = load_config()
        worker_args = {
            "query": query,
            "limit": count,
            "threshold": threshold,
            "fallback": not no_fallback,
        }
        if slot:
            worker_args["slot"] = slot
        worker_response = _try_worker_call("search_memory", worker_args, use_worker, no_worker, quiet=True, config=config)
        if worker_response is not None:
            text = worker_response.get("text")
            if text:
                click.echo(text)
                return
            items = worker_response.get('data', {}).get('items', [])
            if items:
                for idx, item in enumerate(items, 1):
                    snippet = (item.get('context') or '')[:80]
                    score = item.get('relevance_score', item.get('score'))
                    click.echo(f"{idx}. {snippet} (score={score})")
            else:
                click.echo("No results found (worker)")
            return

        from ..core.block_manager import BlockManager
        from ..core.database_manager import DatabaseManager

        # Use BlockManager for DFS-based search instead of SearchEngine
        db_manager = DatabaseManager()
        block_manager = BlockManager(db_manager)

        # Perform search with v3 DFS system
        result = block_manager.search_with_slots(
            query=query,
            limit=count,
            use_slots=True,
            entry="cursor",
            depth=3 if slot else 0,
            fallback=not no_fallback
        )

        # Extract blocks from result
        if isinstance(result, dict):
            blocks = result.get('items', [])
            metadata = result.get('meta', {})
        else:
            blocks = result
        metadata = result.get('metadata', {})
        timing = result.get('timing', {})
        
        if blocks:
            # Display search info
            if slot:
                search_type = f"üéØ Anchor-based search (slot {slot})"
                if metadata.get('fallback_used'):
                    search_type += " ‚Üí [PROCESS] Global fallback"
                click.echo(search_type)
                click.echo(f"   Hit rate: {metadata.get('local_hit_rate', 0):.1%}")
                click.echo(f"   Avg hops: {metadata.get('avg_hops', 0)}")
            else:
                click.echo("üîç Global semantic search")
            
            # Display timing
            total_ms = sum(timing.values())
            click.echo(f"   Search time: {total_ms:.1f}ms")
            
            click.echo(f"\nüìã Found {len(blocks)} memories:")
            for i, block in enumerate(blocks, 1):
                timestamp = block.get('timestamp', 'Unknown')
                content = block.get('context', 'No content')[:80]
                relevance = block.get('relevance_score', 0)
                final_score = block.get('final_score', relevance)
                
                click.echo(f"{i}. [{timestamp}] {content}...")
                click.echo(f"   Score: {final_score:.3f}")
        else:
            if slot and not no_fallback:
                click.echo(f"[ERROR] No memories found in anchor slot {slot}, and fallback disabled")
            else:
                click.echo("[ERROR] No memories found")

    except Exception as e:
        click.echo(f"[ERROR] Search failed: {e}")
        sys.exit(1)


@memory.command('reindex')
@click.option(
    '--data-dir',
    type=click.Path(file_okay=False, dir_okay=True, writable=True),
    help='Target data directory (defaults to configured data store)',
)
@click.option('--disable-faiss', is_flag=True, help='Skip FAISS vector index rebuild')
def memory_reindex(data_dir: Optional[str], disable_faiss: bool) -> None:
    """Rebuild branch-aware indices for the selected database."""
    from ..core.branch_index import BranchIndexManager

    if disable_faiss:
        os.environ['GREEUM_DISABLE_FAISS'] = 'true'

    if data_dir:
        target_dir = Path(data_dir).expanduser()
        db_path = target_dir if target_dir.suffix == '.db' else target_dir / 'memory.db'
        manager = DatabaseManager(connection_string=str(db_path))
    else:
        manager = DatabaseManager()

    click.echo('üîÑ Rebuilding branch indices...')
    try:
        branch_manager = BranchIndexManager(manager)
        stats = branch_manager.get_stats()
        click.echo(
            "‚úÖ Rebuilt {count} branches ({mode}, vectorized={vectorized}).".format(
                count=stats['branch_count'],
                mode=stats['mode'],
                vectorized=stats['vectorized_branches'],
            )
        )
    except Exception as exc:  # noqa: BLE001 - surface to CLI
        click.echo(f"[ERROR] Branch reindex failed: {exc}")
        sys.exit(1)
    finally:
        try:
            manager.conn.close()
        except Exception:
            pass
        except Exception:
            pass

# MCP ÏÑúÎ∏åÎ™ÖÎ†πÏñ¥Îì§
@mcp.command()
@click.option('--transport', '-t', default='stdio', help='Transport type (stdio/http/ws)')
@click.option('--port', '-p', default=3000, help='Port for HTTP or WebSocket transports')
@click.option('--host', default='127.0.0.1', show_default=True, help='Host for HTTP transport')
@click.option('--verbose', '-v', is_flag=True, help='Enable verbose logging (INFO level)')
@click.option('--debug', '-d', is_flag=True, help='Enable debug logging (DEBUG level)')
@click.option('--quiet', '-q', is_flag=True, help='[DEPRECATED] Use default behavior instead')
@click.option('--semantic/--no-semantic', default=False, show_default=True,
              help='Enable semantic embeddings (requires cached SentenceTransformer)')
def serve(transport: str, port: int, host: str, verbose: bool, debug: bool, quiet: bool, semantic: bool):
    """Start MCP server for Claude Code integration"""  
    config = load_config()
    # Î°úÍπÖ Î†àÎ≤® Í≤∞Ï†ï (ÏÉàÎ°úÏö¥ Ï†ïÏ±Ö: Í∏∞Î≥∏ÏùÄ Ï°∞Ïö©Ìï®)
    if debug:
        log_level = 'debug'
        click.echo(f"üîç Starting Greeum MCP server ({transport}) - DEBUG mode...")
    elif verbose:
        log_level = 'verbose'
        click.echo(f"[NOTE] Starting Greeum MCP server ({transport}) - VERBOSE mode...")
    else:
        log_level = 'quiet'
        # Í∏∞Î≥∏ÏùÄ Ï°∞Ïö©Ìï® (Ï∂úÎ†• ÏóÜÏùå)
    
    # --quiet ÌîåÎûòÍ∑∏ Ìò∏ÌôòÏÑ± Í≤ΩÍ≥†
    if quiet:
        if verbose or debug:
            click.echo("‚ö†Ô∏è  Warning: --quiet is deprecated and conflicts with --verbose/--debug")
        else:
            click.echo("‚ö†Ô∏è  Warning: --quiet is deprecated. Default behavior is now quiet.")
    
    if transport == 'stdio':
        ensure_data_dir(config.data_dir)
        os.environ.setdefault('GREEUM_DATA_DIR', config.data_dir)
        if semantic:
            # Allow explicit opt-in by clearing the fallback flag
            if os.getenv('GREEUM_DISABLE_ST'):
                os.environ.pop('GREEUM_DISABLE_ST')
            if verbose or debug and not config.semantic_ready:
                click.echo('[WARN] Semantic mode requested but warm-up is not recorded; first startup may take longer.')
            try:
                init_sentence_transformer(set_as_default=True)
            except RuntimeError as err:
                if verbose or debug:
                    click.echo(f'[WARN] {err}')
            except ImportError as err:
                if verbose or debug:
                    click.echo(f'[WARN] {err}')
                force_simple_fallback(set_as_default=True)
        else:
            os.environ.setdefault('GREEUM_DISABLE_ST', '1')
            if verbose or debug:
                if config.semantic_ready:
                    click.echo('[NOTE] Semantic embeddings available. Use --semantic to enable them for this session.')
                else:
                    click.echo('[NOTE] SentenceTransformer disabled (hash fallback). Use --semantic after warm-up to re-enable.')
            force_simple_fallback(set_as_default=True)
        try:
            # Native MCP Server ÏÇ¨Ïö© (FastMCP ÏôÑÏ†Ñ Î∞∞Ï†ú, anyio Í∏∞Î∞ò ÏïàÏ†ÑÌïú Ïã§Ìñâ)
            from ..mcp.native import run_server_sync
            run_server_sync(log_level=log_level)
        except ImportError as e:
            if verbose or debug:
                click.echo(f"Native MCP server import failed: {e}")
                click.echo("Please ensure anyio>=4.5 is installed: pip install anyio>=4.5")
            sys.exit(1)
        except KeyboardInterrupt:
            if verbose or debug:
                click.echo("\nMCP server stopped")
        except Exception as e:
            # anyio CancelledErrorÎèÑ Ïó¨Í∏∞ÏÑú Ï∫êÏπòÎê® - Ï°∞Ïö©Ìûà Ï≤òÎ¶¨
            error_msg = str(e)
            if "CancelledError" in error_msg or "cancelled" in error_msg.lower():
                if verbose or debug:
                    click.echo("\nMCP server stopped")
            else:
                if verbose or debug:
                    click.echo(f"MCP server error: {e}")
                sys.exit(1)
    elif transport == 'http':
        try:
            from ..mcp.native.http_server import run_http_server
            run_http_server(host=host, port=port, log_level=log_level)
        except RuntimeError as e:
            if verbose or debug:
                click.echo(str(e))
            sys.exit(1)
        except KeyboardInterrupt:
            if verbose or debug:
                click.echo("\nMCP HTTP server stopped")
        except Exception as e:
            if verbose or debug:
                click.echo(f"MCP HTTP server error: {e}")
            sys.exit(1)
    elif transport == 'websocket':
        try:
            # WebSocket transport (Ìñ•ÌõÑ ÌôïÏû•)
            from ..mcp.cli_entry import run_cli_server
            run_cli_server(transport='websocket', port=port)
        except ImportError as e:
            if verbose or debug:
                click.echo(f"MCP server import failed: {e}")
                click.echo("Please ensure all dependencies are installed")
            sys.exit(1)
        except NotImplementedError:
            if verbose or debug:
                click.echo(f"WebSocket transport not implemented yet")
            sys.exit(1)
        except KeyboardInterrupt:
            if verbose or debug:
                click.echo("\nMCP server stopped")
        except Exception as e:
            if verbose or debug:
                click.echo(f"MCP server error: {e}")
            sys.exit(1)
    else:
        if verbose or debug:
            click.echo(f"[ERROR] Transport '{transport}' not supported")
        sys.exit(1)


@worker.command('serve')
@click.option('--host', default='127.0.0.1', show_default=True)
@click.option('--port', default=8800, show_default=True, type=int)
@click.option('--semantic', is_flag=True, help='Enable semantic embeddings for the worker')
@click.option('--stdio', is_flag=True, help='Use STDIO transport instead of HTTP')
def worker_serve(host: str, port: int, semantic: bool, stdio: bool) -> None:
    """Start the long-running worker daemon."""
    transport = 'stdio' if stdio else 'http'
    cmd = [
        sys.executable,
        '-m',
        'greeum.cli',
        'mcp',
        'serve',
        '-t',
        transport,
    ]
    if not stdio:
        cmd += ['--host', host, '--port', str(port)]
    if semantic:
        cmd.append('--semantic')
    click.echo(f"Starting worker daemon ({'STDIO' if stdio else 'HTTP'})...")
    click.echo('Command: ' + ' '.join(cmd))
    try:
        subprocess.run(cmd, check=True)
    except subprocess.CalledProcessError as exc:
        click.echo(f"Worker exited with status {exc.returncode}")

@mcp.command('warmup')
@click.option('--model', default='sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2',
              show_default=True, help='SentenceTransformer model to pre-download')
def warmup_embeddings(model: str):
    """Download the semantic embedding model so --semantic starts instantly."""

    click.echo(f"üì¶ Downloading {model} ‚Ä¶")

    try:
        cache_dir = _download_sentence_transformer(model)
    except ImportError as exc:
        click.echo(f"[ERROR] {exc}", err=True)
        mark_semantic_ready(False)
        sys.exit(1)
    except Exception as exc:  # noqa: BLE001 - surface full error to user
        click.echo(f"[ERROR] Warm-up failed: {exc}", err=True)
        mark_semantic_ready(False)
        sys.exit(1)

    mark_semantic_ready(True)
    click.echo(f"‚úÖ Warm-up complete. Model cached at {cache_dir}.")
    click.echo("   Use 'greeum mcp serve --semantic' to enable semantic embeddings.")


# API ÏÑúÎ∏åÎ™ÖÎ†πÏñ¥Îì§  
@api.command()
@click.option('--port', '-p', default=5000, help='Server port')
@click.option('--host', '-h', default='localhost', help='Server host')
def serve(port: int, host: str):
    """Start REST API server"""
    click.echo(f"üåê Starting Greeum API server on {host}:{port}...")
    
    try:
        from ..api.memory_api import app
        import uvicorn
        uvicorn.run(app, host=host, port=port)
    except ImportError:
        click.echo("[ERROR] API server dependencies not installed. Try: pip install greeum[api]")
        sys.exit(1)
    except KeyboardInterrupt:
        click.echo("\nüëã API server stopped")

# LTM ÏÑúÎ∏åÎ™ÖÎ†πÏñ¥Îì§
@ltm.command()
@click.option('--trends', is_flag=True, help='Analyze emotional and topic trends')
@click.option('--period', '-p', default='6m', help='Analysis period (e.g., 6m, 1y)')
@click.option('--output', '-o', default='text', help='Output format (text/json)')
def analyze(trends: bool, period: str, output: str):
    """Analyze long-term memory patterns and trends"""
    click.echo(f"üîç Analyzing LTM patterns...")
    
    if trends:
        click.echo(f"üìä Trend analysis for period: {period}")
    
    try:
        from ..core import BlockManager, DatabaseManager
        import json
        from datetime import datetime, timedelta
        
        # Í∏∞Í∞Ñ ÌååÏã±
        period_map = {'m': 'months', 'y': 'years', 'd': 'days', 'w': 'weeks'}
        period_num = int(period[:-1])
        period_unit = period_map.get(period[-1], 'months')
        
        db_manager = DatabaseManager()
        block_manager = BlockManager(db_manager)
        
        # Ï†ÑÏ≤¥ Î∏îÎ°ù Ï°∞Ìöå
        all_blocks = block_manager.get_blocks()
        
        analysis = {
            "total_blocks": len(all_blocks),
            "analysis_period": period,
            "analysis_date": datetime.now().isoformat(),
            "summary": f"Analyzed {len(all_blocks)} memory blocks"
        }
        
        if trends:
            # ÌÇ§ÏõåÎìú ÎπàÎèÑ Î∂ÑÏÑù
            keyword_freq = {}
            for block in all_blocks:
                keywords = block.get('keywords', [])
                for keyword in keywords:
                    keyword_freq[keyword] = keyword_freq.get(keyword, 0) + 1
            
            # ÏÉÅÏúÑ ÌÇ§ÏõåÎìú
            top_keywords = sorted(keyword_freq.items(), key=lambda x: x[1], reverse=True)[:10]
            analysis["top_keywords"] = top_keywords
        
        if output == 'json':
            click.echo(json.dumps(analysis, indent=2, ensure_ascii=False))
        else:
            click.echo(f"[IMPROVE] Analysis Results:")
            click.echo(f"  ‚Ä¢ Total memories: {analysis['total_blocks']}")
            click.echo(f"  ‚Ä¢ Period: {analysis['analysis_period']}")
            if trends and 'top_keywords' in analysis:
                click.echo(f"  ‚Ä¢ Top keywords:")
                for keyword, freq in analysis['top_keywords'][:5]:
                    click.echo(f"    - {keyword}: {freq} times")
                    
    except Exception as e:
        click.echo(f"[ERROR] Analysis failed: {e}")
        sys.exit(1)

@ltm.command()
@click.option('--repair', is_flag=True, help='Attempt to repair integrity issues')
def verify(repair: bool):
    """Verify blockchain-like LTM integrity"""
    click.echo("üîç Verifying LTM blockchain integrity...")
    
    try:
        from ..core import BlockManager, DatabaseManager
        import hashlib
        
        db_manager = DatabaseManager()
        block_manager = BlockManager(db_manager)
        
        all_blocks = block_manager.get_blocks()
        
        issues = []
        verified_count = 0
        
        for i, block in enumerate(all_blocks):
            # Ìï¥Ïãú Í≤ÄÏ¶ù
            if 'hash' in block:
                # Î∏îÎ°ù Îç∞Ïù¥ÌÑ∞Î°úÎ∂ÄÌÑ∞ Ìï¥Ïãú Ïû¨Í≥ÑÏÇ∞
                block_data = {
                    'block_index': block.get('block_index'),
                    'timestamp': block.get('timestamp'),
                    'context': block.get('context'),
                    'prev_hash': block.get('prev_hash', '')
                }
                calculated_hash = hashlib.sha256(
                    str(block_data).encode()
                ).hexdigest()[:16]
                
                if block.get('hash') != calculated_hash:
                    issues.append(f"Block #{block.get('block_index', i)}: Hash mismatch")
                else:
                    verified_count += 1
            else:
                issues.append(f"Block #{block.get('block_index', i)}: Missing hash")
        
        # Í≤∞Í≥º Ï∂úÎ†•
        total_blocks = len(all_blocks)
        click.echo(f"‚úÖ Verified {verified_count}/{total_blocks} blocks")
        
        if issues:
            click.echo(f"‚ö†Ô∏è  Found {len(issues)} integrity issues:")
            for issue in issues[:10]:  # ÏµúÎåÄ 10Í∞úÎßå ÌëúÏãú
                click.echo(f"  ‚Ä¢ {issue}")
            
            if repair:
                click.echo("üî® Repair functionality not implemented yet")
        else:
            click.echo("[SUCCESS] All blocks verified successfully!")
                    
    except Exception as e:
        click.echo(f"[ERROR] Verification failed: {e}")
        sys.exit(1)

@ltm.command()
@click.option('--format', '-f', default='json', help='Export format (json/blockchain/csv)')
@click.option('--output', '-o', help='Output file path')
@click.option('--limit', '-l', type=int, help='Limit number of blocks')
def export(format: str, output: str, limit: int):
    """Export LTM data in various formats"""
    click.echo(f"üì§ Exporting LTM data (format: {format})...")
    
    try:
        from ..core import BlockManager, DatabaseManager
        import json
        import csv
        from pathlib import Path
        
        db_manager = DatabaseManager()
        block_manager = BlockManager(db_manager)
        
        all_blocks = block_manager.get_blocks()
        
        if limit:
            all_blocks = all_blocks[:limit]
        
        # Ï∂úÎ†• ÌååÏùº Í≤ΩÎ°ú Í≤∞Ï†ï
        if not output:
            from datetime import datetime
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output = f"greeum_ltm_export_{timestamp}.{format}"
        
        output_path = Path(output)
        
        if format == 'json':
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(all_blocks, f, indent=2, ensure_ascii=False)
                
        elif format == 'blockchain':
            # Î∏îÎ°ùÏ≤¥Ïù∏ ÌòïÌÉúÎ°ú Íµ¨Ï°∞Ìôî
            blockchain_data = {
                "chain_info": {
                    "total_blocks": len(all_blocks),
                    "export_date": datetime.now().isoformat(),
                    "format_version": "1.0"
                },
                "blocks": all_blocks
            }
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(blockchain_data, f, indent=2, ensure_ascii=False)
                
        elif format == 'csv':
            with open(output_path, 'w', newline='', encoding='utf-8') as f:
                if all_blocks:
                    writer = csv.DictWriter(f, fieldnames=all_blocks[0].keys())
                    writer.writeheader()
                    writer.writerows(all_blocks)
        
        click.echo(f"‚úÖ Exported {len(all_blocks)} blocks to: {output_path}")
        click.echo(f"üìÑ File size: {output_path.stat().st_size} bytes")
                    
    except Exception as e:
        click.echo(f"[ERROR] Export failed: {e}")
        sys.exit(1)

# STM ÏÑúÎ∏åÎ™ÖÎ†πÏñ¥Îì§
@stm.command()
@click.argument('content')
@click.option('--ttl', default='1h', help='Time to live (e.g., 1h, 30m, 2d)')
@click.option('--importance', '-i', default=0.3, help='Importance score (0.0-1.0)')
def add(content: str, ttl: str, importance: float):
    """Add content to short-term memory with TTL"""
    click.echo(f"[MEMORY] Adding to STM (TTL: {ttl})...")
    
    try:
        from ..core import STMManager, DatabaseManager
        import re
        from datetime import datetime, timedelta
        
        # TTL ÌååÏã±
        ttl_pattern = r'(\d+)([hmdw])'
        match = re.match(ttl_pattern, ttl.lower())
        if not match:
            click.echo("[ERROR] Invalid TTL format. Use: 1h, 30m, 2d, 1w")
            sys.exit(1)
        
        amount, unit = match.groups()
        amount = int(amount)
        
        unit_map = {'m': 'minutes', 'h': 'hours', 'd': 'days', 'w': 'weeks'}
        unit_name = unit_map.get(unit, 'hours')
        
        # TTL Í≥ÑÏÇ∞
        kwargs = {unit_name: amount}
        expiry_time = datetime.now() + timedelta(**kwargs)
        
        db_manager = DatabaseManager()
        stm_manager = STMManager(db_manager)
        
        # STMÏóê Ï∂îÍ∞Ä
        memory_data = {
            'content': content,
            'importance': importance,
            'ttl_seconds': int(timedelta(**kwargs).total_seconds()),
            'expiry_time': expiry_time.isoformat()
        }
        result = stm_manager.add_memory(memory_data)
        
        if result:
            click.echo(f"‚úÖ Added to STM (expires: {expiry_time.strftime('%Y-%m-%d %H:%M:%S')})")
        else:
            click.echo("[ERROR] Failed to add to STM")
            sys.exit(1)
                    
    except Exception as e:
        click.echo(f"[ERROR] STM add failed: {e}")
        sys.exit(1)

@stm.command()
@click.option('--threshold', '-t', default=0.8, help='Importance threshold for promotion')
@click.option('--dry-run', is_flag=True, help='Show what would be promoted without doing it')
def promote(threshold: float, dry_run: bool):
    """Promote important STM entries to LTM"""
    click.echo(f"üîù Promoting STM ‚Üí LTM (threshold: {threshold})...")
    
    try:
        from ..core import STMManager, BlockManager, DatabaseManager
        from ..text_utils import process_user_input
        
        db_manager = DatabaseManager()
        stm_manager = STMManager(db_manager)
        block_manager = BlockManager(db_manager)
        
        # STMÏóêÏÑú Î™®Îì† Ìï≠Î™© Ï°∞Ìöå (Ï∂©Î∂ÑÌûà ÌÅ∞ ÏàòÎ°ú)
        stm_entries = stm_manager.get_recent_memories(count=1000)
        
        candidates = []
        for entry in stm_entries:
            if entry.get('importance', 0) >= threshold:
                candidates.append(entry)
        
        if not candidates:
            click.echo(f"üì≠ No STM entries above threshold {threshold}")
            return
        
        click.echo(f"üéØ Found {len(candidates)} candidates for promotion:")
        
        promoted_count = 0
        for entry in candidates:
            content = entry.get('content', '')
            importance = entry.get('importance', 0)
            
            click.echo(f"  ‚Ä¢ {content[:50]}... (importance: {importance:.2f})")
            
            if not dry_run:
                # LTMÏúºÎ°ú ÏäπÍ≤©
                keywords, tags = process_user_input(content)
                
                # Í∞ÑÎã®Ìïú ÏûÑÎ≤†Îî© (Ïã§Ï†úÎ°úÎäî Îçî Ï†ïÍµêÌïòÍ≤å)
                simple_embedding = [hash(word) % 1000 / 1000.0 for word in content.split()[:10]]
                simple_embedding.extend([0.0] * (10 - len(simple_embedding)))  # 10Ï∞®ÏõêÏúºÎ°ú Ìå®Îî©
                
                ltm_block = block_manager.add_block(
                    context=content,
                    keywords=keywords,
                    tags=tags,
                    embedding=simple_embedding,
                    importance=importance,
                    metadata={'promoted_from_stm': True}
                )
                
                if ltm_block:
                    # STMÏóêÏÑú Ï†úÍ±∞
                    stm_manager.remove_memory(entry.get('id', ''))
                    promoted_count += 1
        
        if dry_run:
            click.echo(f"üîç Dry run: {len(candidates)} entries would be promoted")
        else:
            click.echo(f"‚úÖ Promoted {promoted_count}/{len(candidates)} entries to LTM")
                    
    except Exception as e:
        click.echo(f"[ERROR] Promotion failed: {e}")
        sys.exit(1)

@stm.command()
@click.option('--smart', is_flag=True, help='Use intelligent cleanup based on importance')
@click.option('--expired', is_flag=True, help='Remove only expired entries')
@click.option('--threshold', '-t', default=0.2, help='Remove entries below this importance')
def cleanup(smart: bool, expired: bool, threshold: float):
    """Clean up short-term memory entries"""
    click.echo("üßπ Cleaning up STM...")
    
    try:
        from ..core import STMManager, DatabaseManager
        from datetime import datetime
        
        db_manager = DatabaseManager()
        stm_manager = STMManager(db_manager)
        stm_entries = stm_manager.get_recent_memories(count=1000)
        
        if not stm_entries:
            click.echo("üì≠ STM is already empty")
            return
        
        removed_count = 0
        total_count = len(stm_entries)
        
        click.echo(f"üìä Total STM entries: {total_count}")
        
        for entry in stm_entries:
            should_remove = False
            reason = ""
            
            if expired:
                # ÎßåÎ£åÎêú Ìï≠Î™©Îßå Ï†úÍ±∞
                expiry = entry.get('expiry_time')
                if expiry and datetime.now() > datetime.fromisoformat(expiry):
                    should_remove = True
                    reason = "expired"
            
            elif smart:
                # ÏßÄÎä•Ìòï Ï†ïÎ¶¨
                importance = entry.get('importance', 0)
                if importance < threshold:
                    should_remove = True
                    reason = f"low importance ({importance:.2f} < {threshold})"
            
            else:
                # Í∏∞Î≥∏: ÎÇÆÏùÄ Ï§ëÏöîÎèÑÎßå
                importance = entry.get('importance', 0)
                if importance < 0.1:
                    should_remove = True
                    reason = "very low importance"
            
            if should_remove:
                entry_id = entry.get('id', '')
                content = entry.get('content', '')[:30]
                
                if stm_manager.remove_memory(entry_id):
                    click.echo(f"  üóëÔ∏è  Removed: {content}... ({reason})")
                    removed_count += 1
        
        click.echo(f"‚úÖ Cleanup complete: {removed_count}/{total_count} entries removed")
        click.echo(f"üìä Remaining STM entries: {total_count - removed_count}")
                    
    except Exception as e:
        click.echo(f"[ERROR] Cleanup failed: {e}")
        sys.exit(1)

# AI Context Slots ÏÑúÎ∏åÎ™ÖÎ†πÏñ¥Îì§ (v3.0.0.post5)
@slots.command()
def status():
    """Display current AI Context Slots status (v3.0.0.post5)"""
    click.echo("[MEMORY] AI Context Slots Status Report (v3.0.0.post5)")
    click.echo("=" * 50)
    
    try:
        from ..core.working_memory import AIContextualSlots
        from datetime import datetime
        
        # AI Context Slots Ïù∏Ïä§ÌÑ¥Ïä§ ÏÉùÏÑ±
        slots_instance = AIContextualSlots()
        
        # Ïä¨Î°Ø ÏÉÅÌÉú ÌôïÏù∏
        status = slots_instance.get_status()
        
        active_count = sum(1 for s in status.values() if s is not None)
        click.echo(f"Active Slots: {active_count}/3")
        
        for slot_name, slot_info in status.items():
            if slot_info:
                slot_type = slot_info['type']
                content = slot_info['content_preview']
                timestamp = slot_info['timestamp']
                importance = slot_info['importance']
                is_anchor = slot_info['is_anchor']
                
                # Ïä¨Î°Ø ÌÉÄÏûÖÎ≥Ñ ÏïÑÏù¥ÏΩò
                type_icon = {"context": "üéØ", "anchor": "‚öì", "buffer": "üìã"}.get(slot_type, "üîπ")
                
                click.echo(f"\n{type_icon} {slot_name.upper()} Slot ({slot_type})")
                click.echo(f"   Content: {content}")
                click.echo(f"   Importance: {importance:.2f}")
                click.echo(f"   Created: {timestamp}")
                
                if is_anchor and slot_info.get('anchor_block'):
                    click.echo(f"   [LINK] LTM Anchor: Block #{slot_info['anchor_block']}")
                    
            else:
                click.echo(f"\n‚≠ï {slot_name.upper()} Slot: Empty")
        
        click.echo("\n" + "=" * 50)
        click.echo("üí° Use 'greeum slots set <content>' to add to slots")
        click.echo("üí° Use 'greeum slots clear <slot_name>' to clear specific slot")
                    
    except Exception as e:
        click.echo(f"[ERROR] Error reading slots status: {e}")
        sys.exit(1)

@slots.command()
@click.argument('content')
@click.option('--importance', '-i', default=0.5, help='Importance score (0.0-1.0)')
@click.option('--ltm-anchor', type=int, help='LTM block ID for anchoring')
@click.option('--radius', default=5, help='Search radius for LTM anchor')
def set(content: str, importance: float, ltm_anchor: int, radius: int):
    """Add content to AI Context Slots with smart allocation"""
    click.echo(f"[MEMORY] Adding content to AI Context Slots...")
    
    try:
        from ..core.working_memory import AIContextualSlots
        
        # AI Context Slots Ïù∏Ïä§ÌÑ¥Ïä§ ÏÉùÏÑ±
        slots_instance = AIContextualSlots()
        
        # Ïª®ÌÖçÏä§Ìä∏ Íµ¨ÏÑ±
        context = {
            'importance': importance,
            'metadata': {'cli_command': True}
        }
        
        if ltm_anchor:
            context['ltm_block_id'] = ltm_anchor
            context['search_radius'] = radius
        
        # AIÍ∞Ä ÏµúÏ†Å Ïä¨Î°Ø Í≤∞Ï†ï
        used_slot = slots_instance.ai_decide_usage(content, context)
        
        # Í≤∞Í≥º Ï∂úÎ†•
        click.echo(f"‚úÖ Content added to {used_slot.upper()} slot")
        click.echo(f"[NOTE] Content: {content[:80]}{'...' if len(content) > 80 else ''}")
        click.echo(f"üéØ AI chose {used_slot} slot based on content analysis")
        
        if ltm_anchor:
            click.echo(f"[LINK] LTM Anchor: Block #{ltm_anchor} (radius: {radius})")
        
    except Exception as e:
        click.echo(f"[ERROR] Failed to add to slots: {e}")
        sys.exit(1)

@slots.command()
@click.argument('slot_name', type=click.Choice(['active', 'anchor', 'buffer', 'all']))
def clear(slot_name: str):
    """Clear specific slot or all slots"""
    click.echo(f"üóëÔ∏è  Clearing {slot_name} slot(s)...")
    
    try:
        from ..core.working_memory import AIContextualSlots
        
        # AI Context Slots Ïù∏Ïä§ÌÑ¥Ïä§ ÏÉùÏÑ±
        slots_instance = AIContextualSlots()
        
        if slot_name == "all":
            # Î™®Îì† Ïä¨Î°Ø ÎπÑÏö∞Í∏∞
            cleared_count = 0
            for slot in ['active', 'anchor', 'buffer']:
                if slots_instance.clear_slot(slot):
                    cleared_count += 1
            
            click.echo(f"‚úÖ Cleared {cleared_count} slots")
            
        else:
            # ÌäπÏ†ï Ïä¨Î°Ø ÎπÑÏö∞Í∏∞
            if slots_instance.clear_slot(slot_name):
                click.echo(f"‚úÖ Cleared {slot_name.upper()} slot")
            else:
                click.echo(f"‚ö†Ô∏è  {slot_name.upper()} slot was already empty")
        
    except Exception as e:
        click.echo(f"[ERROR] Failed to clear slot: {e}")
        sys.exit(1)

@slots.command()
@click.argument('query')
@click.option('--limit', '-l', default=5, help='Maximum number of results')
def search(query: str, limit: int):
    """Search using AI Context Slots integration"""
    click.echo(f"üîç Searching with AI Context Slots: '{query}'")
    
    try:
        from greeum.core import DatabaseManager
        from greeum.core.block_manager import BlockManager
        
        db_manager = DatabaseManager()
        block_manager = BlockManager(db_manager)
        
        # Ïä¨Î°Ø ÌÜµÌï© Í≤ÄÏÉâ Ïã§Ìñâ
        results = block_manager.search_with_slots(
            query=query, 
            limit=limit, 
            use_slots=True
        )
        
        if results:
            click.echo(f"üìã Found {len(results)} results:")
            
            for i, result in enumerate(results, 1):
                source = result.get('source', 'unknown')
                content = result.get('context', 'No content')[:80]
                importance = result.get('importance', 0)
                
                if source == 'working_memory':
                    slot_type = result.get('slot_type', 'unknown')
                    type_icon = {"context": "üéØ", "anchor": "‚öì", "buffer": "üìã"}.get(slot_type, "üîπ")
                    click.echo(f"{i}. {type_icon} [{slot_type.upper()} SLOT] {content}...")
                else:
                    block_index = result.get('block_index', '?')
                    click.echo(f"{i}. üìö [LTM #{block_index}] {content}...")
                
                click.echo(f"   Importance: {importance:.2f}")
        else:
            click.echo("[ERROR] No results found")
        
    except Exception as e:
        click.echo(f"[ERROR] Search failed: {e}")
        sys.exit(1)

# Migration ÏÑúÎ∏åÎ™ÖÎ†πÏñ¥Îì§ (v2.5.3 AI-Powered Migration)
@migrate.command()
@click.option('--data-dir', default='data', help='Data directory path')
@click.option('--force', is_flag=True, help='Force migration even if already v2.5.3')
def check(data_dir: str, force: bool):
    """Check database schema version and trigger migration if needed"""
    click.echo("üîç Checking Greeum database schema version...")
    
    try:
        from pathlib import Path

        db_path = Path(data_dir).expanduser() / "memory.db"
        db_path.parent.mkdir(parents=True, exist_ok=True)

        manager = DatabaseManager(str(db_path))
        cursor = manager.conn.cursor()

        needs_migration = BranchSchemaSQL.check_migration_needed(cursor)

        if force or needs_migration:
            manager._apply_branch_migration(cursor)
            manager._initialize_branch_structures(cursor)
            manager.conn.commit()
            click.echo("\n‚úÖ Branch schema migration applied.")
        else:
            click.echo("\n‚úÖ Branch schema already up to date.")

        manager.conn.close()
        sys.exit(0)

    except Exception as e:
        click.echo(f"[ERROR] Migration check failed: {e}")
        sys.exit(1)

@migrate.command()
@click.option('--data-dir', default='data', help='Data directory path')
def status(data_dir: str):
    """Check current migration status and schema version"""
    click.echo("üìä Greeum Database Migration Status")
    click.echo("=" * 40)
    
    try:
        from pathlib import Path

        db_path = Path(data_dir).expanduser() / "memory.db"

        if not db_path.exists():
            click.echo("üìÇ Database Status: Not found")
            click.echo("   This appears to be a new installation")
            return

        manager = DatabaseManager(str(db_path))
        cursor = manager.conn.cursor()

        cursor.execute("PRAGMA table_info(blocks)")
        columns = {row[1] for row in cursor.fetchall()}
        branch_columns = {
            'root', 'before', 'after', 'xref',
            'slot', 'branch_similarity', 'branch_created_at'
        }

        branch_ready = branch_columns.issubset(columns)
        anchor_store = get_anchor_store()
        slot_rows = [
            (slot_name, slot_data.anchor_block)
            for slot_name, slot_data in anchor_store.get_slots().items()
        ]

        click.echo(f"üìÇ Database Size: {db_path.stat().st_size} bytes")
        click.echo(f"üìã Branch Columns Present: {'yes' if branch_ready else 'no'}")

        if slot_rows:
            click.echo("\nüéØ STM Slots:")
            for slot_name, block_hash in slot_rows:
                head = block_hash[:8] + '...' if block_hash else 'None'
                click.echo(f"   ‚Ä¢ {slot_name}: head={head}")
        else:
            click.echo("\n‚ö†Ô∏è  STM anchor entries not initialized yet.")

        pending = BranchSchemaSQL.check_migration_needed(cursor)
        click.echo("\n‚úÖ Migration Status: {}".format("Ready" if not pending else "Additional migration required"))

        manager.conn.close()

    except Exception as e:
        click.echo(f"[ERROR] Status check failed: {e}")
        sys.exit(1)

@migrate.command()
@click.option('--data-dir', default='data', help='Data directory path')
@click.option('--backup-id', help='Specific backup ID to rollback to')
@click.option('--reason', default='Manual rollback', help='Reason for rollback')
def rollback(data_dir: str, backup_id: str, reason: str):
    """Rollback to previous database state using backups"""
    click.echo("‚Ü©Ô∏è  Emergency rollback tooling has been deprecated in the branch-aware preview.")
    click.echo("   Please restore from your manual backup if needed.")
    sys.exit(0)

@migrate.command()
@click.option('--data-dir', default='data', help='Data directory path')
def validate(data_dir: str):
    """Validate migration results and database health"""
    click.echo("üîç Automated migration validation is not available in this preview build.")
    click.echo("   Please run manual smoke tests after 'greeum migrate check'.")
    sys.exit(0)

@migrate.command()
@click.option('--data-dir', default='data', help='Data directory path')
@click.option('--keep-backups', default=5, help='Number of backups to keep')
def cleanup(data_dir: str, keep_backups: int):
    """Clean up old migration backups"""
    click.echo("üßπ Backup cleanup is not implemented in the branch-aware preview.")
    click.echo("   Remove unwanted backup files manually if needed.")
    sys.exit(0)

# v2.6.1 Backup ÏÑúÎ∏åÎ™ÖÎ†πÏñ¥Îì§
@backup.command()
@click.option('--output', '-o', required=True, help='Î∞±ÏóÖ ÌååÏùº Ï†ÄÏû• Í≤ΩÎ°ú')
@click.option('--include-metadata/--no-metadata', default=True, help='ÏãúÏä§ÌÖú Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ Ìè¨Ìï® Ïó¨Î∂Ä')
def export(output: str, include_metadata: bool):
    """Ï†ÑÏ≤¥ Î©îÎ™®Î¶¨Î•º Î∞±ÏóÖ ÌååÏùºÎ°ú ÎÇ¥Î≥¥ÎÇ¥Í∏∞"""
    try:
        from ..core.backup_restore import MemoryBackupEngine
        # from ..core.hierarchical_memory import HierarchicalMemorySystem  # REMOVED: File deleted
        from ..core.database_manager import DatabaseManager
        from pathlib import Path
        
        click.echo("[PROCESS] Î©îÎ™®Î¶¨ Î∞±ÏóÖÏùÑ ÏãúÏûëÌï©ÎãàÎã§...")
        
        # Í≥ÑÏ∏µÏ†Å Î©îÎ™®Î¶¨ ÏãúÏä§ÌÖú Ï¥àÍ∏∞Ìôî - SIMPLIFIED
        db_manager = DatabaseManager()
        # HierarchicalMemorySystem removed - using DatabaseManager directly
        
        backup_engine = MemoryBackupEngine(db_manager)
        success = backup_engine.create_backup(output, include_metadata)
        
        if success:
            click.echo(f"‚úÖ Î∞±ÏóÖ ÏôÑÎ£å: {output}")
            backup_path = Path(output)
            if backup_path.exists():
                size_mb = backup_path.stat().st_size / (1024 * 1024)
                click.echo(f"üìÅ ÌååÏùº ÌÅ¨Í∏∞: {size_mb:.2f} MB")
        else:
            click.echo("[ERROR] Î∞±ÏóÖ ÏÉùÏÑ±Ïóê Ïã§Ìå®ÌñàÏäµÎãàÎã§")
            
    except Exception as e:
        click.echo(f"üí• Î∞±ÏóÖ Ï§ë Ïò§Î•ò: {e}")


@backup.command()
@click.option('--schedule', type=click.Choice(['hourly', 'daily', 'weekly', 'monthly']), 
              required=True, help='Î∞±ÏóÖ Ï£ºÍ∏∞ ÏÑ§Ï†ï')
@click.option('--output-dir', '-d', help='Î∞±ÏóÖ Ï†ÄÏû• ÎîîÎ†âÌÜ†Î¶¨ (Í∏∞Î≥∏: ~/greeum-backups)')
@click.option('--max-backups', type=int, default=10, help='Î≥¥Ï°¥Ìï† ÏµúÎåÄ Î∞±ÏóÖ Ïàò (Í∏∞Î≥∏: 10Í∞ú)')
@click.option('--enable/--disable', default=True, help='ÏûêÎèô Î∞±ÏóÖ ÌôúÏÑ±Ìôî/ÎπÑÌôúÏÑ±Ìôî')
def auto(schedule: str, output_dir: str, max_backups: int, enable: bool):
    """ÏûêÎèô Î∞±ÏóÖ Ïä§ÏºÄÏ§Ñ ÏÑ§Ï†ï Î∞è Í¥ÄÎ¶¨
    
    Examples:
        greeum backup auto --schedule daily --output-dir ~/backups
        greeum backup auto --schedule weekly --max-backups 5
        greeum backup auto --schedule daily --disable
    """
    try:
        from pathlib import Path
        import json
        import os
        
        if not output_dir:
            output_dir = str(Path.home() / "greeum-backups")
        
        # Î∞±ÏóÖ ÎîîÎ†âÌÜ†Î¶¨ ÏÉùÏÑ±
        backup_path = Path(output_dir)
        backup_path.mkdir(parents=True, exist_ok=True)
        
        # ÏûêÎèô Î∞±ÏóÖ ÏÑ§Ï†ï ÌååÏùº Í≤ΩÎ°ú
        config_file = backup_path / "auto_backup_config.json"
        
        if enable:
            # ÏûêÎèô Î∞±ÏóÖ ÌôúÏÑ±Ìôî
            from datetime import datetime
            
            config = {
                "enabled": True,
                "schedule": schedule,
                "output_dir": str(backup_path),
                "max_backups": max_backups,
                "last_backup": None,
                "created_at": datetime.now().isoformat()
            }
            
            with open(config_file, 'w', encoding='utf-8') as f:
                json.dump(config, f, indent=2, ensure_ascii=False)
            
            click.echo(f"‚úÖ ÏûêÎèô Î∞±ÏóÖ ÌôúÏÑ±ÌôîÎê®")
            click.echo(f"   [DATE] Ï£ºÍ∏∞: {schedule}")
            click.echo(f"   üìÅ ÎîîÎ†âÌÜ†Î¶¨: {output_dir}")
            click.echo(f"   üî¢ ÏµúÎåÄ Î∞±ÏóÖ Ïàò: {max_backups}Í∞ú")
            click.echo()
            click.echo("üí° ÏûêÎèô Î∞±ÏóÖ Ïã§Ìñâ Î∞©Î≤ï:")
            
            if schedule == 'hourly':
                cron_expr = "0 * * * *"
            elif schedule == 'daily':
                cron_expr = "0 2 * * *"  # ÏÉàÎ≤Ω 2Ïãú
            elif schedule == 'weekly':
                cron_expr = "0 2 * * 0"  # ÏùºÏöîÏùº ÏÉàÎ≤Ω 2Ïãú
            else:  # monthly
                cron_expr = "0 2 1 * *"  # Îß§Ïõî 1Ïùº ÏÉàÎ≤Ω 2Ïãú
            
            click.echo(f"   crontabÏóê Ï∂îÍ∞Ä: {cron_expr} greeum backup run-auto")
            click.echo("   ÎòêÎäî ÏãúÏä§ÌÖú Ïä§ÏºÄÏ§ÑÎü¨Î•º ÏÇ¨Ïö©ÌïòÏó¨ 'greeum backup run-auto' Ïã§Ìñâ")
            
        else:
            # ÏûêÎèô Î∞±ÏóÖ ÎπÑÌôúÏÑ±Ìôî
            if config_file.exists():
                config_file.unlink()
                click.echo("‚úÖ ÏûêÎèô Î∞±ÏóÖÏù¥ ÎπÑÌôúÏÑ±ÌôîÎêòÏóàÏäµÎãàÎã§")
            else:
                click.echo("‚ÑπÔ∏è  ÏûêÎèô Î∞±ÏóÖÏù¥ Ïù¥ÎØ∏ ÎπÑÌôúÏÑ±Ìôî ÏÉÅÌÉúÏûÖÎãàÎã§")
                
    except Exception as e:
        click.echo(f"üí• ÏûêÎèô Î∞±ÏóÖ ÏÑ§Ï†ï Ïã§Ìå®: {e}")


@backup.command()
def run_auto():
    """ÏûêÎèô Î∞±ÏóÖ Ïã§Ìñâ (Ïä§ÏºÄÏ§ÑÎü¨ÏóêÏÑú Ìò∏Ï∂ú)
    
    Ïù¥ Î™ÖÎ†πÏñ¥Îäî cronÏù¥ÎÇò ÏãúÏä§ÌÖú Ïä§ÏºÄÏ§ÑÎü¨ÏóêÏÑú Ìò∏Ï∂úÎê©ÎãàÎã§.
    """
    try:
        from pathlib import Path
        from datetime import datetime, timedelta
        import json
        import glob
        
        # Í∏∞Î≥∏ Î∞±ÏóÖ ÎîîÎ†âÌÜ†Î¶¨
        backup_dir = Path.home() / "greeum-backups"
        config_file = backup_dir / "auto_backup_config.json"
        
        if not config_file.exists():
            click.echo("‚ö†Ô∏è  ÏûêÎèô Î∞±ÏóÖÏù¥ ÏÑ§Ï†ïÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§. 'greeum backup auto' Î™ÖÎ†πÏñ¥Î•º Î®ºÏ†Ä Ïã§ÌñâÌïòÏÑ∏Ïöî")
            return
        
        # ÏÑ§Ï†ï Î°úÎìú
        with open(config_file, 'r', encoding='utf-8') as f:
            config = json.load(f)
        
        if not config.get('enabled', False):
            click.echo("‚ÑπÔ∏è  ÏûêÎèô Î∞±ÏóÖÏù¥ ÎπÑÌôúÏÑ±ÌôîÎêòÏñ¥ ÏûàÏäµÎãàÎã§")
            return
        
        schedule = config['schedule']
        max_backups = config.get('max_backups', 10)
        last_backup = config.get('last_backup')
        
        # ÎßàÏßÄÎßâ Î∞±ÏóÖ Ïù¥ÌõÑ Ï∂©Î∂ÑÌïú ÏãúÍ∞ÑÏù¥ ÏßÄÎÇ¨ÎäîÏßÄ ÌôïÏù∏
        now = datetime.now()
        should_backup = True
        
        if last_backup:
            last_backup_time = datetime.fromisoformat(last_backup)
            
            if schedule == 'hourly' and now - last_backup_time < timedelta(hours=1):
                should_backup = False
            elif schedule == 'daily' and now - last_backup_time < timedelta(days=1):
                should_backup = False
            elif schedule == 'weekly' and now - last_backup_time < timedelta(weeks=1):
                should_backup = False
            elif schedule == 'monthly' and now - last_backup_time < timedelta(days=30):
                should_backup = False
        
        if not should_backup:
            click.echo("‚ÑπÔ∏è  ÏïÑÏßÅ Î∞±ÏóÖ ÏãúÍ∞ÑÏù¥ ÏïÑÎãôÎãàÎã§")
            return
        
        # Î∞±ÏóÖ Ïã§Ìñâ
        timestamp = now.strftime("%Y%m%d_%H%M%S")
        backup_filename = f"auto_backup_{timestamp}.json"
        backup_path = backup_dir / backup_filename
        
        click.echo(f"[PROCESS] ÏûêÎèô Î∞±ÏóÖ Ïã§Ìñâ: {backup_filename}")
        
        # Î∞±ÏóÖ ÏóîÏßÑ Ï¥àÍ∏∞Ìôî Î∞è Î∞±ÏóÖ Ïã§Ìñâ
        from ..core.backup_restore import MemoryBackupEngine
        # from ..core.hierarchical_memory import HierarchicalMemorySystem  # REMOVED: File deleted
        from ..core.database_manager import DatabaseManager
        
        db_manager = DatabaseManager()
        
        backup_engine = MemoryBackupEngine(db_manager)
        success = backup_engine.create_backup(str(backup_path), include_metadata=True)
        
        if success:
            # Î∞±ÏóÖ ÏÑ§Ï†ï ÏóÖÎç∞Ïù¥Ìä∏
            config['last_backup'] = now.isoformat()
            with open(config_file, 'w', encoding='utf-8') as f:
                json.dump(config, f, indent=2, ensure_ascii=False)
            
            # Ïò§ÎûòÎêú Î∞±ÏóÖ ÌååÏùº Ï†ïÎ¶¨
            backup_pattern = str(backup_dir / "auto_backup_*.json")
            backup_files = sorted(glob.glob(backup_pattern), reverse=True)  # ÏµúÏã†Î∂ÄÌÑ∞
            
            if len(backup_files) > max_backups:
                old_backups = backup_files[max_backups:]
                for old_backup in old_backups:
                    Path(old_backup).unlink()
                    click.echo(f"üóëÔ∏è  Ïò§ÎûòÎêú Î∞±ÏóÖ ÏÇ≠Ï†ú: {Path(old_backup).name}")
            
            file_size = backup_path.stat().st_size / (1024 * 1024)
            click.echo(f"‚úÖ ÏûêÎèô Î∞±ÏóÖ ÏôÑÎ£å: {backup_filename} ({file_size:.2f} MB)")
            click.echo(f"üìä Î≥¥Ï°¥Îêú Î∞±ÏóÖ Ïàò: {min(len(backup_files), max_backups)}Í∞ú")
            
        else:
            click.echo("[ERROR] ÏûêÎèô Î∞±ÏóÖ Ïã§Ìå®")
            
    except Exception as e:
        click.echo(f"üí• ÏûêÎèô Î∞±ÏóÖ Ïã§Ìñâ Ïã§Ìå®: {e}")


@backup.command()
def status():
    """ÏûêÎèô Î∞±ÏóÖ ÏÉÅÌÉú ÌôïÏù∏"""
    try:
        from pathlib import Path
        from datetime import datetime
        import json
        import glob
        
        backup_dir = Path.home() / "greeum-backups"
        config_file = backup_dir / "auto_backup_config.json"
        
        if not config_file.exists():
            click.echo("‚ö™ ÏûêÎèô Î∞±ÏóÖ: ÎØ∏ÏÑ§Ï†ï")
            click.echo("üí° 'greeum backup auto --schedule daily' Î°ú ÏÑ§Ï†ïÌïòÏÑ∏Ïöî")
            return
        
        with open(config_file, 'r', encoding='utf-8') as f:
            config = json.load(f)
        
        status_emoji = "üü¢" if config.get('enabled', False) else "üî¥"
        status_text = "ÌôúÏÑ±Ìôî" if config.get('enabled', False) else "ÎπÑÌôúÏÑ±Ìôî"
        
        click.echo(f"{status_emoji} ÏûêÎèô Î∞±ÏóÖ: {status_text}")
        
        if config.get('enabled', False):
            click.echo(f"   [DATE] Ï£ºÍ∏∞: {config.get('schedule', 'unknown')}")
            click.echo(f"   üìÅ ÎîîÎ†âÌÜ†Î¶¨: {config.get('output_dir', 'unknown')}")
            click.echo(f"   üî¢ ÏµúÎåÄ Î≥¥Ï°¥: {config.get('max_backups', 10)}Í∞ú")
            
            last_backup = config.get('last_backup')
            if last_backup:
                click.echo(f"   üïí ÎßàÏßÄÎßâ Î∞±ÏóÖ: {last_backup}")
            else:
                click.echo(f"   üïí ÎßàÏßÄÎßâ Î∞±ÏóÖ: ÏóÜÏùå")
        
        # Î∞±ÏóÖ ÌååÏùº Î™©Î°ù
        backup_pattern = str(backup_dir / "auto_backup_*.json")
        backup_files = sorted(glob.glob(backup_pattern), reverse=True)
        
        if backup_files:
            click.echo(f"\nüìã Î∞±ÏóÖ ÌååÏùº ({len(backup_files)}Í∞ú):")
            for backup_file in backup_files[:5]:  # ÏµúÎåÄ 5Í∞úÎßå ÌëúÏãú
                backup_path = Path(backup_file)
                size_mb = backup_path.stat().st_size / (1024 * 1024)
                mtime = datetime.fromtimestamp(backup_path.stat().st_mtime)
                click.echo(f"   ‚Ä¢ {backup_path.name} ({size_mb:.2f} MB, {mtime.strftime('%Y-%m-%d %H:%M')})")
            
            if len(backup_files) > 5:
                click.echo(f"   ... Î∞è {len(backup_files) - 5}Í∞ú Îçî")
        else:
            click.echo("\nüìã Î∞±ÏóÖ ÌååÏùº: ÏóÜÏùå")
            
    except Exception as e:
        click.echo(f"üí• ÏûêÎèô Î∞±ÏóÖ ÏÉÅÌÉú ÌôïÏù∏ Ïã§Ìå®: {e}")


# v2.6.1 Restore ÏÑúÎ∏åÎ™ÖÎ†πÏñ¥Îì§
@restore.command()
@click.argument('backup_file', type=click.Path(exists=True))
@click.option('--from-date', help='ÏãúÏûë ÎÇ†Ïßú (YYYY-MM-DD)')
@click.option('--to-date', help='ÎÅù ÎÇ†Ïßú (YYYY-MM-DD)')  
@click.option('--keywords', help='ÌÇ§ÏõåÎìú ÌïÑÌÑ∞ (ÏâºÌëúÎ°ú Íµ¨Î∂Ñ)')
@click.option('--layers', help='Í≥ÑÏ∏µ ÌïÑÌÑ∞ (working,stm,ltm Ï§ë ÏÑ†ÌÉù)')
@click.option('--importance-min', type=float, help='ÏµúÏÜå Ï§ëÏöîÎèÑ (0.0-1.0)')
@click.option('--importance-max', type=float, help='ÏµúÎåÄ Ï§ëÏöîÎèÑ (0.0-1.0)')
@click.option('--tags', help='ÌÉúÍ∑∏ ÌïÑÌÑ∞ (ÏâºÌëúÎ°ú Íµ¨Î∂Ñ)')
@click.option('--merge/--replace', default=False, help='Î≥ëÌï© Î™®Îìú (Í∏∞Î≥∏: ÍµêÏ≤¥)')
@click.option('--preview/--execute', default=True, help='ÎØ∏Î¶¨Î≥¥Í∏∞Îßå ÌëúÏãú (Í∏∞Î≥∏: ÎØ∏Î¶¨Î≥¥Í∏∞)')
def from_file(
    backup_file: str,
    from_date: str,
    to_date: str, 
    keywords: str,
    layers: str,
    importance_min: float,
    importance_max: float,
    tags: str,
    merge: bool,
    preview: bool
):
    """Î∞±ÏóÖ ÌååÏùºÎ°úÎ∂ÄÌÑ∞ Î©îÎ™®Î¶¨ Î≥µÏõê"""
    try:
        from ..core.backup_restore import MemoryRestoreEngine, RestoreFilter
        # from ..core.hierarchical_memory import HierarchicalMemorySystem  # REMOVED
        from ..core.database_manager import DatabaseManager
        # from ..core.memory_layer import MemoryLayerType  # REMOVED
        from datetime import datetime
        
        # Î≥µÏõê ÌïÑÌÑ∞ ÏÉùÏÑ±
        date_from = None
        if from_date:
            try:
                date_from = datetime.strptime(from_date, '%Y-%m-%d')
            except ValueError:
                click.echo(f"‚ö†Ô∏è ÏûòÎ™ªÎêú ÏãúÏûë ÎÇ†Ïßú ÌòïÏãù: {from_date}")
        
        date_to = None
        if to_date:
            try:
                date_to = datetime.strptime(to_date, '%Y-%m-%d') 
            except ValueError:
                click.echo(f"‚ö†Ô∏è ÏûòÎ™ªÎêú ÎÅù ÎÇ†Ïßú ÌòïÏãù: {to_date}")
        
        keyword_list = None
        if keywords:
            keyword_list = [kw.strip() for kw in keywords.split(',') if kw.strip()]
        
        layer_list = None
        if layers:
            # Simplified layer mapping without MemoryLayerType enum
            layer_names = [layer.strip().lower() for layer in layers.split(',')]
            layer_list = layer_names  # Just pass as strings
        
        tag_list = None
        if tags:
            tag_list = [tag.strip() for tag in tags.split(',') if tag.strip()]
        
        filter_config = RestoreFilter(
            date_from=date_from,
            date_to=date_to,
            keywords=keyword_list,
            layers=layer_list,
            importance_min=importance_min,
            importance_max=importance_max,
            tags=tag_list
        )
        
        # Í≥ÑÏ∏µÏ†Å Î©îÎ™®Î¶¨ ÏãúÏä§ÌÖú Ï¥àÍ∏∞Ìôî - SIMPLIFIED
        db_manager = DatabaseManager()
        # HierarchicalMemorySystem removed - using DatabaseManager directly
        
        restore_engine = MemoryRestoreEngine(system)
        
        if preview:
            # ÎØ∏Î¶¨Î≥¥Í∏∞ ÌëúÏãú
            click.echo("üîç Î≥µÏõê ÎØ∏Î¶¨Î≥¥Í∏∞Î•º ÏÉùÏÑ±Ìï©ÎãàÎã§...")
            preview_text = restore_engine.preview_restore(backup_file, filter_config)
            click.echo(preview_text)
            
            if click.confirm('Î≥µÏõêÏùÑ ÏßÑÌñâÌïòÏãúÍ≤†ÏäµÎãàÍπå?'):
                preview = False  # Ïã§Ï†ú Î≥µÏõêÏúºÎ°ú Ï†ÑÌôò
            else:
                click.echo("Î≥µÏõêÏù¥ Ï∑®ÏÜåÎêòÏóàÏäµÎãàÎã§")
                return
        
        if not preview:
            # Ïã§Ï†ú Î≥µÏõê Ïã§Ìñâ
            click.echo("[PROCESS] Î©îÎ™®Î¶¨ Î≥µÏõêÏùÑ ÏãúÏûëÌï©ÎãàÎã§...")
            
            result = restore_engine.restore_from_backup(
                backup_file=backup_file,
                filter_config=filter_config,
                merge_mode=merge,
                dry_run=False
            )
            
            # Í≤∞Í≥º ÌëúÏãú
            if result.success:
                click.echo("‚úÖ Î≥µÏõê ÏôÑÎ£å!")
                click.echo(f"üìä Î≥µÏõê Í≤∞Í≥º:")
                click.echo(f"   [MEMORY] Working Memory: {result.working_count}Í∞ú")
                click.echo(f"   [FAST] STM: {result.stm_count}Í∞ú") 
                click.echo(f"   üèõÔ∏è  LTM: {result.ltm_count}Í∞ú")
                click.echo(f"   [IMPROVE] Ï¥ù Ï≤òÎ¶¨: {result.total_processed}Í∞ú")
                click.echo(f"   ‚è±Ô∏è  ÏÜåÏöî ÏãúÍ∞Ñ: {result.execution_time:.2f}Ï¥à")
                
                if result.error_count > 0:
                    click.echo(f"   ‚ö†Ô∏è  Ïò§Î•ò: {result.error_count}Í∞ú")
                    for error in result.errors[:5]:  # ÏµúÎåÄ 5Í∞ú Ïò§Î•òÎßå ÌëúÏãú
                        click.echo(f"      - {error}")
            else:
                click.echo("[ERROR] Î≥µÏõêÏóê Ïã§Ìå®ÌñàÏäµÎãàÎã§")
                for error in result.errors:
                    click.echo(f"   üí• {error}")
                    
    except Exception as e:
        click.echo(f"üí• Î≥µÏõê Ï§ë Ïò§Î•ò: {e}")


# v2.6.2 Dashboard ÏÑúÎ∏åÎ™ÖÎ†πÏñ¥Îì§
@dashboard.command()
@click.option('--output', '-o', help='Í≤∞Í≥ºÎ•º ÌååÏùºÎ°ú Ï†ÄÏû•Ìï† Í≤ΩÎ°ú')
@click.option('--json-format', is_flag=True, help='JSON ÌòïÌÉúÎ°ú Ï∂úÎ†•')
def overview(output: str, json_format: bool):
    """Î©îÎ™®Î¶¨ ÏãúÏä§ÌÖú Ï†ÑÏ≤¥ Í∞úÏöî ÌëúÏãú"""
    try:
        from ..core.dashboard import get_dashboard_system
        import json
        
        dashboard_system = get_dashboard_system()
        overview_data = dashboard_system.get_overview()
        
        if json_format or output:
            # JSON ÌòïÌÉúÎ°ú Ï∂úÎ†•
            json_output = json.dumps(overview_data, indent=2, ensure_ascii=False)
            
            if output:
                with open(output, 'w', encoding='utf-8') as f:
                    f.write(json_output)
                click.echo(f"‚úÖ ÎåÄÏãúÎ≥¥Îìú Î¶¨Ìè¨Ìä∏ Ï†ÄÏû•Îê®: {output}")
            else:
                click.echo(json_output)
        else:
            # ÏÇ¨Ïö©Ïûê ÏπúÌôîÏ†Å ÌòïÌÉúÎ°ú Ï∂úÎ†•
            _display_dashboard_overview(overview_data)
            
    except Exception as e:
        click.echo(f"üí• ÎåÄÏãúÎ≥¥Îìú Í∞úÏöî ÏÉùÏÑ± Ïã§Ìå®: {e}")


@dashboard.command()
@click.option('--format', 'output_format', type=click.Choice(['simple', 'detailed', 'json']), 
              default='simple', help='Ï∂úÎ†• ÌòïÌÉú')
def health(output_format: str):
    """ÏãúÏä§ÌÖú Í±¥Í∞ïÎèÑ ÌôïÏù∏"""
    try:
        from ..core.dashboard import get_dashboard_system
        import json
        
        dashboard_system = get_dashboard_system()
        health_data = dashboard_system.get_system_health()
        
        if output_format == 'json':
            click.echo(json.dumps(health_data.__dict__, indent=2, ensure_ascii=False, default=str))
        elif output_format == 'detailed':
            _display_health_detailed(health_data)
        else:
            _display_health_simple(health_data)
            
    except Exception as e:
        click.echo(f"üí• ÏãúÏä§ÌÖú Í±¥Í∞ïÎèÑ ÌôïÏù∏ Ïã§Ìå®: {e}")


@dashboard.command()
@click.option('--output', '-o', required=True, help='Î¶¨Ìè¨Ìä∏ ÌååÏùº Ï†ÄÏû• Í≤ΩÎ°ú')
@click.option('--include-details/--no-details', default=True, 
              help='ÏÉÅÏÑ∏ Í≥ÑÏ∏µ Î∂ÑÏÑù Ìè¨Ìï® Ïó¨Î∂Ä')
def export(output: str, include_details: bool):
    """ÏôÑÏ†ÑÌïú ÎåÄÏãúÎ≥¥Îìú Î¶¨Ìè¨Ìä∏ ÎÇ¥Î≥¥ÎÇ¥Í∏∞"""
    try:
        from ..core.dashboard import get_dashboard_system
        from pathlib import Path
        
        dashboard_system = get_dashboard_system()
        
        success = dashboard_system.export_dashboard_report(
            output_path=output,
            include_details=include_details
        )
        
        if success:
            file_size = Path(output).stat().st_size / 1024  # KB
            click.echo(f"‚úÖ ÎåÄÏãúÎ≥¥Îìú Î¶¨Ìè¨Ìä∏ ÏÉùÏÑ± ÏôÑÎ£å: {output} ({file_size:.1f} KB)")
            
            if include_details:
                click.echo("üìä ÏÉÅÏÑ∏ Í≥ÑÏ∏µ Î∂ÑÏÑù Ìè¨Ìï®")
            else:
                click.echo("üìã Í∏∞Î≥∏ Í∞úÏöîÎßå Ìè¨Ìï®")
        else:
            click.echo("[ERROR] Î¶¨Ìè¨Ìä∏ ÏÉùÏÑ±Ïóê Ïã§Ìå®ÌñàÏäµÎãàÎã§")
            
    except Exception as e:
        click.echo(f"üí• Î¶¨Ìè¨Ìä∏ ÎÇ¥Î≥¥ÎÇ¥Í∏∞ Ïã§Ìå®: {e}")


# ÎåÄÏãúÎ≥¥Îìú Ï∂úÎ†• Ìó¨Ìçº Ìï®ÏàòÎì§
def _display_dashboard_overview(data: dict):
    """ÏÇ¨Ïö©Ïûê ÏπúÌôîÏ†Å ÎåÄÏãúÎ≥¥Îìú Í∞úÏöî Ï∂úÎ†•"""
    stats = data['memory_stats']
    health = data['system_health']
    
    click.echo("[MEMORY] Greeum Memory Dashboard")
    click.echo("=" * 50)
    
    # Í∏∞Î≥∏ ÌÜµÍ≥Ñ
    click.echo(f"üìä Ï†ÑÏ≤¥ Î©îÎ™®Î¶¨: {stats['total_memories']}Í∞ú")
    click.echo(f"   [MEMORY] Working Memory: {stats['working_memory_count']}Í∞ú")
    click.echo(f"   [FAST] STM: {stats['stm_count']}Í∞ú")
    click.echo(f"   üèõÔ∏è  LTM: {stats['ltm_count']}Í∞ú")
    
    click.echo()
    
    # ÏãúÏä§ÌÖú Í±¥Í∞ïÎèÑ
    health_percent = health['overall_health'] * 100
    health_emoji = "üü¢" if health_percent >= 80 else "üü°" if health_percent >= 60 else "üî¥"
    click.echo(f"{health_emoji} ÏãúÏä§ÌÖú Í±¥Í∞ïÎèÑ: {health_percent:.1f}%")
    
    # Ïö©Îüâ Ï†ïÎ≥¥
    click.echo(f"üíæ Ï¥ù Ïö©Îüâ: {stats['total_size_mb']:.1f} MB")
    click.echo(f"[FAST] ÌèâÍ∑† Í≤ÄÏÉâ ÏãúÍ∞Ñ: {health['avg_search_time_ms']:.1f}ms")
    
    # Í≤ΩÍ≥†ÏÇ¨Ìï≠
    if health['warnings']:
        click.echo("\n‚ö†Ô∏è  Ï£ºÏùòÏÇ¨Ìï≠:")
        for warning in health['warnings']:
            click.echo(f"   ‚Ä¢ {warning}")
    
    # Í∂åÏû•ÏÇ¨Ìï≠
    if health['recommendations']:
        click.echo("\nüí° Í∂åÏû•ÏÇ¨Ìï≠:")
        for rec in health['recommendations']:
            click.echo(f"   ‚Ä¢ {rec}")
    
    # Ïù∏Í∏∞ ÌÇ§ÏõåÎìú
    if 'popular_keywords' in stats:
        click.echo("\nüî• Ïù∏Í∏∞ ÌÇ§ÏõåÎìú:")
        for keyword, count in stats['popular_keywords'][:5]:
            click.echo(f"   #{keyword} ({count}Ìöå)")


def _display_health_simple(health):
    """Í∞ÑÎã®Ìïú Í±¥Í∞ïÎèÑ Ï∂úÎ†•"""
    health_percent = health.overall_health * 100
    health_emoji = "üü¢" if health_percent >= 80 else "üü°" if health_percent >= 60 else "üî¥"
    
    click.echo(f"{health_emoji} ÏãúÏä§ÌÖú Í±¥Í∞ïÎèÑ: {health_percent:.1f}%")
    
    if health_percent >= 80:
        click.echo("‚úÖ ÏãúÏä§ÌÖúÏù¥ Ï†ïÏÉÅÏ†ÅÏúºÎ°ú ÏûëÎèôÌïòÍ≥† ÏûàÏäµÎãàÎã§")
    elif health_percent >= 60:
        click.echo("‚ö†Ô∏è  ÏãúÏä§ÌÖúÏóê ÏïΩÍ∞ÑÏùò Ï£ºÏùòÍ∞Ä ÌïÑÏöîÌï©ÎãàÎã§")
    else:
        click.echo("üî¥ ÏãúÏä§ÌÖú Ï†êÍ≤ÄÏù¥ ÌïÑÏöîÌï©ÎãàÎã§")


def _display_health_detailed(health):
    """ÏÉÅÏÑ∏Ìïú Í±¥Í∞ïÎèÑ Ï∂úÎ†•"""
    _display_health_simple(health)
    
    click.echo(f"\n[IMPROVE] ÏÑ±Îä• ÏßÄÌëú:")
    click.echo(f"   Í≤ÄÏÉâ ÏÜçÎèÑ: {health.avg_search_time_ms:.1f}ms")
    click.echo(f"   Î©îÎ™®Î¶¨ ÏÇ¨Ïö©Îüâ: {health.memory_usage_mb:.1f}MB")
    click.echo(f"   Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ ÌÅ¨Í∏∞: {health.database_size_mb:.1f}MB")
    
    click.echo(f"\nüéØ ÌíàÏßà ÏßÄÌëú:")
    click.echo(f"   ÌèâÍ∑† ÌíàÏßà Ï†êÏàò: {health.avg_quality_score:.2f}")
    click.echo(f"   Ï§ëÎ≥µÎ•†: {health.duplicate_rate * 100:.1f}%")
    click.echo(f"   ÏäπÍ∏â ÏÑ±Í≥µÎ•†: {health.promotion_success_rate * 100:.1f}%")
    
    if health.warnings:
        click.echo(f"\n‚ö†Ô∏è  Í≤ΩÍ≥†:")
        for warning in health.warnings:
            click.echo(f"   ‚Ä¢ {warning}")
    
    if health.recommendations:
        click.echo(f"\nüí° Í∂åÏû•ÏÇ¨Ìï≠:")
        for rec in health.recommendations:
            click.echo(f"   ‚Ä¢ {rec}")


# v2.7.0: Causal Reasoning Commands
@main.group()
def causal():
    """Causal reasoning and relationship analysis commands"""
    pass


@causal.command()
@click.argument('block_id', type=int)
@click.option('--format', 'output_format', type=click.Choice(['simple', 'detailed', 'json']), 
              default='simple', help='Output format')
def relationships(block_id: int, output_format: str):
    """Show causal relationships for a specific memory block"""
    try:
        from greeum.core import DatabaseManager
        from greeum.core.block_manager import BlockManager
        
        db_manager = DatabaseManager()
        block_manager = BlockManager(db_manager)
        
        # Get the block info
        block = db_manager.get_block(block_id)
        if not block:
            click.echo(f"‚ùå Block #{block_id} not found", err=True)
            return
        
        # Get causal relationships
        relationships = block_manager.get_causal_relationships(block_id)
        
        if output_format == 'json':
            import json
            click.echo(json.dumps({
                'block_id': block_id,
                'relationships': relationships
            }, indent=2, ensure_ascii=False))
            return
        
        if not relationships:
            click.echo(f"üîç No causal relationships found for block #{block_id}")
            return
        
        click.echo(f"üîó Causal relationships for block #{block_id}:")
        click.echo(f"   Context: {block['context'][:60]}...")
        click.echo()
        
        for i, rel in enumerate(relationships, 1):
            source_id = rel['source_block_id']
            target_id = rel['target_block_id']
            relation_type = rel['relation_type']
            confidence = rel['confidence']
            
            # Determine direction
            if source_id == block_id:
                direction = "‚Üí"
                other_id = target_id
                role = "Causes"
            else:
                direction = "‚Üê"
                other_id = source_id
                role = "Caused by"
            
            # Get other block context
            other_block = db_manager.get_block(other_id)
            other_context = other_block['context'][:50] + "..." if other_block else "Unknown"
            
            confidence_emoji = "üî•" if confidence >= 0.8 else "‚ö°" if confidence >= 0.6 else "üí°"
            
            click.echo(f"{i}. {confidence_emoji} {role} Block #{other_id} ({confidence:.2f})")
            click.echo(f"   {direction} {other_context}")
            click.echo(f"   Type: {relation_type}")
            
            if output_format == 'detailed':
                import json
                keywords = json.loads(rel.get('keywords_matched', '[]'))
                if keywords:
                    click.echo(f"   Keywords: {', '.join(keywords)}")
                
                temporal_gap = rel.get('temporal_gap_hours')
                if temporal_gap is not None:
                    if temporal_gap < 1:
                        gap_str = f"{temporal_gap * 60:.0f} minutes"
                    elif temporal_gap < 24:
                        gap_str = f"{temporal_gap:.1f} hours"
                    else:
                        gap_str = f"{temporal_gap / 24:.1f} days"
                    click.echo(f"   Time gap: {gap_str}")
            
            click.echo()
        
    except Exception as e:
        click.echo(f"‚ùå Error analyzing relationships: {e}", err=True)


@causal.command()
@click.argument('start_block_id', type=int)
@click.option('--depth', default=3, help='Maximum chain depth to explore')
@click.option('--format', 'output_format', type=click.Choice(['simple', 'detailed', 'json']), 
              default='simple', help='Output format')
def chain(start_block_id: int, depth: int, output_format: str):
    """Find causal relationship chains starting from a block"""
    try:
        from greeum.core import DatabaseManager
        from greeum.core.block_manager import BlockManager
        
        db_manager = DatabaseManager()
        block_manager = BlockManager(db_manager)
        
        # Get the starting block
        start_block = db_manager.get_block(start_block_id)
        if not start_block:
            click.echo(f"‚ùå Start block #{start_block_id} not found", err=True)
            return
        
        # Find causal chain
        chain_results = block_manager.find_causal_chain(start_block_id, depth)
        
        if output_format == 'json':
            import json
            click.echo(json.dumps({
                'start_block_id': start_block_id,
                'chain': chain_results
            }, indent=2, ensure_ascii=False))
            return
        
        if not chain_results:
            click.echo(f"üîç No causal chains found starting from block #{start_block_id}")
            return
        
        click.echo(f"üîó Causal chain starting from block #{start_block_id}:")
        click.echo(f"   Start: {start_block['context'][:60]}...")
        click.echo()
        
        # Group by depth for better visualization
        by_depth = {}
        for item in chain_results:
            d = item['depth']
            if d not in by_depth:
                by_depth[d] = []
            by_depth[d].append(item)
        
        for depth_level in sorted(by_depth.keys()):
            items = by_depth[depth_level]
            indent = "  " * (depth_level + 1)
            
            for item in items:
                confidence = item['confidence']
                target_block = item['target_block']
                target_context = target_block['context'][:50] + "..."
                
                confidence_emoji = "üî•" if confidence >= 0.8 else "‚ö°" if confidence >= 0.6 else "üí°"
                
                click.echo(f"{indent}‚Üì {confidence_emoji} Block #{item['target_id']} ({confidence:.2f})")
                click.echo(f"{indent}   {target_context}")
                
                if output_format == 'detailed':
                    click.echo(f"{indent}   Type: {item['relation_type']}")
        
    except Exception as e:
        click.echo(f"‚ùå Error finding causal chain: {e}", err=True)


@causal.command()
@click.option('--format', 'output_format', type=click.Choice(['simple', 'detailed', 'json']), 
              default='simple', help='Output format')
def stats(output_format: str):
    """Show causal reasoning detection statistics"""
    try:
        from greeum.core import DatabaseManager
        from greeum.core.block_manager import BlockManager
        
        db_manager = DatabaseManager()
        block_manager = BlockManager(db_manager)
        
        # Get statistics
        statistics = block_manager.get_causal_statistics()
        
        if 'error' in statistics:
            click.echo(f"‚ùå {statistics['error']}", err=True)
            return
        
        if output_format == 'json':
            import json
            click.echo(json.dumps(statistics, indent=2, ensure_ascii=False))
            return
        
        click.echo("üìä Causal Reasoning Statistics")
        click.echo("=" * 35)
        
        # Detection summary
        total_analyzed = statistics.get('total_analyzed', 0)
        relationships_found = statistics.get('relationships_found', 0)
        accuracy_estimate = statistics.get('accuracy_estimate', 0.0)
        
        click.echo(f"\nüîç Detection Summary:")
        click.echo(f"   Total blocks analyzed: {total_analyzed}")
        click.echo(f"   Relationships found: {relationships_found}")
        if total_analyzed > 0:
            detection_rate = (relationships_found / total_analyzed) * 100
            click.echo(f"   Detection rate: {detection_rate:.1f}%")
        click.echo(f"   Estimated accuracy: {accuracy_estimate:.1f}%")
        
        # Confidence distribution
        high_conf = statistics.get('high_confidence', 0)
        medium_conf = statistics.get('medium_confidence', 0)
        low_conf = statistics.get('low_confidence', 0)
        
        click.echo(f"\nüìà Confidence Distribution:")
        click.echo(f"   üî• High (‚â•0.8): {high_conf}")
        click.echo(f"   ‚ö° Medium (0.5-0.8): {medium_conf}")
        click.echo(f"   üí° Low (<0.5): {low_conf}")
        
        # Relationship types
        by_type = statistics.get('by_type', {})
        if by_type:
            click.echo(f"\nüè∑Ô∏è  Relationship Types:")
            for rel_type, count in by_type.items():
                if count > 0:
                    click.echo(f"   {rel_type}: {count}")
        
        # Database statistics
        total_stored = statistics.get('total_stored', 0)
        stored_dist = statistics.get('stored_confidence_distribution', {})
        
        if output_format == 'detailed':
            click.echo(f"\nüíæ Storage Statistics:")
            click.echo(f"   Total stored relationships: {total_stored}")
            
            if stored_dist:
                click.echo(f"   Stored confidence distribution:")
                for level, count in stored_dist.items():
                    click.echo(f"     {level}: {count}")
        
    except Exception as e:
        click.echo(f"‚ùå Error getting causal statistics: {e}", err=True)


# Import and register graph commands
try:
    from .graph import graph_group
    main.commands.pop('graph', None)
    main.add_command(graph_group, name='graph')
except ImportError:
    pass  # Graph CLI not available

# Import and register metrics commands
try:
    from .metrics_cli import metrics_group
    # Replace the empty metrics group with the real one
    main.commands.pop('metrics', None)
    main.add_command(metrics_group, name='metrics')
except ImportError:
    pass  # Metrics CLI not available

# Import and register validate commands  
try:
    from .validate_cli import validate_group
    # Replace the empty validate group with the real one
    main.commands.pop('validate', None)
    main.add_command(validate_group, name='validate')
except ImportError:
    pass  # Validate CLI not available


if __name__ == '__main__':
    main()
