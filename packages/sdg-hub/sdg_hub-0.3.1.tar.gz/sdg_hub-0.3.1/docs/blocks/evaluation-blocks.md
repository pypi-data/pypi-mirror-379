# Evaluation Blocks

Evaluation blocks provide quality assessment and scoring capabilities for generated content. These blocks help measure the quality, accuracy, and relevance of synthetic data, enabling you to implement quality gates and iterative improvement workflows.

## ðŸ“Š Available Evaluation Blocks

### EvaluateFaithfulnessBlock
Assesses the factual accuracy and consistency of generated content against source materials or ground truth.

### EvaluateRelevancyBlock
Measures how relevant generated content is to the given context, query, or requirements.

### VerifyQuestionBlock
Validates the quality and appropriateness of generated questions, checking for clarity, answerability, and relevance.


## ðŸš€ Next Steps

- **[LLM Blocks](llm-blocks.md)** - AI-powered text generation
- **[Filtering Blocks](filtering-blocks.md)** - Quality control and data validation
- **[Transform Blocks](transform-blocks.md)** - Data manipulation and reshaping
- **[Flow Integration](../flows/overview.md)** - Combine evaluation into complete pipelines