before_script:
  - git lfs pull


variables:
  MAMBA_ROOT_PREFIX: "/opt/conda"


stages:
  - test
  - deploy
  - cleanup


# run all tests only on the main branch
test_s2downloader:
  stage: test
  coverage: '/TOTAL\s+\d+\s+\d+\s+(\d+%)/'
  script:
    - source activate ci_env

    # install missing dependencies on the CI container
    - mamba env update --name ci_env --file tests/CI_docker/context/environment_s2downloader.yml

    # run tests
    - make pytest

    # create the docs
    - make docs

  artifacts:
    expose_as: 'Test and coverage report'
    paths:
    - htmlcov/
    - report.html
    - docs/_build/html/
    reports:
      coverage_report:
        coverage_format: cobertura
        path: coverage.xml
      junit: report.xml
    expire_in: 30 days
  only:
    - main
    - staging


# run a subset of tests on every branch
test_subset:
  stage: test
  coverage: '/TOTAL\s+\d+\s+\d+\s+(\d+%)/'
  script:
    - source activate ci_env

    # install missing dependencies on the CI container
    - mamba env update --name ci_env --file tests/CI_docker/context/environment_s2downloader.yml

    # run tests
    - pytest -m "subset" tests --verbosity=3 --color=yes --tb=short --cov=s2downloader --cov-report html:htmlcov --cov-report term-missing --cov-report xml:coverage.xml --template=html1/index.html --report=report.html --junitxml report.xml

    # create the docs
    - make docs

  artifacts:
    expose_as: 'Test and coverage report'
    paths:
    - htmlcov/
    - report.html
    - docs/_build/html/
    reports:
      coverage_report:
        coverage_format: cobertura
        path: coverage.xml
      junit: report.xml
    expire_in: 30 days
    when: always
  except:
    - main
    - staging

test_styles:
  stage: test
  script:
    - source activate ci_env
    # install missing dependencies in the CI container
    - mamba env update --name ci_env --file tests/CI_docker/context/environment_s2downloader.yml
    # run style checks and save output to file while not blocking a commit if it fails
    - make lint
  artifacts:
    paths:
        - tests/linting/pre-commit-output.txt
    when: always


test_urls:
  stage: test
  script:
    - source activate ci_env
    - make urlcheck
  when: always


test_s2downloader_install:
  stage: test
  script:
    - source activate

    # update base environment
    - conda update -n base -c conda-forge --all

    # create s2downloader environment from environment_s2downloader.yml
    - mamba env create --name s2downloader_testinstall -f tests/CI_docker/context/environment_s2downloader.yml
    - conda activate s2downloader_testinstall

    # run installer
    - pip install .

    # check if all dependencies are correctly installed
    - pip check

    # test if its importable
    - cd ..
    - ls
    - python -c "import s2downloader; print(s2downloader)"
  only:
    - main
    - staging


pages:  # this job must be called 'pages' to advise GitLab to upload content to GitLab Pages
  stage: deploy
  dependencies:
    - test_s2downloader
  script:
    # Create the public directory
    - rm -rf public
    - mkdir public
    - mkdir -p public/doc
    - mkdir -p public/doc/_static/
    - mkdir -p public/doc/docs/images
    - mkdir -p public/images/
    - mkdir -p public/coverage
    - mkdir -p public/test_reports

    # Copy over the docs
    - cp docs/index.html public/
    - cp -r docs/_static/* public/doc/_static/
    - cp -r docs/_build/html/* public/doc/
    - cp -r docs/images/* public/images/
    - cp -r docs/images/* public/doc/docs/images/

    # Copy over the coverage reports
    - cp -r htmlcov/* public/coverage/

    # Copy over the test reports
    - cp report.html public/test_reports/

    # Check if everything is working great
    - ls -al public
    - ls -al public/doc
    - ls -al public/coverage
    - ls -al public/test_reports
  artifacts:
    paths:
      - public
    expire_in: 30 days
  only:
    - documentation
    - main
    - staging

deploy_pypi:
  stage: deploy
  dependencies:
    - test_s2downloader
  script:
    - source activate ci_env
    - pip install -U twine build pkginfo packaging
    - python -m build --sdist
    - twine check dist/*
    - twine upload dist/*  # requires creds as environment variables
  only:
    - /^v\d+\.\d+\.\d+([abc]\d*)?$/  # PEP-440 compliant version (tags)
  except:
    - dev

create_github_release:
  stage: deploy
  dependencies:
     - test_s2downloader
  script:
     - bash ./.github/create_release_from_gitlab_ci.sh  # uses environment variables set in the UI
  only:
      - /^v\d+\.\d+\.\d+([abc]\d*)?$/  # PEP-440 compliant version (tags)
  except:
      - dev

send_to_zenodo:
  stage: deploy
  dependencies:
      - test_s2downloader
  script:
      - source activate ci_env
      - if [[ ! $CI_COMMIT_TAG =~ ^v?[0-9]+\.[0-9]+ ]]; then exit 0; fi
      - pip install -U gitlab2zenodo
      - git archive --format zip --output s2downloader-${CI_COMMIT_TAG}.zip ${CI_COMMIT_TAG}
      - g2z-send -t $zenodo_token -i $zenodo_record -m .zenodo.json s2downloader-${CI_COMMIT_TAG}.zip -p
  only:
      - /^v\d+\.\d+\.\d+([abc]\d*)?$/
  except:
      - dev


gitleaks: # Gitleaks security scanner
  image:
    name: zricethezav/gitleaks:latest
    entrypoint: [""]
  stage: test
  before_script: []  # prevents git lfs pull
  script:
    - gitleaks git --platform gitlab --max-decode-depth 5 --verbose --redact $CI_PROJECT_DIR
