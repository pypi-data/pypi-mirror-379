#!/usr/bin/env python3
"""
æ¯æ—¥æäº¤ä»£ç è¡Œæ•°ç»Ÿè®¡è„šæœ¬
è¯¥è„šæœ¬ç”¨äºç»Ÿè®¡Gitä»“åº“ä¸­masteråˆ†æ”¯æ¯å¤©æäº¤çš„ä»£ç è¡Œæ•°ï¼ŒåŒ…æ‹¬æ–°å¢è¡Œæ•°ã€åˆ é™¤è¡Œæ•°å’Œå‡€å˜åŒ–è¡Œæ•°

ä½¿ç”¨æ–¹æ³•:
1. ä½œä¸ºå‘½ä»¤è¡Œå·¥å…·ï¼š
   pixelarraylib summary_code_count --since="2025-05-09"
   pixelarraylib summary_code_count --author="å¼ ä¸‰"
   pixelarraylib summary_code_count --output=stats.csv
   pixelarraylib summary_code_count --file-types="py,js,vue"

2. ä½œä¸ºPythonæ¨¡å—ï¼š
   from pixelarraylib.scripts.summary_code_count import main
   main()
"""

import os
import subprocess
import argparse
from datetime import datetime, timedelta
from collections import defaultdict
import pandas as pd


class GitCommitStatsAnalyzer:
    def __init__(self, repo_path="."):
        self.repo_path = repo_path
        self.daily_stats = defaultdict(
            lambda: {
                "commits": 0,
                "added_lines": 0,
                "deleted_lines": 0,
                "net_lines": 0,
                "authors": set(),
                "files_changed": 0,
            }
        )

    def is_git_repo(self):
        """æ£€æŸ¥æ˜¯å¦ä¸ºgitä»“åº“"""
        return os.path.exists(os.path.join(self.repo_path, ".git"))

    def run_git_command(self, command):
        """æ‰§è¡Œgitå‘½ä»¤å¹¶è¿”å›ç»“æœ"""
        try:
            result = subprocess.run(
                command,
                shell=True,
                cwd=self.repo_path,
                capture_output=True,
                text=True,
                check=True,
            )
            return result.stdout.strip()
        except subprocess.CalledProcessError as e:
            # å¯¹äºæŸäº›é¢„æœŸçš„é”™è¯¯ï¼ˆå¦‚ç¬¬ä¸€ä¸ªæäº¤ï¼‰ï¼Œä¸æ‰“å°é”™è¯¯ä¿¡æ¯
            if "unknown revision" in e.stderr or "ambiguous argument" in e.stderr:
                return ""
            else:
                print(f"Gitå‘½ä»¤æ‰§è¡Œå¤±è´¥: {command}")
                print(f"é”™è¯¯ä¿¡æ¯: {e.stderr}")
            return ""

    def get_commit_list(self, since_date=None, until_date=None, author=None):
        """è·å–masteråˆ†æ”¯çš„æäº¤åˆ—è¡¨"""
        command = 'git log master --oneline --pretty=format:"%H|%ad|%an" --date=short'

        if since_date:
            command += f' --since="{since_date}"'
        if until_date:
            command += f' --until="{until_date}"'
        if author:
            command += f' --author="{author}"'

        output = self.run_git_command(command)
        commits = []

        for line in output.split("\n"):
            if line:
                parts = line.split("|")
                if len(parts) >= 3:
                    commit_hash = parts[0]
                    commit_date = parts[1]
                    commit_author = parts[2]
                    commits.append(
                        {
                            "hash": commit_hash,
                            "date": commit_date,
                            "author": commit_author,
                        }
                    )

        return commits

    def get_commit_stats(self, commit_hash, file_types=None):
        """è·å–å•ä¸ªæäº¤çš„ç»Ÿè®¡ä¿¡æ¯"""
        # é¦–å…ˆæ£€æŸ¥æ˜¯å¦æœ‰çˆ¶æäº¤
        parent_check = self.run_git_command(f"git rev-parse {commit_hash}^ 2>/dev/null || echo 'NO_PARENT'")
        
        if parent_check.strip() == "NO_PARENT":
            # è¿™æ˜¯ç¬¬ä¸€ä¸ªæäº¤ï¼Œæ²¡æœ‰çˆ¶æäº¤ï¼Œä½¿ç”¨ç©ºæ ‘ä½œä¸ºæ¯”è¾ƒåŸºå‡†
            command = f"git diff --numstat 4b825dc642cb6eb9a060e54bf8d69288fbee4904 {commit_hash}"
        else:
            # æœ‰çˆ¶æäº¤ï¼Œæ­£å¸¸æ¯”è¾ƒ
            command = f"git diff --numstat {commit_hash}^..{commit_hash}"
        
        output = self.run_git_command(command)

        added_lines = 0
        deleted_lines = 0
        files_changed = 0

        for line in output.split("\n"):
            if line:
                parts = line.split("\t")
                if len(parts) >= 3:
                    try:
                        added = int(parts[0]) if parts[0] != "-" else 0
                        deleted = int(parts[1]) if parts[1] != "-" else 0
                        filename = parts[2]

                        # å¦‚æœæŒ‡å®šäº†æ–‡ä»¶ç±»å‹è¿‡æ»¤
                        if file_types:
                            file_ext = filename.split(".")[-1].lower()
                            if file_ext not in file_types:
                                continue

                        added_lines += added
                        deleted_lines += deleted
                        files_changed += 1
                    except (ValueError, IndexError):
                        continue

        return {
            "added_lines": added_lines,
            "deleted_lines": deleted_lines,
            "net_lines": added_lines - deleted_lines,
            "files_changed": files_changed,
        }

    def analyze_commits(
        self, since_date=None, until_date=None, author=None, file_types=None
    ):
        """åˆ†æmasteråˆ†æ”¯çš„æäº¤ç»Ÿè®¡"""
        if not self.is_git_repo():
            print("é”™è¯¯ï¼šå½“å‰ç›®å½•ä¸æ˜¯Gitä»“åº“")
            return False

        print("æ­£åœ¨åˆ†æGit masteråˆ†æ”¯çš„æäº¤å†å²...")
        commits = self.get_commit_list(since_date, until_date, author)

        if not commits:
            print("æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æäº¤")
            return False

        total_commits = len(commits)
        print(f"æ‰¾åˆ° {total_commits} ä¸ªæäº¤ï¼Œæ­£åœ¨ç»Ÿè®¡...")

        for i, commit in enumerate(commits):
            # æ˜¾ç¤ºè¿›åº¦
            if i % 10 == 0 or i == total_commits - 1:
                progress = (i + 1) / total_commits * 100
                print(f"è¿›åº¦: {progress:.1f}% ({i + 1}/{total_commits})")

            commit_date = commit["date"]
            commit_author = commit["author"]

            stats = self.get_commit_stats(commit["hash"], file_types)

            # ç´¯åŠ åˆ°æ—¥ç»Ÿè®¡
            day_stats = self.daily_stats[commit_date]
            day_stats["commits"] += 1
            day_stats["added_lines"] += stats["added_lines"]
            day_stats["deleted_lines"] += stats["deleted_lines"]
            day_stats["net_lines"] += stats["net_lines"]
            day_stats["authors"].add(commit_author)
            day_stats["files_changed"] += stats["files_changed"]

        print("åˆ†æå®Œæˆï¼")
        return True

    def print_stats(self):
        """ä½¿ç”¨pandas DataFrameæ‰“å°ç»Ÿè®¡ç»“æœ"""
        if not self.daily_stats:
            print("æ²¡æœ‰ç»Ÿè®¡æ•°æ®")
            return

        # å‡†å¤‡DataFrameæ•°æ®
        data = []
        all_authors = set()

        # æŒ‰æ—¥æœŸæ’åº
        sorted_dates = sorted(self.daily_stats.keys())

        for date in sorted_dates:
            stats = self.daily_stats[date]
            all_authors.update(stats["authors"])

            data.append(
                {
                    "Date": date,
                    "Commits": stats["commits"],
                    "Added": stats["added_lines"],
                    "Deleted": stats["deleted_lines"],
                    "Net": stats["net_lines"],  # ä¿æŒä¸ºæ•°å­—ç±»å‹
                    "Authors": len(stats["authors"]),
                    "Files": stats["files_changed"],
                    "Author List": ", ".join(sorted(stats["authors"])),
                }
            )

        # åˆ›å»ºDataFrame
        df = pd.DataFrame(data)

        if df.empty:
            print("æ²¡æœ‰ç»Ÿè®¡æ•°æ®")
            return

        # è®¾ç½®pandasæ˜¾ç¤ºé€‰é¡¹
        pd.set_option("display.max_columns", None)
        pd.set_option("display.width", None)
        pd.set_option("display.max_colwidth", 50)

        # å®šä¹‰æ¯åˆ—çš„å®½åº¦ï¼ˆè°ƒæ•´ä¸ºæ›´åˆé€‚çš„å®½åº¦ï¼‰
        column_widths = {
            "Date": 15,  # å¢åŠ å®½åº¦ï¼Œç¡®ä¿æ—¥æœŸå®Œæ•´æ˜¾ç¤º
            "Commits": 12,  # å¢åŠ å®½åº¦ï¼Œè€ƒè™‘æ ‡é¢˜é•¿åº¦
            "Added": 12,  # å¢åŠ å®½åº¦ï¼Œè€ƒè™‘å¤§æ•°å­—
            "Deleted": 12,  # å¢åŠ å®½åº¦ï¼Œè€ƒè™‘å¤§æ•°å­—
            "Net": 12,  # å¢åŠ å®½åº¦ï¼Œè€ƒè™‘ç¬¦å·å’Œå¤§æ•°å­—
            "Authors": 10,  # å¢åŠ å®½åº¦ï¼Œè€ƒè™‘æ ‡é¢˜é•¿åº¦
            "Files": 10,  # å¢åŠ å®½åº¦ï¼Œè€ƒè™‘æ ‡é¢˜é•¿åº¦
        }

        # æ‰“å°ä¸»è¡¨æ ¼ï¼ˆä¸åŒ…å«ä½œè€…åˆ—è¡¨ï¼‰
        display_df = df.drop("Author List", axis=1).copy()

        # æ ¼å¼åŒ–å‡€å˜åŒ–åˆ—ï¼Œæ·»åŠ æ­£è´Ÿå·
        display_df["Net"] = display_df["Net"].apply(
            lambda x: f"+{x}" if x > 0 else str(x)
        )

        # è®¡ç®—æ€»å®½åº¦ï¼ˆåŒ…æ‹¬åˆ—ä¹‹é—´çš„ç©ºæ ¼ï¼‰
        total_width = sum(column_widths.values()) + len(column_widths) - 1

        # æ‰“å°è¡¨å¤´
        print("\n" + "=" * total_width)
        print(f"{'æ¯æ—¥ä»£ç æäº¤ç»Ÿè®¡ (masteråˆ†æ”¯)':^{total_width}}")  # å±…ä¸­æ˜¾ç¤ºæ ‡é¢˜
        print("=" * total_width)

        # æ‰“å°åˆ—æ ‡é¢˜
        header = ""
        for col, width in column_widths.items():
            header += f"{col:^{width}} "  # ä½¿ç”¨^å®ç°å±…ä¸­å¯¹é½
        print(header.rstrip())
        print("-" * total_width)

        # æ‰“å°æ•°æ®è¡Œ
        for _, row in display_df.iterrows():
            line = ""
            for col, width in column_widths.items():
                value = str(row[col])  # è½¬æ¢ä¸ºå­—ç¬¦ä¸²
                if col == "Date":
                    # æ—¥æœŸå·¦å¯¹é½
                    line += f"{value:<{width}} "
                elif col == "Net":
                    # å‡€å˜åŒ–å³å¯¹é½ï¼Œç¡®ä¿ç¬¦å·å¯¹é½
                    line += f"{value:>{width}} "
                else:
                    # å…¶ä»–æ•°å­—å³å¯¹é½
                    line += f"{value:>{width}} "
            print(line.rstrip())

        # è®¡ç®—æ€»è®¡
        total_commits = df["Commits"].sum()
        total_added = df["Added"].sum()
        total_deleted = df["Deleted"].sum()
        total_net = df["Net"].sum()
        total_authors = len(all_authors)
        total_files = df["Files"].sum()

        # æ‰“å°æ€»è®¡è¡Œ
        print("-" * total_width)
        total_net_str = f"+{total_net}" if total_net > 0 else str(total_net)
        total_line = (
            f"{'æ€»è®¡':<{column_widths['Date']}} "
            f"{total_commits:>{column_widths['Commits']}} "
            f"{total_added:>{column_widths['Added']}} "
            f"{total_deleted:>{column_widths['Deleted']}} "
            f"{total_net_str:>{column_widths['Net']}} "
            f"{total_authors:>{column_widths['Authors']}} "
            f"{total_files:>{column_widths['Files']}}"
        )
        print(total_line)

        # ç»Ÿè®¡æ‘˜è¦
        print("\nğŸ“Š ç»Ÿè®¡æ‘˜è¦ (masteråˆ†æ”¯):")
        print(f"  ğŸ“… ç»Ÿè®¡å¤©æ•°: {len(df)} å¤©")
        print(f"  ğŸ”„ æ€»æäº¤æ•°: {total_commits:,}")
        print(f"  â• æ€»æ–°å¢è¡Œæ•°: {total_added:,}")
        print(f"  â– æ€»åˆ é™¤è¡Œæ•°: {total_deleted:,}")
        print(f"  ğŸ“ˆ å‡€å˜åŒ–è¡Œæ•°: {total_net:+,}")
        print(f"  ğŸ‘¥ å‚ä¸ä½œè€…æ•°: {total_authors}")

        if len(df) > 0:
            print(f"  ğŸ“Š å¹³å‡æ¯å¤©æäº¤: {total_commits/len(df):.1f}")
            print(f"  ğŸ“ˆ å¹³å‡æ¯å¤©å‡€å¢: {total_net/len(df):+.1f} è¡Œ")

        # æ˜¾ç¤ºTOPç»Ÿè®¡
        if len(df) > 1:
            print("\nğŸ† TOPç»Ÿè®¡ (masteråˆ†æ”¯):")
            # æœ€æ´»è·ƒçš„ä¸€å¤©
            max_commits_day = df.loc[df["Commits"].idxmax()]
            print(
                f"  ğŸ¥‡ æœ€å¤šæäº¤æ—¥: {max_commits_day['Date']} ({max_commits_day['Commits']} æ¬¡æäº¤)"
            )

            # ä»£ç å˜åŒ–æœ€å¤§çš„ä¸€å¤©
            max_lines_day = df.loc[df["Added"].idxmax()]
            print(
                f"  ğŸ“ æœ€å¤šæ–°å¢æ—¥: {max_lines_day['Date']} (+{max_lines_day['Added']} è¡Œ)"
            )

            # å‡€å¢é•¿æœ€å¤§çš„ä¸€å¤©ï¼ˆä½¿ç”¨åŸå§‹æ•°å€¼ï¼‰
            max_net_day = df.loc[df["Net"].idxmax()]
            net_change_str = (
                f"+{max_net_day['Net']}"
                if max_net_day["Net"] > 0
                else str(max_net_day["Net"])
            )
            print(f"  ğŸš€ æœ€å¤§å‡€å¢æ—¥: {max_net_day['Date']} ({net_change_str} è¡Œ)")

        if all_authors:
            print(f"\nğŸ‘¥ å‚ä¸ä½œè€… (masteråˆ†æ”¯): {', '.join(sorted(all_authors))}")

        # å¦‚æœæ•°æ®é‡ä¸å¤§ï¼Œæ˜¾ç¤ºè¯¦ç»†çš„ä½œè€…åˆ†å¸ƒ
        if len(df) <= 10:
            print(f"\nğŸ“‹ è¯¦ç»†ä½œè€…åˆ†å¸ƒ (masteråˆ†æ”¯):")
            for _, row in df.iterrows():
                if row["Author List"]:
                    print(f"  {row['Date']}: {row['Author List']}")

    def get_dataframe(self):
        """è¿”å›pandas DataFrameæ ¼å¼çš„ç»Ÿè®¡æ•°æ®"""
        if not self.daily_stats:
            return pd.DataFrame()

        data = []
        sorted_dates = sorted(self.daily_stats.keys())

        for date in sorted_dates:
            stats = self.daily_stats[date]
            data.append(
                {
                    "æ—¥æœŸ": date,
                    "æäº¤æ•°": stats["commits"],
                    "æ–°å¢è¡Œæ•°": stats["added_lines"],
                    "åˆ é™¤è¡Œæ•°": stats["deleted_lines"],
                    "å‡€å˜åŒ–": stats["net_lines"],
                    "ä½œè€…æ•°": len(stats["authors"]),
                    "æ–‡ä»¶æ•°": stats["files_changed"],
                    "ä½œè€…åˆ—è¡¨": ", ".join(sorted(stats["authors"])),
                }
            )

        return pd.DataFrame(data)

    def export_to_csv(self, filename):
        """å¯¼å‡ºç»Ÿè®¡ç»“æœåˆ°CSVæ–‡ä»¶"""
        df = self.get_dataframe()
        if df.empty:
            print("æ²¡æœ‰ç»Ÿè®¡æ•°æ®å¯å¯¼å‡º")
            return

        df.to_csv(filename, index=False, encoding="utf-8")
        print(f"ğŸ“ ç»Ÿè®¡ç»“æœå·²å¯¼å‡ºåˆ°: {filename}")


def main():
    parser = argparse.ArgumentParser(
        description="Gitæ¯æ—¥ä»£ç æäº¤ç»Ÿè®¡å·¥å…· (ä»…ç»Ÿè®¡masteråˆ†æ”¯)",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=__doc__,
    )

    parser.add_argument("--since", "-s", help="å¼€å§‹æ—¥æœŸ (æ ¼å¼: YYYY-MM-DDï¼Œé»˜è®¤30å¤©å‰)")
    parser.add_argument("--until", "-u", help="ç»“æŸæ—¥æœŸ (æ ¼å¼: YYYY-MM-DDï¼Œé»˜è®¤ä»Šå¤©)")
    parser.add_argument("--author", "-a", help="æŒ‡å®šä½œè€…åç§°")
    parser.add_argument("--output", "-o", help="è¾“å‡ºCSVæ–‡ä»¶å")
    parser.add_argument(
        "--file-types", "-t", help="æŒ‡å®šæ–‡ä»¶ç±»å‹ï¼Œç”¨é€—å·åˆ†éš” (å¦‚: py,js,vue)"
    )
    parser.add_argument(
        "--repo-path", "-p", default=".", help="Gitä»“åº“è·¯å¾„ (é»˜è®¤å½“å‰ç›®å½•)"
    )

    args = parser.parse_args()

    # è®¾ç½®é»˜è®¤æ—¥æœŸèŒƒå›´ï¼ˆæœ€è¿‘30å¤©ï¼‰
    if not args.since:
        args.since = (datetime.now() - timedelta(days=30)).strftime("%Y-%m-%d")

    # å¤„ç†æ–‡ä»¶ç±»å‹è¿‡æ»¤
    file_types = None
    if args.file_types:
        file_types = [ft.strip().lower() for ft in args.file_types.split(",")]

    # åˆ›å»ºåˆ†æå™¨å®ä¾‹
    analyzer = GitCommitStatsAnalyzer(args.repo_path)

    # æ‰§è¡Œåˆ†æ
    success = analyzer.analyze_commits(
        since_date=args.since,
        until_date=args.until,
        author=args.author,
        file_types=file_types,
    )

    if success:
        # æ˜¾ç¤ºç»Ÿè®¡ç»“æœ
        analyzer.print_stats()

        # å¯¼å‡ºCSVï¼ˆå¦‚æœæŒ‡å®šï¼‰
        if args.output:
            analyzer.export_to_csv(args.output)


if __name__ == "__main__":
    main()
