Core examples
=============

Core examples are hosted on the GitHub Flax repository in the `examples <https://github.com/google/flax/tree/main/examples>`__
directory.

Each example is designed to be **self-contained and easily forkable**, while
reproducing relevant results in different areas of machine learning.

Some of the examples below have a link "InteractiveðŸ•¹" that lets you run them
directly in Colab.

Transformers
********************

- :octicon:`mark-github;0.9em` `Gemma <https://github.com/google/flax/tree/main/examples/gemma/>`__ :
  A family of open-weights Large Language Model (LLM) by Google DeepMind, based on Gemini research and technology.

-  :octicon:`mark-github;0.9em` `LM1B <https://github.com/google/flax/tree/main/examples/lm1b/>`__ :
   Transformer encoder trained on the One Billion Word Benchmark.

Toy examples
********************

`NNX toy examples <https://github.com/google/flax/tree/main/examples/nnx_toy_examples/>`__
directory contains a few smaller, standalone toy examples for simple training scenarios.
