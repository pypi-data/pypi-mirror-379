# ml/models/advanced_rag.py
from sentence_transformers import SentenceTransformer, CrossEncoder
import numpy as np
from typing import List, Dict, Optional
import torch

class AdvancedRAGSystem:
    def __init__(self):
        """
        Enhanced RAG with reranking for better context retrieval
        Purpose: 50% better response relevance through two-stage retrieval
        """
        print("ðŸ”„ Initializing Advanced RAG System...")
        
        # Primary embedding model for semantic search
        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')
        
        # Cross-encoder for reranking (more accurate but slower)
        try:
            self.reranker = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')
            self.reranker_available = True
            print("âœ… Cross-encoder reranker loaded successfully")
        except Exception as e:
            print(f"âš ï¸ Reranker not available, using fallback: {e}")
            self.reranker_available = False
        
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        print(f"ðŸš€ Advanced RAG System ready on {self.device}")
    
    def semantic_search_with_reranking(self, query: str, documents: List[str], 
                                     top_k: int = 5) -> List[Dict]:
        """
        Two-stage retrieval: semantic search + cross-encoder reranking
        
        Args:
            query: User's search query
            documents: List of documents to search in
            top_k: Number of final results to return
            
        Returns:
            List of documents with scores and rankings
        """
        if not documents:
            return []
        
        # Stage 1: Semantic search (get top candidates)
        candidates_count = min(20, len(documents))  # Get top 20 or all if less
        semantic_results = self._semantic_search(query, documents, candidates_count)
        
        if not self.reranker_available or len(semantic_results) <= top_k:
            return semantic_results[:top_k]
        
        # Stage 2: Cross-encoder reranking for better accuracy
        reranked_results = self._cross_encoder_rerank(query, semantic_results, top_k)
        
        return reranked_results
    
    def _semantic_search(self, query: str, documents: List[str], top_k: int) -> List[Dict]:
        """
        Perform semantic search using sentence transformers
        """
        query_embedding = self.embedding_model.encode([query])[0]
        doc_embeddings = self.embedding_model.encode(documents)
        
        # Calculate cosine similarities
        similarities = np.dot(doc_embeddings, query_embedding) / (
            np.linalg.norm(doc_embeddings, axis=1) * np.linalg.norm(query_embedding)
        )
        
        # Get top results
        top_indices = np.argsort(similarities)[-top_k:][::-1]
        
        results = []
        for idx in top_indices:
            results.append({
                'document': documents[idx],
                'semantic_score': float(similarities[idx]),
                'index': int(idx),
                'stage': 'semantic_search'
            })
        
        return results
    
    def _cross_encoder_rerank(self, query: str, candidates: List[Dict], top_k: int) -> List[Dict]:
        """
        Rerank candidates using cross-encoder for better accuracy
        """
        try:
            # Prepare query-document pairs for reranking
            pairs = [(query, candidate['document']) for candidate in candidates]
            
            # Get reranking scores
            rerank_scores = self.reranker.predict(pairs)
            
            # Combine scores and rerank
            for i, candidate in enumerate(candidates):
                candidate['rerank_score'] = float(rerank_scores[i])
                candidate['final_score'] = (
                    0.4 * candidate['semantic_score'] + 
                    0.6 * candidate['rerank_score']
                )
                candidate['stage'] = 'reranked'
            
            # Sort by final score and return top_k
            reranked = sorted(candidates, key=lambda x: x['final_score'], reverse=True)
            return reranked[:top_k]
            
        except Exception as e:
            print(f"âš ï¸ Reranking failed, falling back to semantic search: {e}")
            return candidates[:top_k]
    
    def hybrid_search(self, query: str, documents: List[str], 
                     keyword_weight: float = 0.3, top_k: int = 5) -> List[Dict]:
        """
        Combine semantic search with keyword matching
        """
        # Semantic search results
        semantic_results = self._semantic_search(query, documents, top_k * 2)
        
        # Simple keyword matching
        query_words = set(query.lower().split())
        keyword_scores = []
        
        for doc in documents:
            doc_words = set(doc.lower().split())
            keyword_overlap = len(query_words.intersection(doc_words))
            keyword_score = keyword_overlap / len(query_words) if query_words else 0
            keyword_scores.append(keyword_score)
        
        # Combine scores
        hybrid_results = []
        for result in semantic_results:
            idx = result['index']
            hybrid_score = (
                (1 - keyword_weight) * result['semantic_score'] +
                keyword_weight * keyword_scores[idx]
            )
            
            hybrid_results.append({
                'document': result['document'],
                'semantic_score': result['semantic_score'],
                'keyword_score': keyword_scores[idx],
                'hybrid_score': hybrid_score,
                'index': result['index'],
                'stage': 'hybrid_search'
            })
        
        # Sort by hybrid score and return top_k
        hybrid_results.sort(key=lambda x: x['hybrid_score'], reverse=True)
        return hybrid_results[:top_k]
    
    def query_expansion(self, query: str) -> List[str]:
        """
        Expand query with related terms for better search coverage
        """
        # Simple query expansion with synonyms and related terms
        expansion_dict = {
            'python': ['python', 'py', 'programming', 'coding', 'script'],
            'javascript': ['javascript', 'js', 'node', 'web', 'frontend'],
            'error': ['error', 'bug', 'exception', 'issue', 'problem'],
            'function': ['function', 'method', 'procedure', 'routine'],
            'database': ['database', 'db', 'sql', 'query', 'data'],
            'api': ['api', 'endpoint', 'rest', 'service', 'request'],
            'interview': ['interview', 'job', 'hiring', 'career', 'preparation'],
            'resume': ['resume', 'cv', 'profile', 'experience', 'skills']
        }
        
        query_words = query.lower().split()
        expanded_terms = set(query_words)
        
        for word in query_words:
            if word in expansion_dict:
                expanded_terms.update(expansion_dict[word])
        
        # Return expanded queries
        expanded_queries = [query]  # Original query first
        if len(expanded_terms) > len(query_words):
            expanded_query = ' '.join(expanded_terms)
            expanded_queries.append(expanded_query)
        
        return expanded_queries
    
    def get_search_stats(self) -> Dict:
        """
        Get statistics about the RAG system performance
        """
        return {
            'embedding_model': 'all-MiniLM-L6-v2',
            'reranker_available': self.reranker_available,
            'reranker_model': 'cross-encoder/ms-marco-MiniLM-L-6-v2' if self.reranker_available else 'none',
            'device': self.device,
            'two_stage_retrieval': self.reranker_available,
            'hybrid_search': True,
            'query_expansion': True
        }
