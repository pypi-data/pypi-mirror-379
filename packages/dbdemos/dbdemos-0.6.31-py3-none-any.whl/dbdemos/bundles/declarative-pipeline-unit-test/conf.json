{"name": "declarative-pipeline-unit-test", "category": "data-engineering", "title": "Unit Testing Declarative Pipeline for production-grade pipelines", "serverless_supported": true, "custom_schema_supported": true, "default_catalog": "main", "default_schema": "dbdemos_ldp_unit_test", "description": "Deploy robust pipelines with unit tests leveraging expectation.", "fullDescription": "Production-grade pipeline requires Unit Test to garantee their robustness. Lakeflow Declarative Pipeline let you track your pipeline data quality with expectation in your table. <br/> These expectations can also be leverage to write integration tests, making robust pipeline. <br/> In this demo, we'll show you how to test your LDP pipeline and make it composable, easily switching input data with your test data.", "bundle": true, "notebooks": [{"path": "LDP-pipeline-to-test", "pre_run": false, "publish_on_website": true, "add_cluster_setup_cell": false, "title": "LDP to test", "description": "Definition of the pipeline we want to test.", "object_type": "NOTEBOOK"}, {"path": "ingestion_profile/LDP-ingest_prod", "pre_run": false, "publish_on_website": true, "add_cluster_setup_cell": false, "title": "Prod ingestion source", "description": "Define the production data source (ex: kafka)", "object_type": "NOTEBOOK"}, {"path": "ingestion_profile/LDP-ingest_test", "pre_run": false, "publish_on_website": true, "add_cluster_setup_cell": false, "title": "Test ingestion source", "description": "Define the test data source (ex: csv file crafted to validate our tests)", "object_type": "NOTEBOOK"}, {"path": "test/LDP-Test-Dataset-setup", "pre_run": true, "publish_on_website": true, "add_cluster_setup_cell": false, "title": "Test dataset creation", "description": "Craft the data required for the tests (used by 'LDP-ingest_test')"}, {"path": "test/LDP-Tests", "pre_run": false, "publish_on_website": true, "add_cluster_setup_cell": false, "title": "Unit test definition", "description": "Main notebook containing the unit tests.", "object_type": "NOTEBOOK"}], "init_job": {"settings": {"name": "field_demos_ldp_unit_test_init_{{CURRENT_USER_NAME}}", "email_notifications": {"no_alert_for_skipped_runs": false}, "timeout_seconds": 0, "max_concurrent_runs": 1, "tasks": [{"task_key": "init_data", "notebook_task": {"notebook_path": "{{DEMO_FOLDER}}/test/LDP-Test-Dataset-setup", "source": "WORKSPACE"}, "job_cluster_key": "Shared_job_cluster", "timeout_seconds": 0, "email_notifications": {}}, {"task_key": "start_ldp_pipeline", "pipeline_task": {"pipeline_id": "{{DYNAMIC_DLT_ID_dlt-test}}", "full_refresh": true}, "timeout_seconds": 0, "email_notifications": {}, "depends_on": [{"task_key": "init_data"}]}], "job_clusters": [{"job_cluster_key": "Shared_job_cluster", "new_cluster": {"spark_version": "16.4.x-scala2.12", "spark_conf": {"spark.master": "local[*, 4]", "spark.databricks.cluster.profile": "singleNode"}, "custom_tags": {"ResourceClass": "SingleNode"}, "spark_env_vars": {"PYSPARK_PYTHON": "/databricks/python3/bin/python3"}, "enable_elastic_disk": true, "data_security_mode": "SINGLE_USER", "runtime_engine": "STANDARD", "num_workers": 0}}], "format": "MULTI_TASK"}}, "cluster": {"spark_conf": {"spark.master": "local[*]", "spark.databricks.cluster.profile": "singleNode"}, "custom_tags": {"ResourceClass": "SingleNode"}, "single_user_name": "{{CURRENT_USER}}", "data_security_mode": "SINGLE_USER", "num_workers": 0}, "pipelines": [{"id": "dlt-test", "run_after_creation": false, "definition": {"clusters": [{"label": "default", "autoscale": {"min_workers": 1, "max_workers": 5, "mode": "LEGACY"}}], "development": true, "continuous": false, "channel": "CURRENT", "edition": "ADVANCED", "photon": false, "libraries": [{"notebook": {"path": "{{DEMO_FOLDER}}/LDP-pipeline-to-test"}}, {"notebook": {"path": "{{DEMO_FOLDER}}/ingestion_profile/LDP-ingest_test"}}, {"notebook": {"path": "{{DEMO_FOLDER}}/test/LDP-Tests"}}], "name": "dbdemos_ldp_unit_test_{{CATALOG}}_{{SCHEMA}}", "catalog": "{{CATALOG}}", "target": "{{SCHEMA}}"}}]}