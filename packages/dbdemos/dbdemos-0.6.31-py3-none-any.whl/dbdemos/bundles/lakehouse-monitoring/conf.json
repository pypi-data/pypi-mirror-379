{"name": "lakehouse-monitoring", "category": "DBSQL", "serverless_supported": true, "custom_schema_supported": true, "default_catalog": "main", "default_schema": "dbdemos_lhm", "title": "Lakehouse Monitoring for Retail Transactions", "description": "Monitor your data quality with Lakehouse Monitoring", "fullDescription": "Databricks Lakehouse Monitoring allows you to monitor all your data pipelines and ML models \u2013 without additional tools and complexity. Integrated into Unity Catalog, teams can track quality alongside governance, building towards the self-serve data platform dream. By continuously assessing the profile of your data, Lakehouse Monitoring allows you to stay ahead of potential issues, ensuring that pipelines run smoothly and ML models remain effective over time.", "bundle": true, "tags": [{"dlt": "Delta Live Table"}, {"ds": "Data Science"}, {"dbsql": "BI/DW/DBSQL"}], "notebooks": [{"path": "_resources/01-DataGeneration", "pre_run": false, "publish_on_website": true, "add_cluster_setup_cell": false, "title": "Prep data", "description": "Data generation.", "object_type": "NOTEBOOK"}, {"path": "01-Timeseries-monitor", "pre_run": true, "publish_on_website": true, "add_cluster_setup_cell": false, "title": "Create your first monitor", "description": "Discover Lakehouse Montoring."}, {"path": "02-Inference-monitor", "pre_run": true, "publish_on_website": true, "add_cluster_setup_cell": false, "title": "Monitor your Inference table", "description": "Leverage Lakehouse Montoring to track your Model performance."}, {"path": "config", "pre_run": false, "publish_on_website": false, "add_cluster_setup_cell": false, "title": "Configuration", "description": "Setup.", "object_type": "NOTEBOOK"}, {"path": "_resources/00-global-setup-v2", "title": "Global init", "description": "Global init", "pre_run": false, "publish_on_website": false, "add_cluster_setup_cell": false, "parameters": {}, "depends_on_previous": true, "libraries": [], "warehouse_id": null, "object_type": null}], "init_job": {}, "cluster": {"autoscale": {"min_workers": 1, "max_workers": 1}, "spark_version": "16.4.x-cpu-ml-scala2.12", "single_user_name": "{{CURRENT_USER}}", "data_security_mode": "SINGLE_USER", "runtime_engine": "STANDARD"}, "pipelines": [], "workflows": []}