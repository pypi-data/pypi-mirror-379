# ğŸ§  leo-prompt-optimizer

**leo-prompt-optimizer** is a Python library that helps developers **optimize raw LLM prompts** into structured, high-performance instructions using real LLM intelligence.

It leverages **open-source models via [Groq API](https://console.groq.com/)** (like Mixtral or LLaMA 3), and also supports OpenAI, making it fast, flexible, and production-ready.

---

## ğŸš€ Features

- ğŸ› ï¸ Refines vague, messy, or unstructured prompts
- ğŸ§  Follows a 9-step prompt engineering framework
- ğŸ§© Supports contextual optimization (with user input & LLM output)
- ğŸ” Works with both Groq **and** OpenAI
- âš¡ Blazing-fast open models via Groq
- ğŸ” Secure API key management with `.env` or helper function
- ğŸ›ï¸ Let users choose model (`gpt-3.5-turbo`, `mixtral-8x7b`, `llama3`, etc.)

---

## ğŸ“¦ Installation

```bash
pip install leo-prompt-optimizer
````

---

## ğŸ”§ Setup: API Keys

You can provide your API key in two ways:

### âœ… Option A: `.env` file (recommended)

At the root of your project, create a `.env` file:

```env
GROQ_API_KEY=sk-your-groq-key
or
OPENAI_API_KEY=sk-your-openai-key
```

Then, in your Python script:

```python
from dotenv import load_dotenv
load_dotenv()  # ğŸ‘ˆ Required to load the API keys from .env
```

---

### âœ… Option B: Set programmatically

```python
from leo_prompt_optimizer import set_groq_api_key, set_openai_api_key

set_groq_api_key("sk-your-groq-key")
set_openai_api_key("sk-your-openai-key")
```

---

## âœï¸ Usage Example

```python
from dotenv import load_dotenv
load_dotenv()  # Only needed if using .env for API keys

from leo_prompt_optimizer import optimize_prompt, set_groq_api_key, set_openai_api_key

# Optional: Set API key manually (Groq or OpenAI)
# set_openai_api_key("sk-...")
# set_groq_api_key("sk-...")

optimized = optimize_prompt(
    prompt_draft="[YOUR PROMPT]",
    user_input="[POTENTIAL INPUT EXAMPLE]", # Optional
    llm_output="[POTENTIAL OUTPUT EXAMPLE]", # Optional
    provider="[YOUR PROVIDER]",               # "groq" (default) or "openai"
    model="[YOUR MODEL]",            # Optional: model choie based on your provider(e.g. "gpt-4", "llama3-70b", etc.)
    base_url="[YOUR BASE_URL]"       # Optional: if you have a specific base url
)

print(optimized)
```

> ğŸ§  `user_input` and `llm_output` are optional but helpful when refining an existing prompt flow.
> ğŸ›ï¸ You can also specify the `provider` (`groq` or `openai`) and the exact `model` you want.

---

## ğŸ“˜ Output Format

The returned optimized prompt follows a structured format:

```text
Role:
[Define the LLM's persona]

Task:
[Clearly state the specific objective]

Instructions:
* Step-by-step subtasks

Context:
[Any relevant background, constraints, domain]

Output Format:
[e.g., bullet list, JSON, summary]

User Input:
[Original user input or example]
```

---

## ğŸ§ª Quick Test (Optional)

```bash
python3 test_import.py
```

This will check:

* âœ… Import works
* âœ… API keys are detected
* âœ… LLM returns optimized result

---

## ğŸ§¯ Common Errors & Fixes

| Error                    | Solution                                                                                                                  |
| ------------------------ | ------------------------------------------------------------------------------------------------------------------------- |
| `Missing GROQ_API_KEY`   | Ensure it's in `.env` and loaded with `load_dotenv()`, or passed via `set_groq_api_key()`                                 |
| `Missing OPENAI_API_KEY` | Same as above, but with `set_openai_api_key()`                                                                            |
| `Invalid model` or 403   | The model may be deprecated or restricted. Try another model or check [Groq Models](https://console.groq.com/docs/models) |
| `ModuleNotFoundError`    | Ensure `leo-prompt-optimizer` is installed in the right Python environment                                                |

---

## ğŸ’¡ Why Use It?

Prompt quality is critical when building with LLMs.

**leo-prompt-optimizer** helps you:

âœ… Make prompts explicit and structured
ğŸš« Reduce hallucinations
ğŸ” Increase consistency and reuse
ğŸ§± Standardize prompt formats across your stack

---