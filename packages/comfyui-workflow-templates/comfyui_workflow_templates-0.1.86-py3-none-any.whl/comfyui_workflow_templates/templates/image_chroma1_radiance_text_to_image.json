{
  "id": "242a6140-7341-49ca-876b-c01366b39b84",
  "revision": 0,
  "last_node_id": 41,
  "last_link_id": 47,
  "nodes": [
    {
      "id": 10,
      "type": "CLIPLoader",
      "pos": [
        -485,
        164
      ],
      "size": [
        370,
        106
      ],
      "flags": {},
      "order": 0,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "CLIP",
          "type": "CLIP",
          "links": [
            14
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.59",
        "Node name for S&R": "CLIPLoader",
        "models": [
          {
            "name": "t5xxl_fp16.safetensors",
            "url": "https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/t5xxl_fp16.safetensors",
            "directory": "text_encoders"
          }
        ]
      },
      "widgets_values": [
        "t5xxl_fp16.safetensors",
        "chroma",
        "default"
      ]
    },
    {
      "id": 13,
      "type": "UNETLoader",
      "pos": [
        -485,
        40
      ],
      "size": [
        370,
        82
      ],
      "flags": {},
      "order": 1,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            30
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.59",
        "Node name for S&R": "UNETLoader",
        "models": [
          {
            "name": "Chroma1-Radiance-v0.1.safetensors",
            "url": "https://huggingface.co/lodestones/Chroma1-Radiance/resolve/main/Chroma1-Radiance-v0.1.safetensors",
            "directory": "diffusion_models"
          }
        ]
      },
      "widgets_values": [
        "Chroma1-Radiance-v0.1.safetensors",
        "default"
      ]
    },
    {
      "id": 7,
      "type": "CLIPTextEncode",
      "pos": [
        230,
        250
      ],
      "size": [
        425.27801513671875,
        180.6060791015625
      ],
      "flags": {},
      "order": 9,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 12
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "slot_index": 0,
          "links": [
            6
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.59",
        "Node name for S&R": "CLIPTextEncode"
      },
      "widgets_values": [
        "low quality, bad anatomy, extra digits, missing digits, extra limbs, missing limbs, hands, fingers"
      ],
      "color": "#223",
      "bgcolor": "#335"
    },
    {
      "id": 11,
      "type": "T5TokenizerOptions",
      "pos": [
        -80,
        170
      ],
      "size": [
        270,
        82
      ],
      "flags": {},
      "order": 7,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 14
        }
      ],
      "outputs": [
        {
          "name": "CLIP",
          "type": "CLIP",
          "links": [
            12,
            20
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.59",
        "Node name for S&R": "T5TokenizerOptions"
      },
      "widgets_values": [
        0,
        3
      ]
    },
    {
      "id": 3,
      "type": "KSampler",
      "pos": [
        700,
        140
      ],
      "size": [
        315,
        262
      ],
      "flags": {},
      "order": 11,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 31
        },
        {
          "name": "positive",
          "type": "CONDITIONING",
          "link": 4
        },
        {
          "name": "negative",
          "type": "CONDITIONING",
          "link": 6
        },
        {
          "name": "latent_image",
          "type": "LATENT",
          "link": 47
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "slot_index": 0,
          "links": [
            7
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.59",
        "Node name for S&R": "KSampler"
      },
      "widgets_values": [
        461052028503273,
        "randomize",
        30,
        4,
        "euler",
        "simple",
        1
      ]
    },
    {
      "id": 15,
      "type": "VAELoader",
      "pos": [
        260,
        500
      ],
      "size": [
        370,
        58
      ],
      "flags": {},
      "order": 2,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "VAE",
          "type": "VAE",
          "links": [
            41
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.59",
        "Node name for S&R": "VAELoader"
      },
      "widgets_values": [
        "pixel_space"
      ]
    },
    {
      "id": 34,
      "type": "EmptyChromaRadianceLatentImage",
      "pos": [
        -460,
        370
      ],
      "size": [
        326.3540954589844,
        106
      ],
      "flags": {},
      "order": 3,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [
            47
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.59",
        "Node name for S&R": "EmptyChromaRadianceLatentImage"
      },
      "widgets_values": [
        1024,
        1024,
        1
      ]
    },
    {
      "id": 22,
      "type": "ModelSamplingAuraFlow",
      "pos": [
        700,
        20
      ],
      "size": [
        315,
        60
      ],
      "flags": {},
      "order": 8,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 30
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            31
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.59",
        "Node name for S&R": "ModelSamplingAuraFlow"
      },
      "widgets_values": [
        3.0000000000000004
      ]
    },
    {
      "id": 8,
      "type": "VAEDecode",
      "pos": [
        700,
        460
      ],
      "size": [
        315,
        46
      ],
      "flags": {
        "collapsed": false
      },
      "order": 12,
      "mode": 0,
      "inputs": [
        {
          "name": "samples",
          "type": "LATENT",
          "link": 7
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 41
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "slot_index": 0,
          "links": [
            35
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.59",
        "Node name for S&R": "VAEDecode"
      },
      "widgets_values": []
    },
    {
      "id": 14,
      "type": "Note",
      "pos": [
        -80,
        20
      ],
      "size": [
        270,
        90
      ],
      "flags": {},
      "order": 4,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "properties": {},
      "widgets_values": [
        "min_padding 1 is supposed to be the official way to inference chroma but I think the results are better with min_padding 0\n"
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 6,
      "type": "CLIPTextEncode",
      "pos": [
        230,
        40
      ],
      "size": [
        422.84503173828125,
        164.31304931640625
      ],
      "flags": {},
      "order": 10,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 20
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "slot_index": 0,
          "links": [
            4
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.59",
        "Node name for S&R": "CLIPTextEncode"
      },
      "widgets_values": [
        "Hyperrealistic macro photograph of a team of tiny bakersâ€”each precisely 2 inches tallâ€”collaborating on an enormous, golden-brown croissant with flaky, layered textures. The bakers are engaged in dynamic, detailed actions: one uses a miniature wooden bucket to spread rich, creamy butter between the croissantâ€™s layers, another climbs a thin rope ladder to evenly pipe smooth, glossy chocolate filling onto the top, and a third brushes a light egg wash with a tiny pastry brush. The scene is bathed in warm, soft kitchen lighting with cinematic depthâ€”subtle highlights on the croissantâ€™s golden crust, gentle shadows that emphasize texture, and a soft glow from overhead pendant lights. Floating flour dust particles catch the light, adding a sense of movement and realism, while tiny details like the bakersâ€™ stitched cloth aprons, smudged flour on their faces, the rough wood of the worktable, and the slight sheen of melted butter on the croissant are rendered with ultra-precision. Ultra-detailed, 8K resolution, photorealistic textures, sharp focus on the bakers and croissant, shallow depth of field to blur the background slightly, rich warm color palette, lifelike proportions, and a cozy, whimsical atmosphere that balances realism with charm.\n"
      ],
      "color": "#232",
      "bgcolor": "#353"
    },
    {
      "id": 26,
      "type": "SaveImage",
      "pos": [
        1030,
        20
      ],
      "size": [
        1018.58642578125,
        1102.2607421875
      ],
      "flags": {},
      "order": 13,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 35
        }
      ],
      "outputs": [],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.59"
      },
      "widgets_values": [
        "ComfyUI"
      ]
    },
    {
      "id": 38,
      "type": "Note",
      "pos": [
        260,
        600
      ],
      "size": [
        370,
        110
      ],
      "flags": {},
      "order": 5,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "About pixel_space",
      "properties": {},
      "widgets_values": [
        "This Chroma1 Radiance image generation is in pixel space. No additional VAE is needed."
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 40,
      "type": "MarkdownNote",
      "pos": [
        -1000,
        0
      ],
      "size": [
        490,
        420
      ],
      "flags": {},
      "order": 6,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "properties": {},
      "widgets_values": [
        "## Model links\n\nThis model is still iterating, you can visit [lodestones/Chroma1-Radiance](https://huggingface.co/lodestones/Chroma1-Radiance) to get the latest version\n\n**diffusion_models**\n- [Chroma1-Radiance-v0.1.safetensors](https://huggingface.co/lodestones/Chroma1-Radiance/resolve/main/Chroma1-Radiance-v0.1.safetensors)\n\n**text_encoders**\n- [t5xxl_fp16.safetensors](https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/t5xxl_fp16.safetensors)\n\n```\nðŸ“‚ ComfyUI/\nâ”œâ”€ ðŸ“‚ models/\nâ”‚   â”œâ”€ ðŸ“‚ diffusion_models/\nâ”‚   â”‚     â””â”€â”€ Chroma1-Radiance-v0.1.safetensors\nâ”‚   â”œâ”€ ðŸ“‚ text_encoders/\nâ”‚   â”‚     â””â”€â”€ t5xxl_fp16.safetensors \n```\n\n\n## About Chroma1-Radiance\n\nChroma1-Radiance is a text-to-image model that generates pictures from words. What makes it special is that it works directly with the image's pixels, instead of using a compressed version. This helps it create higher-quality images with fewer visual mistakes like blurriness or distorted details. It's a new and promising model that's trying a different way to improve how images are made.\n\nIf you want to keep update with Chroma1-Radiance you can follow [lodestones](https://x.com/LodestoneE621)\n"
      ],
      "color": "#432",
      "bgcolor": "#653"
    }
  ],
  "links": [
    [
      4,
      6,
      0,
      3,
      1,
      "CONDITIONING"
    ],
    [
      6,
      7,
      0,
      3,
      2,
      "CONDITIONING"
    ],
    [
      7,
      3,
      0,
      8,
      0,
      "LATENT"
    ],
    [
      12,
      11,
      0,
      7,
      0,
      "CLIP"
    ],
    [
      14,
      10,
      0,
      11,
      0,
      "CLIP"
    ],
    [
      20,
      11,
      0,
      6,
      0,
      "CLIP"
    ],
    [
      30,
      13,
      0,
      22,
      0,
      "MODEL"
    ],
    [
      31,
      22,
      0,
      3,
      0,
      "MODEL"
    ],
    [
      35,
      8,
      0,
      26,
      0,
      "IMAGE"
    ],
    [
      41,
      15,
      0,
      8,
      1,
      "VAE"
    ],
    [
      47,
      34,
      0,
      3,
      3,
      "LATENT"
    ]
  ],
  "groups": [
    {
      "id": 1,
      "title": "Step 1 - Load models",
      "bounding": [
        -490,
        -30,
        390,
        313.6000061035156
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 2,
      "title": "Step3 - Prompt",
      "bounding": [
        220,
        -30,
        445.27801513671875,
        474.2060852050781
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 3,
      "title": "Step 2 - Image size",
      "bounding": [
        -490,
        300,
        390,
        190
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    }
  ],
  "config": {},
  "extra": {
    "ds": {
      "scale": 0.4914108634365025,
      "offset": [
        1632.196674315222,
        291.0511957579497
      ]
    },
    "frontendVersion": "1.26.11",
    "VHS_latentpreview": false,
    "VHS_latentpreviewrate": 0,
    "VHS_MetadataImage": true,
    "VHS_KeepIntermediate": true
  },
  "version": 0.4
}