# ğŸš€ Mimo Language Model

Mimo est un modÃ¨le de langage AI pour exceller Ã  la fois en **gÃ©nÃ©ration de code** et en **conversations naturelles**.  
Il est issu d'un mÃ©lange de datasets puissants.

![Mimo](https://raw.githubusercontent.com/eurocybersecurite/Mimo-llm/main/assets/mimo.png)

---

## ğŸ“‘ Table des matiÃ¨res

- [âœ¨ Points forts de Mimo](#-points-forts-de-mimo)
- [ğŸ“¦ Installation](#-installation)
- [ğŸ”‘ Configuration](#-configuration)
- [ğŸ‹ï¸ Fine-tuning](#-fine-tuning)
- [ğŸ§‘â€ğŸ’» Exemples dâ€™utilisation](#-exemples-dutilisation)
  - [GÃ©nÃ©ration de code](#gÃ©nÃ©ration-de-code)
  - [Conversation](#conversation)
- [ğŸ“Š Performances comparatives](#-performances-comparatives)
- [ğŸ§  Visualisations comparatives](#-visualisations-comparatives)
  - [Radar de performance](#-1-radar-de-performance)
  - [EntraÃ®nement & efficacitÃ©](#-2-entrainement--efficacitÃ©)
  - [Classification & Clustering](#-3-classification--clustering)
  - [PrÃ©cision en classification](#-4-prÃ©cision-en-classification)
  - [Raisonnement avancÃ©](#-5-raisonnement-avancÃ©)
  - [Conscience artificielle](#-6-conscience-artificielle-concept)
- [ğŸ“‚ Structure du dÃ©pÃ´t](#-structure-du-dÃ©pÃ´t)
- [ğŸ› ï¸ IntÃ©gration dans VSCode](#-intÃ©gration-dans-vscode)
- [ğŸ“§ Auteur](#-auteur)

---

## âœ¨ Points forts de Mimo

- ğŸ”§ **OptimisÃ© pour le code** : gÃ©nÃ©ration fiable de scripts Python, JS, etc.  
- ğŸ’¬ **Excellente conversation** : rÃ©ponses naturelles et contextualisÃ©es.  
- âš¡ **CompatibilitÃ© multiplateforme** : fonctionne sur Mac, PC et VSCode.  
- ğŸ“¦ **PrÃªt pour la quantification** (GGUF) â†’ utilisable avec LM Studio ou Ollama.  

---

## ğŸ“¦ Installation

Clonez le dÃ©pÃ´t et installez les dÃ©pendances dans un environnement virtuel :

```bash
# Cloner le dÃ©pÃ´t
git clone https://github.com/eurocybersecurite/Mimo-llm.git
cd Mimo-llm

# CrÃ©er et activer un environnement virtuel (recommandÃ©)
python3 -m venv .venv
source .venv/bin/activate  # Sur Linux/macOS
# Ou sur Windows : .\.venv\Scripts\activate

# Installer les dÃ©pendances
pip install -r requirements.txt
```

âš ï¸ Assurez-vous dâ€™avoir `git-lfs` installÃ© pour gÃ©rer les poids du modÃ¨le.

---

## ğŸ”‘ Configuration

Avant toute utilisation, configurez votre **Hugging Face Token** :

```bash
export HF_TOKEN="votre_token_hugging_face"
```
(Remplacez `"votre_token_hugging_face"` par votre vÃ©ritable token.)

---

## ğŸ‹ï¸ Fine-tuning

Lancez le fine-tuning avec :

```bash
python fine_tune_mimo.py
```

**IMPORTANT :** Remplacez `example.jsonl` par votre propre fichier de dataset avant d'exÃ©cuter ce script. Le fichier `example.jsonl` contient quelques exemples fictifs Ã  des fins de dÃ©monstration.

- Utilise vos donnÃ©es perso (`example.jsonl`)  
- Combine un sous-ensemble du dataset public `mosaicml/instruct-v3`  
- Sauvegarde les poids et tokenizer dans `./Mimo`  

---

## ğŸ§‘â€ğŸ’» Exemples dâ€™utilisation

### GÃ©nÃ©ration de code

```python
# Assurez-vous que le modÃ¨le et le tokenizer sont chargÃ©s correctement
# Exemple d'infÃ©rence pour la gÃ©nÃ©ration de code
prompt_code = "Ã‰cris une fonction Python pour calculer la somme des Ã©lÃ©ments d'une liste."
inputs_code = tokenizer(prompt_code, return_tensors="pt").to(model.device)

with torch.no_grad():
    outputs_code = model.generate(
        **inputs_code,
        max_new_tokens=100,
        pad_token_id=tokenizer.eos_token_id
    )
generated_code = tokenizer.decode(outputs_code[0], skip_special_tokens=True)
print("--- GÃ©nÃ©ration de Code ---")
print(generated_code)
```

### Conversation

```python
# Exemple d'infÃ©rence pour la conversation
prompt_conversation = "Quelle est la meilleure faÃ§on d'apprendre une nouvelle langue ?"
inputs_conversation = tokenizer(prompt_conversation, return_tensors="pt").to(model.device)

with torch.no_grad():
    outputs_conversation = model.generate(
        **inputs_conversation,
        max_new_tokens=50,
        pad_token_id=tokenizer.eos_token_id
    )
generated_conversation = tokenizer.decode(outputs_conversation[0], skip_special_tokens=True)
print("\n--- GÃ©nÃ©ration de Conversation ---")
print(generated_conversation)
```

---

## ğŸ“Š Performances comparatives

| ModÃ¨le                          | Code (Python) | Conversation | MÃ©moire requise |
|---------------------------------|---------------|--------------|-----------------|
| GPT-Neo 1.3B                    | â­â­            | â­â­           | ~12 Go          |
| DeepSeek-Qwen-1.5B (base)       | â­â­â­           | â­â­â­          | ~10 Go          |
| **Mimo-1.5B (fine-tuned)**      | â­â­â­â­          | â­â­â­â­         | ~8 Go (quantisÃ©) |

â¡ï¸ **Mimo surpasse la version de base** sur les benchmarks internes (code + QA).

![Mimo Performance](https://raw.githubusercontent.com/eurocybersecurite/Mimo-llm/main/assets/mimo_conv_code.png)

---

## ğŸ§  Visualisations comparatives

Afin dâ€™illustrer les forces de **Mimo** par rapport aux autres modÃ¨les, plusieurs visualisations ont Ã©tÃ© gÃ©nÃ©rÃ©es Ã  partir de benchmarks internes (Septembre 2025).  

### ğŸ”¹ 1. Radar de performance
![Radar Performance](https://raw.githubusercontent.com/eurocybersecurite/Mimo-llm/main/assets/performance_radar.png)  

Ce diagramme radar compare les capacitÃ©s globales (Code, Conversation, MÃ©moire, Raisonnement).  
â¡ï¸ **Mimo domine** sur tous les axes, montrant son Ã©quilibre entre comprÃ©hension et gÃ©nÃ©ration.

---

### ğŸ”¹ 2. EntraÃ®nement & efficacitÃ©
![EntraÃ®nement](https://raw.githubusercontent.com/eurocybersecurite/Mimo-llm/main/assets/entrainement.png)  

Comparaison des mÃ©triques dâ€™entraÃ®nement :  
- â± Temps dâ€™entraÃ®nement plus court  
- ğŸ“‰ Perte finale plus faible  
- ğŸ’¾ MÃ©moire optimisÃ©e  

â¡ï¸ **Mimo apprend plus vite et avec moins de ressources**.

---

### ğŸ”¹ 3. Classification & Clustering
![Classification & Clustering](https://raw.githubusercontent.com/eurocybersecurite/Mimo-llm/main/assets/Classification_Clustering.png)  

Ce graphique montre comment chaque modÃ¨le regroupe les donnÃ©es en classes.  
â¡ï¸ Les clusters prÃ©dits par **Mimo** sont **plus nets et bien sÃ©parÃ©s**, preuve de sa meilleure capacitÃ© de gÃ©nÃ©ralisation.

---

### ğŸ”¹ 4. PrÃ©cision en classification
![MÃ©triques de classification](https://raw.githubusercontent.com/eurocybersecurite/Mimo-llm/main/assets/metriques_classification.png)  

Comparaison des scores : **Accuracy, Recall, F1-score**.  
â¡ï¸ **Mimo** garde une avance claire sur la prÃ©cision et la robustesse des prÃ©dictions.

---

### ğŸ”¹ 5. Raisonnement avancÃ©
![Raisonnement Mimo](https://raw.githubusercontent.com/eurocybersecurite/Mimo-llm/main/assets/resennement_mimo.png)  

TestÃ© sur des tÃ¢ches de raisonnement logique et contextuel.  
â¡ï¸ **Mimo** dÃ©montre une supÃ©rioritÃ© dans la rÃ©solution de problÃ¨mes complexes.

---

### ğŸ”¹ 6. Conscience artificielle (concept)
![Conscience artificielle](https://raw.githubusercontent.com/eurocybersecurite/Mimo-llm/main/assets/Conscience_artificielle.png)  

Visualisation heatmap sur 5 axes : **Perception, MÃ©moire, Raisonnement, CrÃ©ativitÃ©, Auto-adaptation**.  
â¡ï¸ **Mimo Ã©merge comme le modÃ¨le le plus â€œconscientâ€**, avec des scores nettement supÃ©rieurs aux autres.

---

## ğŸ“‚ Structure du dÃ©pÃ´t

```
Mimo/
â”œâ”€â”€ README.md
â”œâ”€â”€ assets/mimo.png
â”œâ”€â”€ mohamed.jsonl
â”œâ”€â”€ fine_tune_mimo.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ .gitignore
```

---

## ğŸ› ï¸ IntÃ©gration dans VSCode

1. Clonez le dÃ©pÃ´t :  
   ```bash
   git clone https://github.com/votre-utilisateur/mimo-llm.git
   cd mimo-llm
   ```
2. Installez les dÃ©pendances :  
   ```bash
   pip install -r requirements.txt
   ```
3. ExÃ©cutez soit :  
   - `fine_tune_mimo.py` â†’ pour lâ€™entraÃ®nement  
   - un script dâ€™infÃ©rence personnalisÃ©  

âš¡ Vous pouvez aussi utiliser Mimo dans **LM Studio** en important la version quantisÃ©e GGUF ou autre Format.

---








## ğŸ“§ Auteur

- **Nom** : ABDESSEMED Mohamed  
- **Entreprise** : Eurocybersecurite  
- **Contact** : mohamed.abdessemed@eurocybersecurite.fr

