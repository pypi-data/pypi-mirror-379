Metadata-Version: 2.4
Name: commonpower
Version: 0.6.2
Summary: A package for the exploration of safe single/multi-agent reinforcement learning in smart grids.
Project-URL: Homepage, https://github.com/TUMcps/commonpower
Project-URL: Documentation, https://commonpower.readthedocs.io
Author-email: Michael Eichelbeck <michael.eichelbeck@tum.de>, Hannah Markgraf <hannah.markgraf@tum.de>
License: MIT
License-File: LICENSE
Keywords: Control,Multi-Agent Systems,Power System,Reinforcement learning,Safety,Simulation,Smart Grid
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3
Requires-Python: <3.13,>=3.11
Requires-Dist: d3rlpy<3.0,>=2.8.1
Requires-Dist: gurobipy<13.0,>=12.0.3
Requires-Dist: jsonpickle<5.0,>=4.1.1
Requires-Dist: matplotlib<4.0,>=3.10.6
Requires-Dist: numpy<3.0,>=2.3.2
Requires-Dist: pandapower<4.0,>=3.1.2
Requires-Dist: prettytable<4.0,>=3.16.0
Requires-Dist: pydantic<3.0,>=2.11.7
Requires-Dist: pymongo<5.0,>=4.14.1
Requires-Dist: pyomo<7.0,>=6.9.4
Requires-Dist: stable-baselines3<3.0,>=2.7.0
Requires-Dist: tensorboard<3.0,>=2.20.0
Requires-Dist: tqdm<5.0,>=4.67.1
Requires-Dist: wandb<1.0,>=0.21.3
Provides-Extra: ci
Requires-Dist: pytest<9.0,>=8.4.1; extra == 'ci'
Provides-Extra: docs
Requires-Dist: myst-parser<5.0,>=4.0.1; extra == 'docs'
Requires-Dist: nbsphinx<1.0,>=0.9.7; extra == 'docs'
Requires-Dist: sphinx-autodoc-typehints<3.0,>=2.5.0; extra == 'docs'
Requires-Dist: sphinx-autorun<3.0,>=2.0.0; extra == 'docs'
Requires-Dist: sphinx-rtd-theme<4.0,>=3.0.2; extra == 'docs'
Provides-Extra: full
Requires-Dist: hyperopt<1.0,>=0.2.7; extra == 'full'
Requires-Dist: jupyter<2.0,>=1.1.1; extra == 'full'
Requires-Dist: ray[tune]<3.0,>=2.49.0; extra == 'full'
Requires-Dist: scikit-learn<2.0,>=1.7.1; extra == 'full'
Requires-Dist: torch<3.0,>=2.8.0; extra == 'full'
Provides-Extra: nn
Requires-Dist: hyperopt<1.0,>=0.2.7; extra == 'nn'
Requires-Dist: ray[tune]<3.0,>=2.49.0; extra == 'nn'
Requires-Dist: scikit-learn<2.0,>=1.7.1; extra == 'nn'
Requires-Dist: torch<3.0,>=2.8.0; extra == 'nn'
Description-Content-Type: text/markdown

CommonPower
===========

Introduction
-------------

CommonPower provides a flexible framework to model power systems, interface to single-agent and multi-agent RL controllers,
and maintain safety based on a symbolic representation of the system equations.
Alternatively, the system model can directly be used to solve a given use case via the built-in model predictive controller.
Following a modular design philosophy, CommonPower is an easily extendable tool for the development and benchmarking
of RL controllers in the context of smart grids. The initial focus is on energy management and economic dispatch.
Additionally, CommonPower readily allows the influence of forecast quality to be studied.
The primary features are

- an object-oriented approach to modelling power system entities,

- a Pyomo-based symbolic math representation of entities to obtain all relevant system equations in the background,

- interfaces for single/multi-agent reinforcement learning and optimal control,

- a flexible interface to make use of diverse data sources and forecasting models.

Documentation
--------------

Our documentation is available on [ReadtheDocs](https://commonpower.readthedocs.io).

Example
--------

The following code is an illustrative example of a multi-agent scenario with three housholds and heterogeneous controllers.
Two of the households are controlled by a multi-agent RL algorithm, the third by a model predictive controller.
This example covers the system creation, training, and deployment.

```python
from commonpower.core import System
from commonpower.models.components import Load, RenewableGen, ESSLinear
from commonpower.models.busses import RTPricedBus, ExternalGrid
from commonpower.models.powerflow import PowerBalanceModel
from commonpower.data_forecasting import CSVDataSource, DataProvider, PersistenceForecaster, PerfectKnowledgeForecaster
from commonpower.control.runners import DeploymentRunner, MAPPOTrainer
from commonpower.control.controllers import OptimalController, RLControllerMA
from commonpower.control.wrappers import MultiAgentWrapper
from commonpower.control.safety_layer.safety_layers import ActionProjectionSafetyLayer

pv_data = CSVDataSource("<path_to_data>")
load_data = CSVDataSource("<path_to_data>")
price_data = CSVDataSource("<path_to_data>")

# create 3 identical households
households = []
for i in range(3):
    household = RTPricedBus(f"household{i}").add_data_provider(DataProvider(price_data, PersistenceForecaster()))
    household.add_node(
        RenewableGen(f"pv{i}").add_data_provider(DataProvider(pv_data, PersistenceForecaster()))
    ).add_node(
        Load(f"load{i}").add_data_provider(DataProvider(load_data, PerfectKnowledgeForecaster()))
    ).add_node(
        ESSLinear(f"ess{i}", {
            "p": [-1.5, 1.5], # active power limits in kW
            "q": [0.0, 0.0],  # reactive power limits in kW
            "soc": [0.2, 9],  # state of charge limits in kWh
            "soc_init": 5.0  # initial state of charge
        })
    )
    households.append(household)

substation = ExternalGrid("substation")

sys = System(PowerBalanceModel()).add_node(households[0]).add_node(households[1]).add_node(households[2]).add_node(substation)

mpc_controller = OptimalController("mpc1").add_entity(households[0])
rl_agent1 = RLControllerMA("agent1", safety_layer=ActionProjectionSafetyLayer()).add_entity(households[1])
rl_agent2 = RLControllerMA("agent2", safety_layer=ActionProjectionSafetyLayer()).add_entity(households[2])

# traning
train_runner = MAPPOTrainer(sys, alg_config={"<your>": "<config>"}, wrapper=MultiAgentWrapper)
train_runner.run()

# deployment
deploy_runner = DeploymentRunner(sys, wrapper=MultiAgentWrapper)
deploy_runner.run()
```

For more examples, have a look at our [Tutorials](https://commonpower.readthedocs.io/en/latest/tutorials.html).


Reference
----------

CommonPower was developed and is maintained by the Cyber-Physical Systems Group at the Chair for Robotics and Embedded Systems at Technical University of Munich.

If you use CommonPower, please cite the corresponding [tool paper](https://arxiv.org/abs/2406.03231) as 
```
@misc{eichelbeck2024commonpower,
      title={{CommonPower}: A Framework for Safe Data-Driven Smart Grid Control}, 
      author={Michael Eichelbeck and Hannah Markgraf and Matthias Althoff},
      year={2024},
      eprint={2406.03231},
      archivePrefix={arXiv},
}
```

Installing CommonPower
----------------------

You will need [Python](https://www.python.org/downloads/) >= 3.11, <3.13 and the package manager [uv](https://github.com/astral-sh/uv) installed on your system.

We recommend using a [virtual environment](https://docs.python.org/3/library/venv.html) to work with CommonPower. 
To create and activate a virtual environment run
```bash
cd <your/working/directory>
uv venv
source ./.venv/bin/activate || .\.venv\Scripts\activate 
```

You can then proceed to install CommonPower.
For local development, install the library in editable mode using UV:
```bash
git clone "https://github.com/TUMcps/commonpower.git"
cd commonpower
uv sync
```

Otherwise, install CommonPower via PyPI:
```bash
uv pip install commonpower
```

Multi-agent reinforcement learning
----------------------------------

At the moment, CommonPower supports multi-agent reinforcement learning using the IPPO/MAPPO implementation detailed in this [paper](https://arxiv.org/abs/2103.01955). 
Since we had to make a few adjustments, we forked the original repository. Please clone our [fork](https://github.com/TUMcps/on-policy), cd into the repository and install the package to your virtual environment using
`uv pip install -e .`.

Gurobi
------

We use Gurobi as a default solver for our optimization problems. As a student, you can obtain an [academic license](https://www.gurobi.com/academia/academic-program-and-licenses/). 
There are two options: If you want to run CommonPower on you laptop, you can use the named-user license. To run it on a server, you need the WLS license.
After obtaining a license, follow the Gurobi [quickstart guide](https://www.gurobi.com/documentation/quickstart.html) (choose the appropriate one for your system) to install Gurobi and retrieve your license. 
If you use Gurobi on a server (with the WLS license) and receive the error that it requires two many cores, you can just [submit a ticket](https://support.gurobi.com/hc/en-us/requests/new?ticket_form_id=360000629792) with the error message and your WLS license will be upgraded.

Get started
------------

Have a look at the [Introduction Tutorial](https://commonpower.readthedocs.io/en/latest/tutorials/Introduction.html) to learn more about how CommonPower is structured.
